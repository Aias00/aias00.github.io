[{"title":"wsl安装、配置及使用","url":"/article/c84e9335.html","content":"\n1.安装\n\n2.修改镜像源\n\nhttps://cloud.tencent.com/developer/article/1538304\n\n3.设置用户sudo不填写密码\n\n3.安装 git\n\n4.配置 jdk\nhttps://zhuanlan.zhihu.com/p/166437674\n5.安装 maven\n","tags":["wsl"]},{"title":"spring-cloud-eureka","url":"/article/11c912f4.html","content":"\n","tags":["spring-cloud","eureka"]},{"title":"2021年春季面试记录","url":"/article/eba5d7a5.html","content":"\n## 百度\n\n### 百度一面\n\n- rabbitmq 如何保证消息不丢失\n- 双亲委派机制\n- 类加载器如何确定自己能加载哪些类\n- mysql innodb 引擎索引的数据结构\n- redis 实现 缓存带过期时间及淘汰策略\n- redis 集群\n- 共识算法\n- 分布式不用 queue 排队，如何实现抢工单\n- 分布式锁\n- dubbo 支持的协议，用的哪个协议，序列化，服务注册和发现\n- dubbo消费者是如何调用到连接者的\n- 两个消费者提供的服务名一样 包名都一样\n- springboot 和 springmvc 的区别\n- 算法：倒排链表\n- JVM 结构\n- 垃圾回收算法\n- 异常的类别\n- 设计模式，用到了哪些\n- mybatis 用了哪些数据结构\n- sql 优化\n- mysql 索引最左匹配原则\n- apollo 分布式配置\n- threadlocal\n\n### 百度二面\n\n- rabbitmq 如何保证消息不丢失，rabbitmq 顺序消费\n- java内存模型哪个区域最容易发生内存泄漏\n- 加载一个类涉及到哪些内存区域\n- dubbo 如何实现泛化（不引入 jar 包如何调用提供者的方法）\n- 共识算法\n- 分布式锁（redis、zookeeper）\n- mysql 为什么用自增主键\n- mysql 如何解决幻读（mvcc）\n- 一些 Linux 操作指令\n- mysql 客户端和服务器如何通信的，可以被中断吗\n- hashmap 为什么用红黑树，为什么不用二叉树，为什么不用平衡二叉树\n- A、B 两个数组，合并后排序（二分排序）\n- concurrentHashMap1.7、1.8\n- countDownLatch\n- try 里面 return，finally 里面 return，会返回什么，finally 什么时候执行的\n- spring如何做到ioc的\n- spring bean 什么时候创建的，什么时候销毁的\n- static/private static/final 哪些是线程安全的\n- threadLocal\n- redis 为什么快\n- mysqL innodb 叶子节点的特点，mysql 主键如何存储的\n- CAS 会出现同时替换的情况吗\n- 92843 找到离他最近比他大的数\n- sql 查出一个学生的平均分最大的\n\n## 快手\n\n### 快手一面\n\n- 自我介绍\n- 业务规模\n- 联合索引在 mysql 中怎么存储\n  - 叶子节点和非叶子节点都存储什么\n- MVCC\n- spring 事务隔离级别\n- @Transactional 注解什么情况下会失效\n- JVM 垃圾回收器了解吗\n- redis 中 string 的底层结构\n- 线程池提交任务流程\n- 删除除了编号不同，其他都相同的学生的冗余信息\n  - 自动编号 学号 姓名 课程 分数\n  - id number name course score\n  - 1 2005001 张三 数学 69\n  - 2 2005002 李四 语文 89\n  - 3 2005001 张三 数学 69\n- 求无重复最大子串的长度\n  - aabbcdefghhijk bcdefgh 7\n\n## 火花思维\n\n### 火花思维一面\n\n- 自我介绍\n- 业务规模\n- redis 哪些数据结构，用过哪些，布隆过滤器用过吗\n- 一次删除含有 500W 个 key 的 set（unlink）\n- redlock 锁，如何实现阻塞（pub/sub）\n- 题库中有 100 道题，如何随机插入到数据库\n- name 和 age，做联合索引哪个在前\n- 商家 id，用户 id，商品 id，如何分库分表，商家可以看到所有他卖出的商品，用户可以看到所有他买到的商品\n- ReentrantLock和synchronized区别\n\n### 火花思维二面\n\n- vhost 有什么用\n- 延时消息\n- 消息幂等\n- 用了什么类型的队列\n- redis 淘汰策略\n- redis 数据结构，用了哪些\n- mysql 乐观锁和悲观锁举例\n- 分布式事务\n","tags":["interview"]},{"title":"volatile关键字面试知识点（持续更新）","url":"/article/d1722f66.html","content":"\nvolatile 变量具有以下特性：\n\n- 可见性：任意对一个 volatile 变量的读，总能看到任意线程对这个 volatile 变量的最后的写入\n- 原子性：对任意单个 volatile 变量的读/写操作具有原子性，但类似于 volatile++这类复合操作无法保证原子性\n\nvolatile 写的内存语义如下：\n\n- 当写一个 volatile 变量时，JMM 会把该线程对应的工作内存的共享变量的值刷新到主内存\n\nvolatile 读的内存语义如下：\n\n- 当读一个 volatile 变量时，JMM 会把该线程对应的工作内存的共享变量缓存置为无效，强制从主内存读取\n\n### volatile 实现原理\n\nvolatile 在执行变量写之后执行 Lock 指令，将变量实时写入内存而不是处理器缓存，其他处理器通过缓存一致性协议嗅探到此变量的变更，将本地缓存置为无效，由此实现可见性\n\n在 JMM 中是通过内存屏障实现的\n\n- 在 volatile 写之前插入 storestore 屏障，防止上面的写操作与下面的 volatile 写重排序\n- 在 volatile 写之后插入 storeload 屏障，防止上面的 volatile 写与后面的读操作重排序\n- 在 volatile 读之后插入 loadload、loadstore 屏障，防止上面的 volatile 读与下面的普通读、volatile 写和普通写重排序\n\n还有 happens-before，对于一个 volatile 变量的写 happens-before 于后续任意对这个 volatile 的读\n\n由此实现有序性\n\n![](https://i.loli.net/2021/04/06/ck86Z1XgFNCtmqy.png)\n![](https://i.loli.net/2021/04/06/9tsXI6Kz1bhR7vB.png)\n![](https://i.loli.net/2021/04/06/2JmDeF8xRsOrXib.png)\n![](https://i.loli.net/2021/04/06/gh86vLoAFsPYZmW.png)\n\n### volatile 指令重排序\n\nvolatile 变量的内存可见性是基于内存屏障(Memory Barrier)实现。JMM 内部会有指令重排，并且会有 as-if-serial 和 happens-before 的理念来保证指令重排的正确性。内存屏障就是基于 4 个汇编级别的关键字来禁止指令重排的，volatile 的重排规则如下：\n\n1.第一个为读操作时，第二个任何操作不可重排到第一个操作前面\n\n2.第二个为写操作时，第一个任何操作不可重排到第二个操作后面\n\n3.第一个为写操作时，第二个的读写操作也不运行重排序\n\n![](https://i.loli.net/2021/04/06/G5lCHmaKWMo6SNg.png)\n\n### happens-before 规则\n\n- 程序顺序规则：一个线程中的每个操作，happens-before 于该线程中的任意后续操作\n- 监视器锁规则：对一个锁的解锁，happens-before 于后续对这个锁的加锁\n- volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 变量的读\n- 传递性：如果 A happens-before 于 B，B happens-before 于 C，则 A happens-before 于 C\n","tags":["interview","volatile"]},{"title":"redis两种持久化方式","url":"/article/ab613fab.html","content":"\n### 简介\n\n- redis 的高性能是由于其将所有的数据都存储在了内存中，但是如果只是存在在内存中，重启之后数据就会全部丢失，为了尽量减少数据的丢失，我们需要将数据同步到磁盘上，这就是所谓的持久化\n- Redis 支持两种方式的持久化，一种是 RDB 模式，一种是 AOF 模式\n- RDB 模式可以在指定的时间间隔内为你存储在 redis 中的数据集做快照，子进程将快照数据写入临时文件，然后定时刷新到磁盘，redis 在启动时会将生成的快照文件中的内容读取到内存中\n- AOF 模式是将服务器接执行的所有写入/删除指令记录下来，只允许追加操作，并在服务器启动时重构原有的数据集，日志以与服务器协议相同的格式记录，当日志文件过大时，redis 会对日志文件进行重写\n- 我们可以不开启持久化配置，这样我们的数据只在 redis 服务启动时存在\n- 我们也可以将 RDB 和 AOF 模式组合使用，在这种情况下，redis 服务器重启时会依据 AOF 方式读取数据，因为这种模式能够保证数据相对最完整\n\n### RDB 模式\n\n#### RBD 模式的优点\n\n- RDB 是一种非常便捷的单文件实时存储模式\n- RDB 文件非常便于备份，我们可以每小时保存一份过去 24 小时内的 RDB 文件，也可以每天备份一次过去 30 天内生成的 RDB 文件，我们可以保存不同版本的快照文件以避免数据的丢失\n- RDB 模式非常适合数据恢复，我们可以将 RDB 文件复制到各种远程服务器进行数据加载\n- 开启 RDB 模式，主进程只需要 Fork 出一个子进程来进行持久化操作，这样就可以极大的避免主进程执行 IO 操作了\n- 相比于 AOF 模式，如果数据集很大，RDB 的启动效率会更高\n\n#### RBD 模式的缺点\n\n- 相对而言，如果只开启了 RDB 模式，在 redis 服务宕机时，没有刷新到磁盘的临时数据可能会丢失\n- RDB 模式经常要通过 Fork 子进程来协助完成持久化工作，当内存中数据集过大时，Fork 操作可能会花费比较多的时间，如果 cpu 性能较差，redis 服务可能会出现几百毫秒甚至 1 秒的时间无法接收数据，AOF 模式也需要进行 Fork 操作但是你可以设置这个操作进行的频率\n\n### AOF 模式\n\n#### AOF 模式的优点\n\n- 使用 AOF 模式可以保证更高的数据安全性\n- redis 提供了 3 种同步策略:每秒同步/每次修改同步/不同步\n- 每秒同步操作也是异步完成的，效率也很高，如果 redis 服务出现宕机，只会丢失 1 秒内的数据\n- 每次修改同步即每次修改操作都会被同步，所以效率是最低的\n- AOF 是以追加方式写入文件，在宕机时不会导致文件数据的损坏，即使一条指令只写入了一半，我们也可以利用 redis-check-aof 工具对其进行修复\n- 在 AOF 文件过大时，redis 可以自动启用重写机制，redis 会创建一个老文件的最小集合，然后等新的文件创建完成之后交换两个文件开始对新的文件进行追加写入\n- AOF 包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作\n\n#### AOF 模式的缺点\n\n- 对于相同的数据集，AOF 文件通常要大过 RDB 文件，RDB 文件在重启时恢复速度要快过 AOF 文件\n- 根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB。总之，每秒同步策略的效率是比较高的，不追加的效率和 RDB 模式一样高效\n\n### 常用配置\n\n#### RDB 模配置\n\nRedis 会将数据集的快照 dump 到 dump.rdb 文件中。我们也可以通过配置文件来修改 Redis 服务器 dump 快照的频率，在打开 6379.conf 文件之后，我们搜索 save，可以看到下面的配置信息：\n\n- save 900 1 #在 900 秒(15 分钟)之后，如果至少有 1 个 key 发生变化，则 dump 内存快照\n- save 300 10 #在 300 秒(5 分钟)之后，如果至少有 10 个 key 发生变化，则 dump 内存快照\n- save 60 10000 #在 60 秒(1 分钟)之后，如果至少有 10000 个 key 发生变化，则 dump 内存快照\n\n#### AOF 持久化配置\n\n在 Redis 的配置文件中存在三种同步方式，它们分别是：\n\n- appendfsync always #每次有数据修改发生时都会写入 AOF 文件\n- appendfsync everysec #每秒钟同步一次，该策略为 AOF 的缺省策略\n- appendfsync no #从不同步。高效但是数据持久化完全依赖操作系统的策略\n","tags":["redis"]},{"title":"使用nacos配置中心功能","url":"/article/24f85607.html","content":"\n开始学习使用 spring-cloud-alibaba\n\n### 使用 nacos 配置中心功能\n\n1.创建一个 spring-cloud-alibaba 模块，添加以下依赖\n\n```xml\n<!--nacos配置中心-->\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>\n</dependency>\n```\n\n2.创建测试 controller\n\n```java\n@RestController\n@RefreshScope\npublic class ConfigController {\n    @Value(\"${useLocalCache:false}\")\n    private boolean useLocalCache;\n\n    @GetMapping(\"/get\")\n    public boolean get() {\n        return useLocalCache;\n    }\n}\n```\n\n3.添加配置文件\n\nbootstarp.yml\n\n```yml\nspring:\n  application:\n    name: coco-web\n  profiles:\n    active: dev\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 192.168.70.1:8848 #注册中心地址\n      config:\n        server-addr: 192.168.70.1:8848 # 配置中心地址\n        file-extension: yaml # 指定yaml格式的配置\nserver:\n  port: 9992\n```\n\n4.在 nacos 配置管理->配置列表中点击右侧+号新增配置\n\n![](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401133424970.png)\n\n并点击发布\n\n5.启动服务，访问接口\n\n![](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401133441929.png)\n\n6.查看配置列表，可以看见刚才发布的配置数据\n\n![](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401133458659.png)\n\n7.点击编辑，修改对应配置项的数值，点击发布\n\n![](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401133516106.png)\n\n8.再次访问接口，可以发现数值跟随 nacos 中的配置进行变更\n\n![](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401133530606.png)\n\n本文代码：<https://gitee.com/AtlsHY/coco/tree/master/coco-web>\n","tags":["nacos","spring-cloud-alibaba"]},{"title":"synchronized最好的锁对象","url":"/article/b56d6cb5.html","content":"\n之前在网上看到一个面试题目：synchronzied 最好的锁对象是什么\n\n当时第一反应是 new Object，但是后来看到这篇文章：[Object vs byte[0] as lock](https://stackoverflow.com/questions/2120437/object-vs-byte0-as-lock)\n\n大意就是 new byte[0]作为锁对象会更好，能够减少字节码操作的次数\n\n下面来验证一下\n\n```java\npublic class ObjectSynchronizedDemo {\n    private final Object obj = new Object();\n}\n\npublic class ArraySynchronizedDemo {\n    private final byte[] lockObj = new byte[0];\n}\n\n```\n\n```class\nObjectSynchronizedDemo.class\n{\n  public com.aias.learn.test.ObjectSynchronizedDemo();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=3, locals=1, args_size=1\n         0: aload_0\n         1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n         4: aload_0\n         5: new           #2                  // class java/lang/Object\n         8: dup\n         9: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n        12: putfield      #3                  // Field obj:Ljava/lang/Object;\n        15: return\n      LineNumberTable:\n        line 7: 0\n        line 8: 4\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      16     0  this   Lcom/aias/learn/test/ObjectSynchronizedDemo;\n}\n\nArraySynchronizedDemo.class\n{\n  public com.aias.learn.test.ArraySynchronizedDemo();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=1, args_size=1\n         0: aload_0\n         1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n         4: aload_0\n         5: iconst_0\n         6: newarray       byte\n         8: putfield      #2                  // Field lockObj:[B\n        11: return\n      LineNumberTable:\n        line 7: 0\n        line 8: 4\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      12     0  this   Lcom/aias/learn/test/ArraySynchronizedDemo;\n}\n\n```\n\n可以看出，new byte[0]确实比 new Object() 少 4 条字节码操作。\n\n再计算一下内存占用情况：\n\nnew Object()内存占用：\n\nMark Word(8 字节)+klass pointer(开启指针压缩，4 字节)+对齐填充(4 字节) = 16 字节\n\nnew byte[0]内存占用：\n\nMark Word(8 字节)+klass pointer(开启指针压缩，4 字节)+数组长度(int，4 字节) = 16 字节\n\n所以两种锁对象占用内存是相等的。\n","tags":["synchronized"]},{"title":"zookeeper","url":"/article/3ad834c9.html","content":"\n### zookeeper 的节点类型\n\n每个子目录项如 NameService 都被称为 znode，和文件系统一样，我们能够自由的增加、删除 znode，在一个 znode 下增加、删除子 znode，唯一不同在于 znode 是可以存储数据的\n\n![2021-04-16-14-20-4620210416142045](https://i.loli.net/2021/04/16/cTIUSliPgQGq7z1.png)\n\n有四种类型的 znode：\n\n- presistent：持久化节点，客户端与 zookeeper 断开连接之后，该节点依旧存在\n- presistent_sequential：持久有序节点：zookeeper 给该节点名称进行顺序编号的持久化节点\n- ephemeral：临时节点，客户端与 zookeeper 断开连接之后，该节点被删除\n- ephemeral_sequential：临时有序节点，zookeeper 给该节点进行顺序编号的临时节点\n\n### zookeeper znode 存储结构\n\nZnode 包含了「存储数据、访问权限、子节点引用、节点状态信息」\n\n- 「data:」 znode 存储的业务数据信息\n- 「ACL:」 记录客户端对 znode 节点的访问权限，如 IP 等。\n- 「child:」 当前节点的子节点引用\n- 「stat:」 包含 Znode 节点的状态信息，比如「事务 id、版本号、时间戳」等等。\n\n#### 每个节点的数据最大不能超过多少呢\n\n为了保证高吞吐和低延迟，以及数据的一致性，znode 只适合存储非常小的数据，不能超过 1M，最好都小于 1K。\n\n### zookeeper 的通知机制\n\n客户端注册监听它关心的目录节点，当目录节点发生变化（数据修改、被删除、子目录节点增加\\删除）时，zookeeper 会通知客户端\n\n- Zookeeper 的 Watcher 机制主要包括客户端线程、客户端 WatcherManager、Zookeeper 服务器三个部分\n- 客户端向 Zookeeper 服务器注册 Watcher 的同时，会将 Watcher 对象存储在客户端的 WatcherManager 中\n- 当 Zookeeper 服务器触发 Watcher 事件之后，会向客户端发送通知，客户端线程从 WatcherManager 中取出对应的 Watcher 对象来执行回调逻辑\n\n#### watcher 特性总结\n\n- 「一次性：」一个 watcher 事件是一个一次性的触发器。一次性触发，客户端只会收到一次这样的消息。\n- 「异步的：」Zookeeper 服务器发送 watcher 的通知事件到客户端是异步的，不能期望能够监控到节点每次的变化，Zookeeper 只能保证最终一致性，而无法保证强一致性。\n- 「轻量级：」Watcher 机制非常简单，它只是通知发生了事件，而不会传递事件对象内容。\n- 「客户端串行：」执行客户端 Watcher 回调的过程是一个串行同步的过程。\n- 注册 watcher 用 getData、exists、getChildren 方法\n- 触发 watcher 用 create、delete、setData 方法\n\n### zookeeper 能干什么\n\n#### 命名服务\n\n在 zookeeper 的文件系统里创建一个目录，即有唯一的 path\n\n#### 配置管理\n\n分布式服务将配置存储在 zookeeper 上，保存在 zookeeper 的某个目录节点中，然后所有相关应用程序对这个节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 zookeeper 的通知，然后从 zookeeper 获取新的配置信息\n\n![配置管理](https://i.loli.net/2021/04/16/NGmozsiKLDk9lyh.png)\n\n#### 集群管理\n\n检测是否有机器退出或加入，选举 master\n\n- 所有机器约定在父目录 GroupMembers 下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper 的连接断开，其所创建的临时目录节点被删除，所有其他机器收到通知：某个兄弟目录被删除；新机器加入也是类似，所有机器收到通知：新兄弟加入\n- 所有节点创建临时顺序编号目录节点，每次选取编号最小的机器作为 master\n  ![2021-04-16-14-31-5620210416143156](https://i.loli.net/2021/04/16/oP8TiLfYutzUFjd.png)\n\n#### 分布式锁\n\n#### 队列管理\n\n两种类型的队列：\n\n##### 同步队列：当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达\n\n在约定目录下创建临时目录节点，监听节点数据是否达到我们要求的数目\n\n##### 队列按照 FIFO 方式进行入队和出队操作\n\n入列有编号，出列按编号。\n\n### 分布式与数据复制\n\nzookeeper 作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处：\n\n1.容错\n\n一个节点出错，不至于让整个系统停止工作，别的节点可以接管它的工作\n\n2.提高系统的拓展能力\n\n把负载分布到多个节点上，或者增加节点来提高系统的负载能力\n\n3.提高性能\n\n让客户端本地访问就近节点，提高用户访问速度\n\n从客户端读写访问的透明度来看，数据复制集群系统分为下面两种：\n\n1.写主（WriteMaster）\n\n对数据的修改交给指定的节点。读无此限制，可以读取任意一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离。\n\n2.写任意（WriteAny）\n\n对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。\n\n对 zookeeper 来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力拓展非常好，而写，随着机器的增多吞吐能力肯定下降（这也是它建立 observer 的原因），而响应能力取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。\n\n### 数据一致性与 paxos 算法\n\n我们关注的重点还是在如何保持数据在集群所有机器的一致性，这就涉及到 paxos 算法\n\n据说 Paxos 算法的难理解与算法的知名度一样令人敬仰，所以我们先看如何保持数据一致性，这里有个原则就是：在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态\n\nPaxos 算法解决了什么问题，解决的就是保证每个节点执行相同的操作序列。master 维护一个全局写队列，所有写操作都必须放入这个队列编号，那么无论我们写多少节点，只要写操作是按照编号来的，就能保证一致性。但是如果 master 挂了呢。\n\npaxos 算法通过投票来对写操作进行全局编号，同一时刻，只有一个写操作被批准，同时并发的写操作要去争取选票，只有获得过半数选票的写操作才会被批准（所以永远只会有一个写操作得到批准），其他的写操作竞争失败只好再发起一轮投票，就这样，在日复一日年复一年的投票中，所有写操作都被严格编号排序。编号严格递增，当一个节点接收了一个编号为 100 的写操作，只有又接收到了编号为 99 的写操作（因为网络延迟等很多不可预见的原因），它马上意识到自己数据不一致了，自动停止对外服务并重启同步过程。任何一个节点挂掉都不会影响整个集群的数据一致性（总 2n+1 台，除非挂掉大于 n 台）\n\n### 角色\n\nzookeeper 中的角色主要有以下三类\n\n![2021-04-16-15-42-1420210416154213](https://i.loli.net/2021/04/16/5qAkB6IDMGdNrx2.png)\n\n### 设计目的\n\n1.最终一致性：client 不论连接到哪个 server，展示给它的都是同一个视图，这是 zookeeper 最重要的功能\n\n2.可靠性：具有简单、健壮、良好的性能，如果消息被一台服务器接受，那么它将被所有的服务器接受\n\n3.实时性：zookeeper 保证客户端将在一个时间间隔内获得服务器的更新信息，或者服务器失效的信息。但由于网络延迟等原因，zookeeper 不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用 sync()接口\n\n4.等待无关（wait-free）：慢的或者失效的 client 不得干预快速的 client 请求，使得每个 client 都能有效的等待\n\n5.原子性：更新只能成功或者失败，没有中间状态\n\n6.顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息 a 在消息 b 前发布，则在所有 server 上消息 a 都将在消息 b 之前被发布；偏序是指如果一个消息 b 在消息 a 后被同一个发布者发布，a 必将排在 b 之前\n\n### zookeeper 的工作原理\n\nzookeeper 的核心是原子广播，这个机制保证了各个 server 之间的同步。实现这个机制的协议叫做 zab 协议。zab 协议有两种模式，分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，zab 就进入了恢复协议，当领导者被选举出来，且大多数 server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 server 和 leader 具有相同的系统状态\n\n为了保证事务的顺序一致性，zookeeper 采用了递增的事务 id 号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了 zxid。实现中的 zxid 是一个 64 位的数字，它高 32 位是 epoch 用来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch，标识当前属于哪个 leader 的统治时期。低 32 位用于递增计数\n\n每个 server 在工作过程中有三种状态：\n\n- looking：当前 server 不知道 leader 是谁，正在搜寻\n- leading：当前 server 即为选举出来的 leader\n- following：leader 已经选出来，当前 server 与之同步\n\n### zookeeper 选主流程\n\n当 leader 崩溃或者 leader 失去大多数 follower，这时候 zk 进入恢复模式，恢复模式需要重新选举出另外一个新的 leader，让所有的 server 都恢复到一个正常的状态。\n\nzk 的选举算法有两种：一种是基于 basic paxos 实现的，另一种是基于 fast paxos 实现的。系统默认的选举算法是 fast paxos。\n\n#### basic paxos 流程\n\n1.选举线程由当前 server 发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的 server\n\n2.选举线程首先向所有的 server 发起一次询问（包括自己）\n\n3.选举线程收到回复后，验证是否是自己发起的询问（验证 zxid 是否一致），然后获取对方的 id（myid），并存储到当前询问对象列表中，最后获取对方提议的 leader 相关信息（id，zxid），并将这些信息存储到当次选举的投票记录中\n\n4.收到所有 server 回复后，就计算出 zxid 最大的那个 server，并将这个 server 相关信息设置成下一次要投票的 server\n\n5.线程将当前 zxid 最大的 server 设置为当前 server 要推荐的 leader，如果此时获胜的 server 获得 n/2+1 个 server 的票数，设置当前推荐的 leader 为获胜的 server，将根据获胜的 server 相关信息设置自己的状态，否则，继续这个过程，直到 leader 被选举出来。\n\n通过流程分析我们可以得出：要使 leader 获得多数 server 的支持，则 server 总数必须是奇数 2n+1，且存活的 server 数目不得少于 n+1\n\n每个 server 启动以后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的 server 还会从磁盘快照中恢复数据和会话信息，zk 会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。流程图：\n\n![basic paxos 流程](https://i.loli.net/2021/04/17/oUksNZ2Bq6t3uze.png)\n\n#### fast paxos 流程\n\nfast paxos 流程是在选举过程中，某 server 首先向所有 server 提议自己要称为 leader，当其他 server 收到提议以后，解决 epoch 和 zxid 的冲突，并接受对方的提议，然后向对方发送接收提议完成的消息，重复这个流程，最后一定能选举出 leader。流程图：\n\n### zookeeper 同步流程\n\n选完 Leader 以后，zk 就进入状态同步过程\n\n1.leader 等待 server 连接\n\n2.follower 连接 Leader，将最大的 zxid 发送给 leader\n\n3.leader 根据 follower 的 zxid 确定同步点\n\n4.完成同步后通知 follower 已经成为 uptodate 状态\n\n5.follower 收到 uptodate 消息后，又可以重新接受 client 的请求\n\n流程图如下所示：\n\n![同步流程](https://i.loli.net/2021/04/17/B8YxNRLMKkIChjl.png)\n\n### zookeeper 工作流程\n\n#### leader 工作流程\n\nleader 主要有三个功能：\n\n1.恢复数据\n\n2.维持与 learner 的心跳，接收 leader 请求并判断 leader 的请求消息类型\n\n3.learner 的消息类型主要有 ping 消息、request 消息、ack 消息、revalidate 消息，根据不同的消息类型，进行不同的处理\n\nping 消息是指 learner 的心跳消息；request 消息是 follower 发送的提议消息，包括写请求以及同步请求；ack 消息是 follower 的对提议的回复，超过半数的 follower 通过，则 commit 该提议；revaildate 消息是用来延长 session 有效时间\n\nleader 的工作流程简图如下，在实际实现中，流程要比下图复杂的多，启动了三个线程来实现功能：\n\n#### follower 工作流程\n\nfollower 主要有四个功能：\n\n1.向 leader 发送请求（ping 消息、request 消息、ack 消息、revalidate 消息）\n\n2.接收 leader 消息并进行处理\n\n3.接收 client 请求，如果为写请求，发送给 leader 进行投票\n\n4.返回 client 结果\n\nfollower 的消息循环处理如下几种来自 leader 的消息：\n\n1.ping 消息：心跳消息\n\n2.proposal 消息：leader 发起的提案，要求 follower 投票\n\n3.commit 消息：服务器端最新一次提案的信息\n\n4.uptodate 消息：表明同步完成\n\n5.revalidate 消息：根据 leader 的 revalidate 结果，关闭待 revalidate 的 session 还是允许其接受消息\n\n6.sync 消息：返回 sync 结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新\n\nfollower 的工作流程简图如下，在实际实现中，是通过 5 个线程来实现功能的：\n\n#### observer 工作流程\n\n对于 observer 的流程不再赘述，observer 流程和 follower 唯一的不同就是 observer 不会参加 leader 发起的投票\n\n### Zookeeper 保证了哪些特性\n\n- 「顺序一致性」：从同一客户端发起的事务请求，最终会严格的按照顺序被应用到 Zookeeper 中去\n- 「原子性」：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一事务，要么都没有应用\n- 「单一视图」：无论客户端连接到哪一个 Zookeeper 服务器上，其看到的服务端数据模型都是一致的\n- 「可靠性」：一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来\n- 「实时性（最终一致性）」：Zookeeper 仅能保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。\n","tags":["zookeeper"]},{"title":"redis性能优化","url":"/article/201b20ca.html","content":"\nredis 利用了 IO 多路复用机制，处理客户端请求时，不会阻塞主线程。redis 单纯执行指令时（大多数指令），一个指令不到 1 微秒，如此，单核 CPU1 秒就能处理一百万个指令（大概对应几十万个请求），单线程不会成为 redis 的性能瓶颈，网络才是瓶颈\n\n### 优化网络延时\n\n首先如果使用单机部署（应用服务和 redis 在同一台机器上）的话，使用 Unix 进程间通讯来请求 redis 服务，速度比 localhost 局域网（学名：loopback）更快。\n\n但是很多公司的业务规模不是单机部署能够支撑的，所以还是得用 TCP。\n\nredis 客户端和服务器的通讯一般使用 TCP 长连接。如果客户端发送请求后需要等待 redis 返回结果再发送下一条指令，客户端和 redis 的多个请求就如下图：\n\n![2021-04-13-17-17-4020210413171739](https://i.loli.net/2021/04/13/nY7z1mQFTS5AXcj.png)\n\n（备注：如果要发送的 key 不是特别长，一个 TCP 包完全能放的下 redis 指令，所以只画了一个 push 包）\n\n这样两次请求中，客户端都要经历一段网络传输时间\n\n#### 合并请求\n\n但如果有可能，完全可以使用 **multi-key** 类的指令来合并请求，比如两个 GET key 可以用 MGET key1 key2 合并。这样在实际通讯中，请求次数也减少了，延时自然减少了\n\n如果不能用 multi-key 指令来合并，比如一个 SET，一个 GET，无法合并，还有以下解决办法：\n\n- MULTI/EXEC\n\n构建事务，可以合并多个指令为一个 request，通讯过程如下：\n\n![2021-04-13-17-26-1620210413172616](https://i.loli.net/2021/04/13/wqOlXuDyJpZ5gvE.png)\n\n- script\n\n最好利用缓存脚本的 **sha1 hash key** 来调起脚本，这样通讯量更小\n\n以上两种解决方案要求这个 **transaction/script** 中涉及的 key 在同一个 node 上，所以要酌情考虑\n\n#### 合并 response\n\n如果没有办法合并多个请求，还可以考虑合并多个 responses，比如把两个回复信息合并：\n\n![2021-04-13-17-33-3220210413173331](https://i.loli.net/2021/04/13/jpeSKcwoFd4yGnQ.png)\n\n这样，理论上可以省去一次回复所用的网络传输时间，这就是 **pipeline** 的功能\n\n不是任意多个回复信息都可以放进一个 TCP 包中，如果请求数太多，回复的数据很长（比如 get 一个长字符串），TCP 还是会分包传输，但是使用 pipeline，依然可以减少传输次数\n\npipeline 和上面其他的方法都不一样的是，它不具有原子性。所以在 cluster 状态下的集群，pipeline 更容易实现\n\n#### 小结\n\n1. 使用 unix 进程间通信，如果单机部署\n2. 使用 multi-key 指令合并多个指令，减少请求数\n3. 使用 transaction、script 合并 requests 以及 responses\n4. 使用 pipeline 合并 response\n\n### 警惕执行时间长的操作\n\n在大数据量的情况下，有些操作执行的时间会相对长，比如 KEYS \\*，LRANGE list 0 -1，以及其他算法时间复杂度为 O(N)的指令。因为 redis 只用一个线程来做数据查询，如果这些指令执行时间很长，就会阻塞 redis，造成大量延时\n\nredis 中 transaction、script 等因为可以合并多个 commands 为一个具有原子性的执行过程，所以也可能占用 redis 很长时间\n\n如果想找出生产环境使用的\"慢指令\"，可以利用 SLOWLOG GET 5 来查看最近的 5 个执行时间很长的指令。至于多长算长，可以通过在 redis.conf 中设置 slowlog-log-slower-than 来定义\n\n```shell\n# Redis has two primitives to delete keys. One is called DEL and is a blocking\n# deletion of the object. It means that the server stops processing new commands\n# in order to reclaim all the memory associated with an object in a synchronous\n# way. If the key deleted is associated with a small object, the time needed\n# in order to execute the DEL command is very small and comparable to most other\n# O(1) or O(log_N) commands in Redis. However if the key is associated with an\n# aggregated value containing millions of elements, the server can block for\n# a long time (even seconds) in order to complete the operation.\n#\n# For the above reasons Redis also offers non blocking deletion primitives\n# such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and\n# FLUSHDB commands, in order to reclaim memory in background. Those commands\n# are executed in constant time. Another thread will incrementally free the\n# object in the background as fast as possible.\n```\n\ndel 一个大的 object 的时候，回收相应的内存可能会需要很长时间（甚至几秒），所以建议用 del 的异步版本：UNLINK。后者会启动一个新的 thread 来删除目标 key，而不阻塞原来的线程\n\n当一个 Key 过期后，redis 一般也需要同步地将它删除。其中一种删除 key 的方式是：每 10 秒检查一次有设置过期时间的 Key，这些 key 存储在一个全局的 struct 中，可以用 server.db->expires 访问。检查的方式是：\n\n- 从中随机取出 20 个 key\n- 把过期的删掉\n- 如果刚刚的 20 个 key 中，有 25%以上（也就是 5 个以上）都是过期的，redis 认为，过期的 key 还挺多的，继续重复步骤 1，直到满足退出条件：某次取出的 key 中没有那么多过期的 key\n\n这里对于性能的影响是，如果真的有很多 key 在同一时间过期，那么 redis 会一直循环执行删除，占用主线程\n\n对此，redis 作者的建议是警惕 EXPIREAT 这个指令，因为它更容易产生 key 同时过期的现象。还有一些建议是给 key 的过期时间设置一个随机波动量。最后，redis.conf 中也给出了一个方法，把 keys 的过期删除操作变为异步，即在 redis.conf 中设置 lazyfree-lazy-expire yes\n\n### 优化数据结构、使用正确的算法\n\n一种数据类型（比如 string、list）进行增删改查的效率是由其底层的存储结构决定的\n\n我们在使用一种数据类型时，可以适当关注一下它底层的存储结构及其算法，避免使用复杂度太高的方法。举个例子：\n\n- ZADD 的时间复杂度是 O(log(N))，这比其他数据类型增加一个新的元素的操作更复杂，所以要小心使用\n- 若 Hash 类型的值的 fields 数量有限，它很可能采用 zipList 这种结构做存储，而 zipList 的查询效率可能没有同等字段数量的 hashTable 效率高，在必要时，可以调整 redis 的存储结构\n\n除了时间性能上的考虑，有时候我们还需要节省空间。比如上面提到的 ziplist 结构，就比 hashtable 结构节省空间。但节省空间的数据结构，其算法的复杂度可能很高。所以这里就需要在具体问题面前做出权衡。\n\n### 考虑操作系统和硬件是否影响性能\n\nredis 运行的外部环境，也就是操作系统和硬件显然也会影响 redis 的性能\n\n- CPU：intel 多种 cpu 都比 AMD 皓龙系列好\n- 虚拟化：实体机比虚拟机好，主要是因为部分虚拟机上，硬盘不是本地硬盘，监控软件导致 fork 指令的速度慢（持久化时会用到 fork），尤其是用 Xen 来做虚拟化时\n- 内存管理：在 linux 操作系统中，为了让 translation lookaside buffer 即 TLB，能够管理更多内存空间（TLB 只能缓存有限个 page），操作系统把一些 memory page 变得更大，比如 2MB 或者 1GB，而不是通常的 4096 字节，这些大的内存页叫做 huge pages。同时为了方便程序员使用这些大的 page，操作系统中实现了一个 transparent huge pages（THP）机制，使得大内存页对他们来说是透明的，可以像使用正常的内存 page 一样使用他们。但这种机制并不是数据库所需要的，可能是因为 THP 会把内存空间变得紧凑而连续，而数据库需要的是稀疏的内存空间，所以请禁用掉 THP 功能。redis 也不例外，但 redis 官方博客上给出的理由是：使用大内存 page 会使 bgsave 时，fork 的速度变慢；如果 fork 之后，这些内存 page 在原进程中被修改了，他们就需要被复制（即 copy on write），这样的复制会消耗大量的内存，所以请禁止掉操作系统中的 transparent huge page 功能\n- 交换空间：当一些内存 page 被存储在交换空间文件上，而 redis 又要请求那些数据，那么操作系统会阻塞 redis 进程，然后把想要的 page 从交换空间中拿出来，放进内存。这其中涉及整个内存的阻塞，所以可能会造成延时问题，一个解决方法是禁用交换空间\n\n### 考虑持久化带来的开销\n\nredis 的一项重要功能就是持久化，也就是把数据复制到硬盘上。基于持久化，才有了 redis 的数据恢复等功能\n\n但是维护持久化这个功能，也是有性能开销的\n\n#### RDB 全量持久化\n\n这种持久化方式把 redis 中的全量数据打包成 rdb 文件放在硬盘上。但是执行 rdb 持久化的过程是原进程 fork 出来一个子进程，而 fork 这个系统调用是需要时间的，而这段时间内，redis 是无法相应请求的\n\n为此，要使用合理的 rdb 持久化的时间间隔，不要太频繁\n\n#### AOF 增量持久化\n\n这种持久化方式会把发到 redis server 的指令以文本的形式保存下来（格式遵循 redis protocol），这个过程中，会调用两个系统调用，一个是 write(2)，同步完成，一个是 fsync(2)，异步完成。\n\n这两步都可能是延时问题的原因：\n\n- write 可能会因为输出的 buffer 满了，或者 kernal 正在把 buffer 中的数据同步到硬盘，就被阻塞了\n- fsync 的作用是确保 write 写入到 aof 文件的数据落到了硬盘上，在一个 7200 转/分的硬盘上可能要延时 20ms，消耗还是挺大的。更重要的是在 fsync 进行的时候，write 可能会被阻塞\n\n其中，write 的阻塞貌似只能接受，因为没有更好的方法把 buffer 中的数据写入到一个文件中了。但对于 fsync，redis 允许三种配置，选用哪种取决于对备份及时性和性能的平衡。\n\n- always：当把 appendfsync 设置为 always，fsync 会和客户端的指令同步执行，因此可能造成延时问题，但备份及时性最好\n- everysec：每秒钟异步执行一次 fsync，此时 redis 的性能表现会更好，但是 fsync 依然可能阻塞 write，算是一个折中选择。\n- no：redis 不会主动触发 fsync（并不是永远不 fsync），而是由 kernal 决定何时 fsync\n\n### 使用分布式架构，读写分离，数据分片\n\n首先说，哪些情况下不得不（或者说最好）使用分布式架构\n\n1.数据量很大，单台服务器内存装不下，\n\n2.需要服务高可用\n\n3.单台请求的压力过大\n\n解决这些问题可以采用数据分片或者主从分离，或者两者都用（即，在分片用的 cluster 节点上，也设置主从结构）\n\n这样的架构，可以为性能提升加入新的切入点：\n\n- 把慢速的指令发送到某些从库上执行\n- 把持久化功能放到一个很少使用的从库上\n- 把某些大 list 分片\n\n其中前两条都是根据 redis 单线程的特性，用其他进程（甚至机器）做性能补充的方法\n\n当然，使用分布式架构，也可能对性能有影响，比如请求需要被转发、数据需要不断被复制分发等\n","tags":["redis"]},{"title":"cas","url":"/article/3ad60b.html","content":"\nCAS 全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent 包中的原子类就是通过 CAS 来实现的\n\nCAS 算法涉及到 3 个操作数：\n\n- 需要读写的内存值 V\n- 进行比较的值 A\n- 要写入的新值 B\n\n当且仅当 V 的值等于 A 时，CAS 通过原子方式用新值 B 来更新 V 的值（\"比较\"+\"更新\"，整体是一个原子操作），否则不会执行任何操作。一般情况下，\"更新\"是一个不断重试的操作\n\nAtomicInteger 源码：\n\n![2021-04-12-15-24-1120210412152410](https://i.loli.net/2021/04/12/DfLJnte9r8AS7wV.png)\n\n根据定义我们可以看出各属性的作用：\n\n- unsafe：获取并操作内存的数据\n- valueOffset：存储 value 在 AtomicInteger 中的偏移量\n- value：存储 AtomicInteger 的 int 值，该属性需要借助 volatile 关键字保证其在线程间是可见的\n\n接下来查看 AtomicInteger 的自增函数 incrementAndGet()的源码，发现自增函数底层调用的是 unsafe.getAndAddInt()。但是由于 JDK 本身只有 Unsafe.class，只通过 class 文件中的参数名，并不能很好的了解方法的作用，所以通过 OpenJDK8 来查看 Unsafe 的源码\n\n```java\n// ------------------------- JDK 8 -------------------------\n// AtomicInteger 自增方法\npublic final int incrementAndGet() {\n  return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\n}\n\n// Unsafe.class\npublic final int getAndAddInt(Object var1, long var2, int var4) {\n  int var5;\n  do {\n      var5 = this.getIntVolatile(var1, var2);\n  } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));\n  return var5;\n}\n\n// ------------------------- OpenJDK 8 -------------------------\n// Unsafe.java\npublic final int getAndAddInt(Object o, long offset, int delta) {\n   int v;\n   do {\n       v = getIntVolatile(o, offset);\n   } while (!compareAndSwapInt(o, offset, v, v + delta));\n   return v;\n}\n```\n\n根据 OpenJDK8 的源码我们可以看出，getAndAddInt 循环获取给定对象 o 中的偏移量处的值 v，然后判断内存值是否等于 v。如果相等则将内存值设为 v+delta，否则返回 false，继续循环进行重试，直到设置成功才能退出循环，并将旧值返回。整个\"比较+更新\"操作封装在 compareAndSwapInt()中，在 JNI 里是借助一个 CPU 指令完成的，属于原子操作，可以保证多个线程都能看到同一个变量的修改值。\n\n后续 JDK 通过 CPU 的 cmpxchg 指令，去比较寄存器中的 A 和内存中的值 V。如果相等，就把要写入的新值 B 存入内存中。如果不相等，就将内存值 V 赋值给寄存器中的值 A，然后通过 java 代码中的 while 循环再次调用 cmpxchg 指令进行重试，直到设置成功为止\n\nCAS 虽然很高效，但是也存在三大问题：\n\n- ABA 问题：CAS 需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是 A，后来变成了 B，然后又变成了 A，那么 CAS 进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA 问题的解决思路就是在变量前面加版本号，每次变量更新的时候都把版本号+1，这样变化过程就从\"A-B-A\"变成了\"1A-2B-3A\"。\n  - JDK 从 1.5 版本开始提供了 AtomicStampedReference 类来解决 ABA 问题，具体操作封装在 compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值\n- 循环时间长开销大：CAS 操作如果长时间不成功，会导致其一直自旋，给 CPU 带来很大负担\n- 只能保证一个共享变量的原子操作：对一个共享变量执行操作时，CAS 能够保证原子操作，但是对多个共享变量操作时，CAS 是无法保证操作的原子性的\n  - java 从 1.5 版本开始提供了 AtomicReference 类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行 CAS 操作\n\n### 问题\n\n1.假设有多个线程同时在对同一块内存进行 CAS 操作的话：两个线程 T1、T2 同时执行，V 存储同一块内存地址，A 当然也是旧的预期值，那么这种情况下 T1 和 T2 是否都可以更新成功\n\n在多个线程同时 CAS 的情况下是不会发生多个线程 CAS 成功的情况的，因为计算机底层实现保证了 V 指向内存的互斥性和立即可见性，可以理解为 CAS 操作是底层保证的线程安全\n\n一个线程 T 在 CAS 操作时，其他线程无法访问 V 指向的内存地址，并且一旦 T 更新了 V 指向内存的值，其他所有线程的 V 指向内存都变得无效\n\n- 处理器实现原子操作有两种做法\n  - 一是总线锁：在多 CPU 下，当其中一个处理器要对共享内存进行操作的时候，在总线上发出一个 LOCK#信号，这个信号使得其他处理器无法通过总线来访问到共享内存中的数据\n  - 二是缓存锁：如果共享内存已经被缓存，那么锁总线没有意义。缓存锁核心是使用了缓存一致性协议，如 MESI 协议\n    - MESI 表示缓存行的四种状态\n      - M(Modify)：表示共享数据只缓存在当前 CPU 缓存中，并且是被修改状态，也就是缓存的数据和主内存的数据不一致\n      - E(Exclusive)：表示缓存的独占状态，数据只缓存在当前 CPU 缓存中，并且没有被修改\n      - S(Shared)：表示数据可能被多个 CPU 缓存，并且各个缓存中的数据和主内存数据一致\n      - I(Invalid)：表示缓存已经失效\n    - 在 MESI 协议中，每个缓存的缓存控制器不仅知道自己的读写操作，而且也嗅探(snoop)其他 cache 的读写操作\n    - CPU 在读数据时，如果缓存行状态是 I，则需要从主内存中取出，并把缓存行状态置为 S；如果不是 I，则可以直接读取缓存中的值，但在此之前必须要等待对其他 CPU 的监听结果，如果其他 CPU 也有该数据的缓存并且状态是 M，则需要等待其把缓存更新到主内存后再读取\n    - CPU 可以将状态为 M/E/S 的缓存写入内存，其中如果缓存行状态为 S，则其他 CPU 缓存了相同数据的缓存行会无效化\n","tags":["cas"]},{"title":"mq专题","url":"/article/a292cba5.html","content":"\n### MQ 的本质\n\nMQ 本质都是[一发一存一消费]\n\n生产者先将消息投递到一个叫做[队列]的容器中，队列存储消息之后，再转发给消费者\n\n![2021-04-07-22-22-1420210407222213](https://i.loli.net/2021/04/07/oVDlHdXeW3uITpv.png)\n\n上面这个图便是消息队列最原始的模型，它包含了两个关键词：队列和消息\n\n- 消息：就是要传输的数据，可以是最简单的文本字符串，也可以是自定义的复杂格式（只要能按照预定的格式解析出来）\n\n- 队列：先进先出的数据结构。它是存放消息的容器，消息从队尾入队，从队首出队，入队即发消息的过程，出队即消费消息的过程\n\n### 原始模型的进化\n\n现在流行的消息队列都在原始的模型上做了拓展，同时提出了一些新名词，比如：主题（Topic）、分区（partition）等\n\n#### 队列模型\n\n最初的消息队列就是原始模型，它是一个严格意义上的队列（Queue）。消息按照什么顺序写进去，就按照什么顺序读出来。不过，队列没有“读”这个操作，读就是出队，从队首删除消息\n\n![2021-04-07-22-33-0720210407223307](https://i.loli.net/2021/04/07/6dXV3Wi89Nymg2E.png)\n\n这便是队列模型：它允许多个生产者往同一个队列发送消息。但是如果有多个消费者，实际上是竞争关系，也就是一条消息只能被一个消费者收到，读完即删除。\n\n#### 发布-订阅模型\n\n如果需要将一份消息数据发送给多个消费者，并且每个消费者都要求接收到全量的数据。很显然队列模型无法满足这个需求\n\n一个可行的方案是：为每个消费者创建一个单独的队列，让生产者发送多份。这种做法比较笨，而且同一份数据被复制多份，也很浪费空间\n\n为了解决这个问题，就演化出另外一种消息模型：发布-订阅模型\n\n![2021-04-07-22-43-0420210407224303](https://i.loli.net/2021/04/07/LQD4ocayKUht563.png)\n\n在发布-订阅模型中，存放消息的容器变成了“主题”，订阅者在接收消息之前需要先“订阅主题”。最终，每个订阅者都可以接收到同一个主题的全量消息\n\n仔细对比下它和“队列模型”的异同：生产者就是发布者，队列就是主题，消费者就是订阅者，无本质区别。唯一的不同点在于：一份消息数据是否可以被多次消费\n\n#### 小结\n\n上面两种模型就是“单播和广播的区别”。而且，当发布-订阅模型中只有一个订阅者时，它和队列模型就一样了。因此在功能上是完全兼容队列模型的\n\n这也解释了为什么现在主流的消息中间件如 RocketMq、Kafka 都是直接基于发布-订阅模型实现的。此外，RabbitMQ 中之所以有一个 Exchange 模块，其实也是为了解决消息的投递问题，可以变相实现发布-订阅模型\n\n包括大家接触到的“消费组”、“集群消费”、“广播消费”这些概念，都和上面这两种模型相关，以及在应用层面大家最常见的情形：组间广播、组内单播，也属于此范畴\n\n### 透过模型看 MQ 的应用场景\n\n目前，MQ 的应用场景非常多：系统解耦、异步通信、流量削峰、延迟通知、最终一致性保证、顺序消息和流式处理等\n\nMQ 消息模型的适配性很广\n\nMQ 消费模型主要解决的是：生产者和消费者的通信问题\n\n![2021-04-08-11-28-3220210408112832](https://i.loli.net/2021/04/08/BzIrxPsRhYbSkTl.png)\n\n通过对比，能够很明显地看出两点差异：\n\n- 1.引入 MQ 后，由之前的 1 次 RPC 变成了现在的 2 次 RPC，而且生产者只跟队列耦合，它根本无需知道消费者的存在\n\n- 2.多了一个中间节点[队列]进行消息存储，相当于同步变成了异步\n\n再反过来思考 MQ 的应用场景，就不难理解为什么 MQ 适用了。因为这些场景无外乎都应用到了上面的两个特性\n\n举个例子：比如说电商业务中最常见的[订单支付]场景，在订单支付成功后，需要更新订单状态、更新用户积分、通知商家有新订单、更新推荐系统中的用户画像等\n\n![2021-04-08-11-44-1720210408114417](https://i.loli.net/2021/04/08/aSAMLNyB5QdsKY2.png)\n\n引入 MQ 之后，订单系统现在只需要关注它最关心的流程：更新订单状态，即可。其他事情全部交给 MQ 来通知。这便是 MQ 解决的最核心的问题：系统解耦\n\n改造前订单系统依赖 3 个外部系统，改造后仅仅依赖 MQ，而且后续业务再拓展（比如：营销系统打算针对支付用户奖励优惠券），也不涉及订单系统的改动，从而保证了核心流程的稳定性，降低了维护成本\n\n这个改造还带来另外一个好处：因为 MQ 的引入，更新用户积分、通知商家、更新用户画像这些步骤全部变成了异步执行，能减少订单支付的整体耗时，提升订单系统的吞吐量。这便是 MQ 的另外一个典型应用场景：异步通信\n\n初次之外，由于队列能转储消息，对于超出系统承载能力的场景，可以用 MQ 作为“漏斗”进行限流保护，即所谓的流量削峰\n\n我们还可以用队列本身的顺序性，来满足消息必须按顺序投递的需求。利用队列+定时任务来实现消息的延时消费等\n\n### 如何设计一个 MQ\n\n#### 1.MQ 的雏形\n\n如果只是实现一个很粗糙的 MQ，不考虑生产环境的要求，应该如何设计呢？\n\nMQ 最核心的功能需求：一发一存一消费。另外从技术维度来看 MQ 的通信模型，可以理解成：两次 RPC+消息转储\n\n- 1.直接利用成熟的 RPC 框架（dubbo 或者 Thrift），实现两个接口：发消息和读消息\n\n- 2.消息放在本地内存即可。数据结构可以用 JDK 自带的 ArrayBlockingQueue\n\n#### 2.写一个适用于生产环境的 MQ\n\n##### 1.关键点\n\n假如我们还是只考虑最基础的功能：发消息、存消息、消费消息（支持发布-订阅模式）\n\n那么在生产环境中，这些基础功能将会面临以下问题：\n\n- 1.高并发场景下，如何保证收发消息的性能\n- 2.如何保证消息服务的高可用和高可靠\n- 3.如何保证服务是可以水平任意拓展的\n- 4.如何保证消息存储也是水平可拓展的\n- 5.各种元数据（比如集群中的各个节点、主题、消费关系等）如何管理，需不需要考虑数据的一致性\n\n可见，如何解决高并发场景下满足高性能、高可靠等非功能性需求，才是这个问题的关键所在\n\n##### 2.整体设计思路\n\n整体架构会涉及三类角色：\n\n![2021-04-08-13-24-2920210408132428](https://i.loli.net/2021/04/08/YZrMJSkuVAW4qCw.png)\n\n另外，将[一发一存一消费]这个核心流程进一步细化后，比较完整的数据流如下：\n\n![2021-04-08-13-31-1620210408133116](https://i.loli.net/2021/04/08/AbdpysgSX3xv175.png)\n\n基于上面两个图，我们可以很快明确出 3 类角色的作用，分别如下：\n\n- 1.Broker（服务端）：MQ 中最核心的部分，是 MQ 的服务端，核心逻辑几乎全在这里，它为生产者和消费者提供 RPC 接口，负责消息的存储、备份和删除，以及维护消费关系等\n\n- 2.Producer（生产者）：MQ 的客户端之一，调用 Broker 提供给的 RPC 接口发送消息\n\n- 3.Consumer（消费者）：MQ 的另外一个客户端，调用 Broker 提供的 RPC 接口接收消息，同时完成消息确认\n\n##### 3.详细设计\n\n再展开讨论下一些具体的技术难点和可行的解决方案\n\n###### 难点 1：RPC 通信\n\n解决的是 Broker 与 Producer 以及 Consumer 之间的通信问题。如果不重复造轮子，直接利用成熟的 RPC 框架如 dubbo、Thrift 实现即可，这样不需要考虑服务注册与发现、负载均衡、通信协议、序列化方式等一系列问题\n\n当然，也可以基于 Netty 来做底层通信，用 Zookeeper、Eureka 等来做注册中心，然后自定义一套新的通信协议（类似 kafka）。也可以基于 AMQP 这种标准化的 MQ 协议来做实现（类似 RabbitMQ）。对比直接用 RPC 框架，这种方案的定制化能力和优化空间更大\n\n###### 难点 2：高可用设计\n\n高可用主要涉及两个方面：Broker 服务的高可用、存储方案的高可用\n\nBroker 服务的高可用，只需要保证 Broker 可水平拓展及逆行集群部署即可。进一步通过服务自动注册与发现、负载均衡、超时重试机制、发送和消费时的 ack 机制来保证\n\n存储方案的高可用有两个思路：\n\n1. 参考 kafka 的分区+多副本模式，但是需要考虑分布式场景下数据复制和一致性方案（类似 ZAB、Raft 等协议），并实现自动故障转移\n\n2. 还可以用主流的 DB、分布式文件系统、带持久化能力的 KV 系统，他们都有自己的高可用方案\n\n###### 难点 3：存储设计\n\n消息的存储方案是 MQ 的核心部分。可靠性保证已经在高可用设计中谈过了，可靠性要求不高的话直接用内存或者分布式缓存也可以。这里重点说一下存储的高性能如何保证，这个问题的决定因素在于存储结构的设计\n\n目前主流的方案是：追加写日志文件（数据部分）+索引文件的方式（很多主流的开源 MQ 都是这种方式）。索引设计上可以考虑稠密索引或者稀疏索引，查找消息可以利用跳跃表、二分查找等，还可以通过操作系统的页缓存、零拷贝等技术来提升磁盘文件的读写性能\n\n如果不追求很高的性能，也可以考虑线程的分布式文件系统、KV 存储或者数据库方案\n\n###### 难点 4：消费关系管理\n\n为了支持发布-订阅的广播模式，Broker 需要知道每个主题都有哪些 Consumer 订阅了，基于这个关系进行消息投递\n\n由于 Broker 是集群部署的，所以消费关系通常维护在公共存储上，可以基于 zookeeper、apollo 等配置中心来管理以及进行变更通知\n\n###### 难点 5：高性能设计\n\n存储的高性能已经谈过了，当然还可以从其他方面进一步优化性能\n\n比如 Reactor 网络 IO 模型、业务线程池的设计、生产端的批量发送、Broker 端的异步刷盘、消费端的批量拉取等\n\n##### 4.小结\n\n要回答好如何设计一个 MQ\n\n1. 需要从功能性需求（收发消息）和非功能性需求（高性能、高可用、高拓展等）两方面入手\n\n2. 功能性需求不是重点，能覆盖 MQ 最基础的功能即可，至于延时消息、事务消息、重试队列等高级特性只是锦上添花的东西\n\n3. 最核心的是：能结和功能性需求，理清楚整体的数据流，然后顺着这个思路取考虑非功能性的诉求如何满足，这才是技术难点所在\n\n### 消息队列的非幂等问题\n\n#### 幂等性概念\n\n所谓幂等性就是无论多少次操作都和第一次的操作结果一样。如果消息被多次消费，很有可能造成数据的不一致。而如果消息不可避免地被消费多次，如果我们开发人员能通过技术手段保证数据的前后一致性，那也是可以接接受的\n\n#### 场景分析\n\nRabbitMQ、RocketMQ、Kafka 等消息中间件都有可能出现消息重复消费的问题。这种问题并不是 MQ 自己保证的，而是需要开发人员来保证\n\n这几款消息队列都考虑了消息的幂等性，以 Kafka 为例：\n\nKafka 有一个**偏移量**的概念，代表着消息的序号，每条消息写道消息队列都会有一个偏移量，消费者消费了数据之后，每过一段固定的时间，就会把消费过的消息的偏移量提交以下，表示已经消费过了，下次消费就从偏移量后面开始消费。\n\n##### 问题：当消费完消息后，还没来得及提交偏移量，系统就被关机了，那么未提交偏移量的消息则会再次被消费\n\n如下图所示，队列中的数据 A、B、C 对应的偏移量分别未 100、101、102，都被消费者消费了，但是只有数据 A 的偏移量 100 提交成功，另外 2 个偏移量因系统重启而导致未及时提交。\n\n![2021-04-08-15-47-2420210408154723](https://i.loli.net/2021/04/08/Q1UGy5lriCFXs2z.png)\n\n重启后，消费者又是拿偏移量 100 以后的数据，从偏移量 101 开始消费消息。所以数据 B 和数据 C 被重复消费\n\n![2021-04-08-15-50-3720210408155036](https://i.loli.net/2021/04/08/lBPpTHnMY1EK6iy.png)\n\n##### 幂等性解决方案\n\n- 微信支付结果通知场景\n  - 微信官方文档上体到微信支付通知结果可能会推送多次，需要开发者自行保证幂等性。第一次我们可以直接修改订单状态（如：支付中->支付成功），第二次就根据订单状态来判断，如果不是支付中，则不进行订单处理逻辑\n- 插入数据库场景\n  - 每次插入数据时，先检查下数据库中是否又这条数据的主键 id，如果有，则进行更新操作\n- 写 redis 场景\n\n  - redis 的 set 操作天然具有幂等性，所以不用考虑 redis 写的问题\n\n- 其他场景方案\n  - 生产者发送每条数据时，增加一个全局唯一 id，类似订单 id。每次消费时，先去 redis 查询是否有这个 id，如果没有，则进行正常处理消息，且将 id 存到 redis。如果查到有这个 id，说明之前消费过，则不要及逆行重复处理这条消息\n\n### 消息队列消息丢失的问题\n\n#### 1.生产者存放消息的过程中丢失消息\n\n![2021-04-08-16-00-4420210408160043](https://i.loli.net/2021/04/08/dgWOe3rxnMTvUHk.png)\n\n##### 生产者丢失消息解决方案\n\n- 事务机制（不推荐，同步方式）\n\n对于 RabbitMQ 来说，生产者发送数据之前开启 RabbitMQ 的事务机制 channel.txselect，如果消息没有进入队列，则生产者收到异常报错，并进行回滚 channel.txRollback，然后可以操作重试发送消息；如果收到了消息，则可以提交事务 channel.txCommit。但是这是一个同步的操作，会影响性能\n\n- confirm 机制（推荐，异步方式）\n\n可以通过 confirm 模式来解决同步机制的性能问题。每次生产者发送的消息都会被分配一个唯一的 id，如果写入到了 rabbitMQ 队列中，则 rabbitMQ 会回传一个 ack 消息，说明这个消息写入成功。如果 rabbitMQ 没能写入这个消息，则回调 nack 接口，说明需要重试发送消息。\n\n也可以自定义超时时间+消息 id 来实现超时重试机制。但可能出现的问题是调用 ack 接口时失败了，所以会出现消息被发送两次的问题。这个时候就需要保证消费者消费消息的幂等性\n\n##### 事务模式和 confirm 模式的区别\n\n- 事务模式是同步的，提交事务后会被阻塞直到提交事务成功\n\n- confirm 模式异步接收通知，但可能接收不到通知，需要考虑接收不到通知的场景\n\n#### 2.消息队列丢失消息\n\n![2021-04-08-16-16-4720210408161647](https://i.loli.net/2021/04/08/R2xBdzyJ51ipWFg.png)\n\n消息队列的消息可以放到内存中，或者将内存中的消息转储到硬盘（比如数据库）中，一般都是内存和硬盘都存有消息。如果只是放在内存中，那么当机器重启了，消息就全部丢失了。如果是硬盘中，则可能存在一种极端情况，就是将内存中的数据转换到硬盘的期间，消息队列出问题了，未能完成消息的持久化操作\n\n##### 消息队列丢失消息解决方案\n\n- 创建 Queue 的时候将其设置为持久化\n\n- 发送消息的时候将消息的 deliveryMode 设置为 2\n\n- 开启生产者 confirm 模式，可以重试发送消息\n\n#### 3.消费者丢失消息\n\n![2021-04-08-16-20-2020210408162020](https://i.loli.net/2021/04/08/kLGV48qrduvhgOX.png)\n\n消费者刚拿到消息，还没有开始处理，进程因为异常退出了，消费者没有机会再次拿到消息\n\n##### 消费者丢失消息解决方案\n\n- 关闭 RabbitMQ 的自动 ack，每次生产者将消息写入消息队列后，就自动回传一个 ack 给生产者\n\n- 消费者处理完消息后再主动 ack，告诉消息队列消息处理完成\n\n##### 问题：这种主动 ack 有什么漏洞，如果主动 ack 的时候挂了，怎么办\n\n可能会被再次消费，这个时候就需要幂等处理了\n\n##### 问题：如果这条消息一直被重复消费怎么办\n\n需要加上重试次数的监控，如果超过一定次数则将消息丢失，记录到异常表或发送异常通知给管理人员\n\n#### 4.RabbitMQ 消息丢失总结\n\n![2021-04-08-16-34-3620210408163436](https://i.loli.net/2021/04/08/OdJ2RiWKDPXYMc3.png)\n\n#### 5.Kafka 消息丢失\n\n##### 场景\n\nKafka 的某个 broker 节点宕机了，重新选举 leader（写入的节点）。如果 leader 挂了，follower 还有些数据未同步完，则 follower 成为 leader 后，消息队列会丢失一部分数据\n\n##### Kafka 消息丢失解决方案\n\n- 给 topic 设置**replication.factor**参数，值必须大于 1，要求每个 partition 必须有至少 2 个副本\n\n- 给 Kafka 服务端设置**min.insyc.replicas**必须大于 1，表示一个 leader 至少一个 follower 还跟自己保持联系\n\n### 消息队列消息乱序的问题\n\n坑：用户先下单成功，然后取消订单，如果顺序乱了，则最后数据库里面会有一条下单成功的订单\n\n#### RabbitMQ 场景\n\n- 生产者向消息队列按照顺序发送了 2 条消息，消息 1：增加数据 A；消息 2：删除数据 A\n\n- 期望结果：数据 A 被删除\n\n- 但是如果有两个消费者，消费顺序是：消息 2、消息 1。则最后结果是增加了数据 A\n\n![2021-04-08-16-59-0220210408165901](https://i.loli.net/2021/04/08/PcZKANILlGtUgWv.png)\n\n##### RabbitMQ 解决方案\n\n- 将 Queue 进行拆分，创建多个内存 Queue，消息 1 和消息 2 进入同一个 Queue\n\n- 创建多个消费者，每个消费者对应一个 Queue\n\n![2021-04-08-17-03-4620210408170345](https://i.loli.net/2021/04/08/MyYI7KC6VkBXa8E.png)\n\n#### Kafka 场景\n\n- 创建了 topic，有 3 个 partition\n\n- 创建一条订单记录，订单 id 作为 key，订单相关的消息都丢到同一个 partition 中，同一个生产者创建的消息，顺序是正确的\n\n- 为了快速消费消息，会创建多个消费者去处理消息，而为了提高效率，每个消费者可能会创建多个线程来并行的去拿消息及处理消息，处理消息的顺序可能就乱了\n\n![2021-04-08-17-10-1720210408171016](https://i.loli.net/2021/04/08/E3tZdhWuVeAmvGX.png)\n\n##### Kafka 解决方案\n\n- 解决方案和 RabbitMQ 类似，利用多个内存 Queue，每个线程消费一个 Queue\n\n- 具有相同 Key 的消息，进入同一个 Queue\n\n![2021-04-08-17-15-4420210408171543](https://i.loli.net/2021/04/08/iJtVznA3UXCDwgh.png)\n\n### 消息队列消息积压的问题\n\n消息积压：消息队列里面有很多消息来不及消费\n\n- 场景 1：消费端出了问题，比如消费者都挂了，没有消费者消费消息，导致消息在队列里面不断积压\n\n- 场景 2：消费端出了问题，比如消费者消费的速度太慢了，导致消息不断积压\n\n![2021-04-08-17-41-2120210408174120](https://i.loli.net/2021/04/08/BHTAg2epfEoCFG3.png)\n\n解决方案：\n\n- 修复代码层面消费者的问题，确保后续消费速度恢复或尽可能加快消费的速度\n\n- 停掉现有的消费者\n\n- 临时建立好原先 5 倍数量的 Queue\n\n- 临时建立好原先 5 倍数量的消费者\n\n- 将堆积的消息全部转入临时的 Queue，用临时消费者消费这些 Queue\n\n- 消费完成后恢复原有状态\n\n![2021-04-08-17-45-5920210408174559](https://i.loli.net/2021/04/08/VdxubX6Y3qnrlky.png)\n\n### 消息队列消息过期失效的问题\n\n坑：RabbitMQ 可以设置过期时间，如果消息超过一定时间还没有被消费者消费，会被 RabbitMQ 给清理掉。消息就丢失了\n\n![2021-04-08-18-54-5420210408185454](https://i.loli.net/2021/04/08/YBaefWiUjhp9OmR.png)\n\n#### 消息过期失效解决方案\n\n- 准备好批量重导的程序\n\n- 手动将消息闲时批量重导\n\n### 消息队列队列写满\n\n坑：当消息队列因消息积压导致的队列快写满，所以不能接收更多的消息了。生产者生产的消息将会被丢弃\n\n解决方案：\n\n- 判断哪些是无用的消息，RabbitMQ 可以进行 purge message 操作\n\n- 如果是有用的消息，则需要将消息快速消费，将消息里面的内容转存到数据库\n\n- 准备好程序将转存在数据库中的消息再次重导入到消息队列\n\n- 显示重导消息到消息队列\n","tags":["mq","消息中间件"]},{"title":"分布式专题","url":"/article/29e3bd78.html","content":"\n## 分库分表\n\n### 分库分表之扩容\n\n#### 分库、分表、垂直拆分和水平拆分\n\n- 分库：因一个数据库支持的最高并发访问数是有限的，可以将一个数据库的数据拆分到多个库中，来增加最高访问数\n\n- 分表：因一个表的数据量太大，用索引来查询数据都搞不定了，所以可以将一张表的数据拆分到多张表，查询时只需要查拆分后的某一张表，SQL 语句的查询性能得到提升\n\n- 分库分表优势：分库分表后，承受的并发增加了多倍；磁盘使用率大大降低；单表数据量减少，sql 执行效率明显提升\n\n- 水平拆分：把一个表的数据拆分到多个数据库，每个数据库中的表结构不变。用多个库抗更高的并发。比如订单表每个月有 500W 条数据累计，每个月都可以进行水平拆分，将上个月的数据放到另外一个数据库中\n\n- 垂直拆分：把一个有很多字段的表，拆分成多张表到同一个库或者多个库上面。高频访问字段放到一张表，低频访问的字段放到另外一张表。利用数据库缓存来缓存高频访问的行数据。比如一张很多字段的订单表拆分成几张表分别存不同的字段（可以有冗余字段）\n\n#### 分库分表的方式\n\n- 利用租户来分库、分表\n\n- 利用字段范围来分库、分表\n\n- 利用字段 hash 来分库、分表\n\n#### 垂直拆分带来的问题\n\n- 依然存在单表数据量过大的问题\n- 部分表无法关联查询，只能通过接口聚合的方式解决，提升了开发的复杂度\n- 分布式事务处理复杂\n\n#### 水平拆分带来的问题\n\n- 跨库的关联查询性能差\n- 数据多次扩容和维护量大\n- 跨分片的事务一致性难以保证\n\n### 分库分表之唯一 ID\n\n#### 为什么分库分表需要唯一 ID\n\n- 如果要做分库分表，则必须考虑主键 ID 是全局唯一的，比如有一张订单表，被分到 A 库和 B 库，如果两张表都是从 1 开始递增，那么查询数据的时候就乱了，很多订单 ID 都是重复的，而这些订单其实并不是一笔订单\n\n- 分库的一个期望结果就是将访问数据的次数分摊到其他库，有些场景是需要均匀分摊的，那么数据插入到多个数据库的时候就需要交替生成唯一的 ID 来保证请求均匀分摊到所有数据库\n\n#### 生成唯一 ID 的原则\n\n- 全局唯一\n\n- 趋势递增\n\n- 单调递增\n\n- 信息安全\n\n#### 生成唯一 ID 的几种方式\n\n##### 数据库自增 ID，每个数据库每增加一条记录，自己的 ID 增 1\n\n- 多个库的 ID 可能重复，不适合分库分表后的 ID 生成\n- 信息不安全\n\n##### UUID\n\n- UUID 太长，占用空间大\n- 不具有有序性，作为主键时，在写入数据时，不能产生有顺序的 append 操作，只能进行 insert 操作，导致读取整个 B+树节点到内存，插入数据后将整个节点写回磁盘，当记录占用空间很大时，性能很差\n\n##### 获取系统当前时间作为唯一 ID\n\n- 高并发时，1ms 内可能有多个相同的 ID\n- 信息不安全\n\n##### Twitter 的**snowflake**（雪花算法）：twitter 开源的分布式 id 生成算法，64 位的 long 型的 id，分为 4 部分\n\n![2021-04-08-22-34-1320210408223412](https://i.loli.net/2021/04/08/MFdcAjCxav9uLBt.png)\n\n- 优点：\n  - 毫秒数在高位，自增序列在低位，整个 ID 都是趋势递增的\n  - 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成 ID 的性能也是非常高的\n  - 可以根据自身业务特性分配 bit 位，非常灵活\n- 缺点：\n  - 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态\n\n##### 百度的**UIDGenerator**算法\n\n![2021-04-08-22-43-3920210408224338](https://i.loli.net/2021/04/08/Tf7IFksaGmoHuVW.png)\n\n- 基于 snowflake 的优化算法\n- 借用未来时间和双 buffer 来解决时间回拨与生成性能等问题，同时结和 mysql 进行 ID 分配\n- 优点：解决了时间回拨和生成性能问题\n- 缺点：依赖 mysql 数据库\n\n##### 美团的**Leaf-snowflake**算法\n\n- 获取 id 是通过代理服务访问数据库获取一批 id（号段）\n- 双缓冲：当前一批的 id 使用 10%时，再访问数据库获取新的一批 id 缓存起来，等上批的 id 用完之后直接用\n- 优点：\n  - leaf 服务可以很方便的线性拓展，性能完全能够支撑大多数业务场景\n  - id 号码时趋势递增的 8byte 的 64 位数字，满足上述数据库存储的主键要求\n  - 容灾性高：leaf 服务内部有号段缓存，即使 DB 宕机，短时间内 leaf 仍能正常对外提供服务\n  - 可以自定义 max_id 的大小，非常方便业务从原有的 id 方式上迁移过来\n  - 即使 DB 宕机，leaf 仍能持续发号一段时间\n  - 偶尔的网络抖动不会影响下个号段的更新\n- 缺点：\n  - ID 号码不够随机，能够泄漏发号数量的信息，不太安全\n\n## 分布式事务\n\n在分布式的世界中，存在着各个服务之间相互调用，链路可能很长，如果有任何一方执行出错，则需要回滚涉及到的其他服务的相关操作。比如订单服务下单成功，然后调用营销中心发券接口发了一张代金券，但是微信支付扣款失败，则需要退回发的那张券，且要将订单状态改为异常订单\n\n### 分布式事务的几种主要方式\n\n- XA 方案（两段式提交）\n- TCC 方案（try、confirm、cancel）\n- SAGA 方案\n- 可靠消息最终一致性方案\n- 最大努力通知方案\n\n#### XA 方案原理\n\n![2021-04-09-09-57-4420210409095743](https://i.loli.net/2021/04/09/brVtGeCmkWMY36l.png)\n\n- 事务管理器负责协调多个数据库的事务，先问问各个数据库准备好了吗？如果准备好了，则在数据库执行操作，如果任何一个数据库没有准备好，则不执行事务\n- 适合单体应用，不适合微服务架构，因为每个服务只能访问自己的数据库，不允许交叉访问其他微服务的数据库\n\n#### TCC 方案\n\n- try 阶段：对各个服务的资源做检测以及对资源进行锁定或者预留\n\n- confirm 阶段：各个服务中执行实际的操作\n\n- cancel 阶段：如果任何一个服务的业务方法执行出错，需要将之前操作成功的步骤进行回滚\n\n- 应用场景：\n\n  - 跟支付、交易打交道，必须保证资金正确的场景\n  - 对于一致性要求很高\n\n- 缺点：\n  - 要写很多补偿逻辑的代码，且不易维护\n\n#### Saga 方案\n\n- 基本原理：\n  - 业务流程中的每个步骤若有一个失败了，则补偿前面操作成功的步骤\n- 适用场景：\n  - 业务流程长、业务流程多\n  - 参与者包含其他公司或遗留系统服务\n- 优势：\n  - 第一个阶段提交本地事务，无锁，高性能\n  - 参与者可异步执行，高吞吐\n  - 补偿服务易于实现\n- 缺点：\n  - 不保证事务的隔离性\n\n#### 可靠消息一致性方案\n\n![2021-04-09-12-08-0520210409120805](https://i.loli.net/2021/04/09/qMnzUdBtCc4PbXa.png)\n\n基本原理：\n\n- 利用消息中间件**RocketMQ**来实现消息事务\n- 第一步：A 系统发送一个**prepared**（预备状态，半消息）消息到 MQ，该消息无法被订阅\n- 第二步：MQ 响应 A 系统，告诉 A 系统已经接收到消息了\n- 第三步：A 系统执行本地事务\n- 第四步：若 A 系统执行本地事务成功，将**prepared**消息改为**commit**（提交事务消息），B 系统就可以订阅到消息了\n- 第五步：MQ 也会定时轮询所有**prepared**消息，回调 A 系统，让 A 系统告诉 MQ 本地事务处理的怎么样了，是继续等待还是回滚\n- 第六步：A 系统收到MQ回查，检查本地事务的执行结果\n- 第七步：若 A 系统执行本地事务失败，则 MQ 收到**Rollback**信号，丢弃消息。若执行本地事务成功，则 MQ 收到**commit**信号\n- B 系统收到消息后，开始执行本地事务，如果执行失败，则自动不断重试直到成功。或 B 系统采取回滚的方式，同时要通过其他方式通知 A 系统也进行回滚\n- B 系统需要保证幂等性\n\n#### 最大努力通知方案\n\n基本原理：\n\n- 系统 A 本地事务执行完成之后，发送消息到 MQ\n- MQ 将消息持久化\n- 系统 B 如果执行本地事务失败，则**最大努力服务**会定时尝试重新调用系统 B，尽自己最大的努力让系统 B 重试，重试多次后，还是不行就只能放弃了。通知开发人员去排查以及后续人工补偿\n\n#### 几种方案如何选择\n\n- 跟支付、交易打交道，优先 TCC\n- 大型系统，但要求不那么严格，考虑消息事务或 SAGA 方案\n- 单体应用，建议 XA 两阶段提交就可以\n- 最大努力通知方案建议都加上，毕竟不可能一出问题就交给开发排查，先重试几次看看能不能成功\n","tags":["分布式"]},{"title":"sql优化专题","url":"/article/d1c9f364.html","content":"\n对于 MySQL 层面的优化一般遵循 5 个原则:\n\n- 减少数据访问：设置合理的字段类型，启用压缩，通过索引访问等减少磁盘 IO\n\n- 返回更少的数据：只返回需要的字段和数据分页处理，减少磁盘 IO 及网络 IO\n\n- 减少交互次数：批量 DML 操作，函数存储等减少数据连接次数\n\n- 减少服务器 CPU 开销：尽量减少数据库排序操作及全表查询，减少 CPU 内存占用\n\n- 利用更多资源：使用表分区，可以增加并行操作，更大限度利用 CPU 资源\n\n总结到 SQL 优化中，就如下 3 点：\n\n- 最大化利用索引\n\n- 尽可能避免全表扫描\n\n- 减少无效数据的查询\n\n理解 SQL 优化原理，首先要搞清楚 SQL 执行顺序\n\n```sql\nselect\ndistinct <select_list>\nfrom <left_table>\n<join_type> join <right_table>\non <join_condition>\nwhere <where_condition>\ngroup by <group_by_list>\nhaving <having_condition>\norder by <order_by_condition>\nlimit <limit_number>\n```\n\nselect 语句，执行顺序如下：\n\n```sql\nfrom\n<表名> # 选取表，将多个表数据通过笛卡尔积变成一个表\non\n<筛选条件> # 对笛卡尔积的虚表进行筛选\njoin <join, left join, right join...>\n<要join的表> # 指定join，用于添加数据到on之后的虚表，例如left join会将左表的剩余数据添加到虚表中\nwhere\n<where条件> # 对上述虚表进行筛选\ngroup by\n<分组条件> # 分组\n<SUM()等聚合函数> # 用于having子句进行判断，在书写上这类聚合函数是写在having判断里面的\nhaving\n<分组筛选> # 对分组后的结果进行聚合筛选\nselect\n<返回数据列表> # 返回的单列必须在group by 子句中，聚合函数除外\ndistinct # 数据去重\norder by\n<排序条件> # 排序\nlimit\n<行数限制>\n```\n\n### 避免不走索引的场景\n\n#### 1.尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描\n\n```sql\nselect * from user where username like '%张';\n```\n\n优化方式：尽量在字段后面使用模糊查询\n\n如果需求是要在前面使用模糊查询：\n\n- 使用 MySQL 内置函数 INSTR(str,substr)来匹配，作用类似于 Java 中的 indexOf()，查询字符串出现的角标位置\n\n  - instr(field,str)函数第一个参数 field 是字段，第二个参数是要查询的字符串 str，返回 str 在字段中的位置，没找到就返回 0\n\n- 使用全文索引，用 match against 检索\n\n- 数据量较大的情况，建议用 ElasticSearch、Solr，亿级数据量检索速度秒级\n\n- 当表数据量较少，直接用 like '%xx%'\n\n#### 2.尽量避免使用 in 和 not in，会导致引擎走全表扫描\n\n```sql\nselect * from user where id in (1,2,3);\n```\n\n优化方式：\n\n如果是连续数值，用 between 代替\n\n```sql\nselect * from user where id between 1 and 3;\n```\n\n如果是子查询，可以用 exists 代替\n\n```sql\n-- 不走索引\nselect * from A where A.id in (select id from B);\n-- 走索引\nselect * from A where exists (select * from B where B.id = A.id)\n```\n\n#### 3.尽量避免使用 or，会导致数据库引擎放弃索引走全表扫描\n\n```sql\nselect * from t where id = 1 or id = 3\n```\n\n优化方式：可以用 union 代替 or\n\n```sql\nselect * from t where id = 1\nunion\nselect * from t where id = 3\n```\n\n#### 4.尽量避免进行 null 值的判断，会导致数据库引擎放弃索引走全表扫描\n\n```sql\nselect * from t where score is null;\n```\n\n优化方式：可以给字段添加默认值 0，对 0 进行判断\n\n```sql\nselect * from t where score = 0;\n```\n\n#### 5.尽量避免在 where 条件等号左侧进行表达式、函数操作，会导致数据库引擎放弃索引走全表扫描\n\n```sql\nselect * from t where score/10 = 9;\n```\n\n优化方式：可以将表达式、函数操作移动到等号右侧\n\n```sql\nselect * from t where score = 9 * 10 ;\n```\n\n#### 6.当数据量大时，避免使用 where 1= 1 条件\n\n通常为了方便拼装查询条件，我们会默认使用该条件，数据库引擎会放弃索引进行全表扫描\n\n```sql\nselect username, age, sex from t where 1 = 1;\n```\n\n优化方式：用代码拼装 sql 时进行判断，没 where 条件就去掉 where，有 where 条件就加 and。用 mybatis **\\<where\\>**标签实现动态 sql\n\n#### 7.查询条件不能用<>或者!=（可以用到 ICP）\n\n如果确实业务需要，使用到不等于符号，需要再重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替\n\n#### 8.where 条件仅包含复合索引非前置列\n\n复合（联合）索引为(a,b,c)三列，但是 SQL 语句没有包含索引前置列 a，按照 MySQL 联合索引的最左匹配原则，不会走联合索引\n\n```sql\nselect * from t where b=1 and c=2;\n```\n\n#### 9.隐式类型转换造成不使用索引\n\n字段整形加上引号可以走索引，字符串不加引号不会走索引\n\n```sql\nselect * from t where col_varchar = 123;\n```\n\n#### 10.order by 条件要与 where 中条件一致，否则 order by 不会利用索引进行排序\n\n```sql\n-- 不走age索引\nselect * from t order by age;\n\n-- 走age索引\nselect * from t where age > 0 order by age;\n```\n\n对于上面的语句，数据库的处理顺序是：\n\n- 第一步：根据 where 条件和统计信息生成执行计划，得到数据\n\n- 第二步：将得到的数据排序，当执行处理数据（order by ）时，数据库会先查看第一步的执行计划，看 order by 的字段是否在执行计划中利用了索引。如果是，则可以利用索引顺序儿直接取得已经排好序的数据。如果不是，则重新进行排序操作\n\n- 第三步：返回排序后的数据\n\n当 order by 中的字段出现在 where 条件中时，才会利用索引而不再二次排序。更准确的说，order by 中的字段在执行计划中利用了索引时，不需要排序操作\n\n这个结论不仅对 order by 有效，对其他需要排序的操作也有效，如 group by 、union、distinct 等\n\n#### 11.某个表中有两列(id 和 c_id)都建立了单独索引,下面这种查询条件不会走索引，应尽量避免\n\n```sql\nselect * from test where id = c_id;\n```\n\n#### 12.正确使用 hint 优化语句\n\nMySQL 中可以使用 hint 指定优化器在执行时选择或忽略特定的索引\n\n一般而言，处于版本变更带来的表结构索引变化，更建议避免使用 hint，而是通过 Analyze table 多收集统计信息\n\n但在特定场合下，指定 hint 可以排除其他索引干扰而指定更优的执行计划\n\n- USE INDEX 在你查询语句中表名的后面，添加 USE INDEX 来提供希望 MySQL 去参考的索引列表，就可以让 MySQL 不再考虑其他可用的索引。例如 select col1 from table use index(mod_time,name)...\n\n- IGNORE INDEX 如果只是单纯的想让 MySQL 忽略一个或者多个索引，可以使用 IGNORE INDEX 作为 hint。例如：select col1 from table IGNORE INDEX(priority)...\n\n- FORCE INDEX 为强制 MySQL 使用一个特定的索引。例如：select col1 from table FORCE INDEX(mod_time)...\n\n#### 13.大分页\n\n索引 idxa_b_c(a,b,c)\n\n```sql\nselect * from t where a = 1 and b = 2 order by c desc limit 100000, 10;\n```\n\n对于大分页的场景，可以先优化需求，无法优化的，有如下两种优化方式：\n\n- 一是把上一次的最后一条数据，也即上面的 c 传过来，然后做\"c < XXX\"处理，但是这种一般需要更改接口协议，并不一定可行\n- 另一种方式是采用延迟关联的方式进行处理，减少 SQL 回表，但是要记得索引需要完全覆盖才有效，SQL 如下：\n\n```sql\nselect t1.* from t t1, (select id from t where a=1 and b=2 order by c desc limit 100000, 10)t2 where t1.id = t2.id;\n```\n\n#### 14.in + order by\n\n索引 idx_shopId_status_created(shop_id,order_status,created_at)\n\n```sql\nselect * from order where shop_id = 1 and order_status in (1,2,3) order by created_at desc limit 10\n```\n\nin 查询在 mysql 底层是通过 n\\*m 的方式去搜索，类似 union，但是效率比 union 高\n\nin 查询在进行 cost 代价计算时(代价=元数组\\*IO 平均值)，是通过将 in 包含的数值，一条条去查询获取元数组的，因此这个计算过程会比较慢，所以 Mysql 设置了一个临界值(eq_range_index_dive_limit)，5.6 之后将这个临界值后该列的 cost 就不参与计算了。因此会导致执行计划选择不准确。默认是 200，即 in 条件超过了 200 个数据，会导致 in 的代价计算存在问题，可能会导致 mysql 选择的索引不准确\n\n处理方式：可以(order_status, created_at)互换前后顺序，并且调整 sql 为延迟关联\n\n#### 15.范围查询阻断，后续字段不能走索引\n\n索引 idx_shopId_status_created(shop_id,created_at,order_status)\n\n```sql\nselect * from order where shop_id = 1 and created_at > '2021-04-14 00:00:00' and order_status = 10;\n```\n\n范围查询还有 in、between\n\n#### 16.优化器选择不使用索引的情况\n\n如果要求访问的数据量很小，则优化器还是会选择辅助索引，但是当访问的数据占整个表中数据蛮大的一部分时（一般是 20%左右），则优化器会选择通过聚集索引来查找数据\n\n#### 17.ASC、DESC 混用\n\n```sql\nselect * from order where a = 1 order by b desc, c asc;\n```\n\ndesc 和 asc 混用会导致索引失效\n\n### select 语句其他优化\n\n#### 1.避免使用 select \\*\n\nselect \\* 取出全部列，会让优化器无法完成索引覆盖扫描这类优化，会影响优化器对执行计划的选择，也会增加网络带宽消耗，更会带来额外的 IO、内存和 CPU 消耗\n\n#### 2.避免出现不确定结果的函数\n\n特定针对主从复制这类业务场景。由于原理上从库复制的是主库执行的语句，使用如 now()、rand()、sysdata()、current_user()等不确定结果的函数很容易导致主库与从库相应的数据不一致。\n\n另外不确定值得函数，产生的 sql 语句无法利用 query cache\n\n#### 3.多表关联查询时，小表在前，大表在后\n\n在 MySQL 中，执行 from 后的表关联查询是从左往右执行的（Oracle 相反），第一张表会涉及到全表扫描\n\n所以将小表放在前面，先扫小表，扫描效率较高，再扫描后面的大表，或许只扫大表前 100 行就符合返回条件并 return 了\n\n例如：表 1 有 50 条数据，表 2 有 30 亿条数据；如果全表扫描表 2，那么效率将会非常差\n\n#### 4.使用表的别名\n\n当在 sql 语句中连接多个表时，使用表的别名并将别名前缀于每个列名上。这样就可以减少解析的时间并减少那些因为列名歧义引起的语法错误\n\n#### 5.用 where 子句替换 having 子句\n\n避免使用 having 子句，因为 Having 只会在检索出所有记录之后才会对结果集进行过滤，而 where 则是在聚合前筛选记录，如果能通过 where 子句限制记录的数目，那么就能减少这方面的开销\n\n#### 6.调整 where 子句中的连接顺序\n\nMySQL 采用从左到右，自上而下的顺序解析 where 子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集\n\n### 增删改 DML 语句优化\n\n#### 1.大批量插入数据\n\n如果同时执行大量的插入，建议使用多个值的 insert 语句。这比分开 insert 的语句快，一般情况下批量插入效率有几倍的差别\n\n```sql\n-- 单个插入\ninsert into t values(1,2);\ninsert into t values(2,3);\ninsert into t values(3,4);\n-- 批量插入\ninsert into t values(1,2),(2,3),(3,4);\n```\n\n选择批量插入的原因有 3 个：\n\n- 减少 sql 语句解析的操作，MySQL 没有类似 oracle 的 share pool，采用批量插入，只需要解析一次就可以进行数据的插入操作\n\n- 在特定场景下可以减少对 DB 连接次数\n\n- SQL 语句较少，可以减少网络传输的 IO\n\n注意：\n\nmysql 对一条 sql 语句有最大长度限制，可以执行以下语句查看，可以在 my.cnf 配置文件中进行更改\n\n```sql\nshow variables like '%max_allowed_packet%';\n```\n\n![2021-04-09-17-35-0120210409173500](https://i.loli.net/2021/04/09/nFOH5UYQP2dKiAG.png)\n\n#### 2.适当使用 commit\n\n适当使用 commit 可以释放事务占用的资源而减少消耗，commit 后能释放的资源如下：\n\n- 事务占用的 undo 数据块\n- 事务在 redo log 中记录的数据块\n- 释放事务施加的锁，减少锁争用影响性能。特别是在需要使用 delete 大量数据的时候，必须分解删除量并定期 commit\n\n#### 3.避免重复查询更新的数据\n\n针对业务中经常出现的更新行同时又希望获得该行更新后信息的需求，MySQL 并不支持 PostgreSQL 那样的 update returning 语法，在 MySQL 中可以通过变量实现\n\n例如：更新一行记录的时间戳，同时希望查询当前记录中存放的时间戳是什么\n\n```sql\n-- 简单方法实现\nupdate t1 set time = now() where id =1;\nselect time from t1 where id = 1;\n-- 使用变量，可以重写为以下方式\nupdate t1 set time=now() where id = 1 and @now:= now();\nselect @now;\n```\n\n前后两者都需要两次网络来回，但使用变量避免了再次访问数据表，特别是当 t1 表数据量较大时，后者比前者快很多\n\n#### 4.查询优先还是更新（insert、update、delete）优先\n\nMySQL 还允许改变语句调度的优先级，它可以使来自多个客户端的查询更好地协作，这样单个客户端就不会由于锁定而等待很长时间。改变优先级还可以确保特定类型的查询被处理得更快\n\n我们首先应该确定应用的类型，判断应用是以查询为主还是更新为主，是确保查询效率还是确保更新的效率，决定是查询优先还是更新优先\n\n下面我们提到的改变调度策略的方法主要是针对只存在表锁的存储引擎，比如 MyISAM、MEMORY、MERGE，对于 InnoDB 存储引擎，语句的执行是由获得行锁的顺序决定的\n\nMySQL 的默认的调度策略可用总结如下：\n\n- 对于写入操作优先于读取操作\n\n- 对某数据表的写入操作某一时刻只能发生一次，写入请求按照他们到达的次序来处理\n\n- 对某张数据表的多个读取操作可以同时地进行\n\nMySQL 提供了几个语句调节符，允许修改它的调度策略：\n\n- LOW_PRIORITY 关键字应用于 DELETE、INSERT、LOAD DATA、REPLACE 和 UPDATE\n\n- HIGH_PRIORITY 关键字应用于 select 和 insert\n\n- DELAYED 关键字应用于 insert 和 replace\n\n如果写入操作是一个 LOW_PRIORITY 请求，那么系统就不会认为它的优先级高于读取操作。\n\n在这种情况下，如果写入者在等待的时候，第二个读取者到达了，那么就允许第二个读取者插到写入者之前。\n\n只有在没有其他读取者的时候，才允许写入者开始操作。这种调度修改可能存在 LOW_PRIORITY 写入操作永远被阻塞的情况。\n\nselect 查询的 HIGH_PRIORITY 关键字也类似。它允许 select 插入正在等待的写入操作之前，即使在正常情况下写入操作的优先级更高。\n\n另外一种影响是，高优先级的 select 在正常的 select 语句之前执行，因为这些语句会被写入操作阻塞\n\n如果希望所有支持 LOW_PRIORITY 选项的语句都默认地按照低优先级来处理，那么请使用--low-priority-update 选项来启动服务器\n\n通过使用 INSERTHIGH_PRIORITY 来把 insert 语句提高到正常的写入优先级，可以消除该选项对单个 insert 语句的影响\n\n### 查询条件优化\n\n#### 1.对于复杂的查询，可以使用中间临时表暂存数据\n\n#### 2.优化 group by 语句\n\n默认情况下，MySQL 会对 group by 分组的所有值进行排序，如“group by col1,col2,...;”查询的方法如同在查询中指定“order by col1, col2, ...;”\n\n如果显示包括一个包含相同的列的 order by 子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序\n\n因此，如果查询包括 group by 但你并不想对分组的值进行排序，你可以指定 order by null 禁止排序\n\n例如：\n\n```sql\nselect col1, col2, count(*) from table group by col1, col2 order by null;\n```\n\n#### 3.优化 join 语句\n\nMySQL 中可以通过子查询来使用 select 语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另外一个查询中\n\n使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的 sql 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是有些情况下，子查询可以被更有效率的连接（join）替代\n\n例如：假设要将所有没有订单记录的用户取出来，可以用下面的查询完成\n\n```sql\nselect col1 from customerinfo where customerId not in (select customerId from salesinfo);\n```\n\n如果使用 join 来完成这个查询工作，速度将会有所提升\n\n尤其是当 salesinfo 表中对 customerId 建有索引的话，性能将会更好\n\n```sql\nselect col1 from customerinfo\n  left join salesinfo on customerinfo.customerId = salesinfo.customerId\n  where salesinfo.customerId is null\n```\n\n#### 4.通过 union 查询\n\nMySQL 通过创建并填充临时表的方式来执行 union 查询。除非确实需要消除重复的行，否则建议使用 nuion all\n\n原因在于如果没有 all 这个关键词，MySQL 会给临时表上加上 distinct 选项，这会导致对整个临时表的数据做唯一性校验，这样做的消耗相当高\n\n高效：\n\n```sql\nselect col1, col2, col3 from table where col1 = 10\nunion all\nselect col1, col2, col3 from table where col3 = 'test';\n```\n\n低效：\n\n```sql\nselect col1, col2, col3 from table where col1 = 10\nunion\nselect col1, col2, col3 from table where col3 = 'test';\n```\n\n#### 5.拆分复杂 sql 为多个小 sql，避免大事务\n\n- 简单的 sql 容易使用到 MySQL 的 query cache\n\n- 减少锁表时间特别是使用 MyISAM 存储引擎的表\n\n- 可以使用多核 CPU\n\n#### 6.使用 truncate 代替 delete\n\n当删除全表中记录时，使用 delete 语句的操作会被记录到 undo 块中，删除记录也记录 Binlog\n\n当确认需要删除全表时，会产生很大量的 Binlog 并占用大量的 undo 数据块，此时既没有很好的效率也占用了大量的资源\n\n使用 truncate 替代，不会记录可恢复的信息，数据不能被恢复。也因此使用 truncate 操作有其极少的资源占用与极快的时间。另外使用 truncate 可以回收表的水位线，使自增字段值归零。\n\n#### 7.使用合理的分页方式以提高分页效率\n\n案例 1：\n\n```sql\nselect * from t where thread_id = 10000 and deleted = 0\norder by gmt_create asc limit 0,15;\n```\n\n上述例子通过一次性根据过滤条件取出所有字段进行排序返回。数据访问开销=索引 IO+索引全部记录结果对应的表数据 IO\n\n适用场景：当中间结果集很小（10000 行以下）或者查询条件复杂（指涉及多个不同查询字段或者多表连接）时适用\n\n案例 2：\n\n```sql\nselect\n  t.*\nfrom\n  ( select\n      id\n    from\n      t\n    where\n      thread_id = 10000\n    and\n      deleted =0\n    order by\n      gmt_create asc\n    limit\n      0, 15)a, t\nwhere\n    a.id = t.id\n```\n\n上述例子必须满足 t 表主键是 id 列，且有覆盖索引 secondary key :(thread_id, deleted, gmt_create)\n\n通过先根据过滤条件利用覆盖索引取出主键 id 进行排序，再进行 join 操作取出其他字段\n\n数据访问开销=索引 IO+索引分页后结果对应的表数据 IO。因此，该写法每次翻页消耗的资源和时间都基本相同，就像翻第一页一样。\n\n对于典型的分页 limit m,n 来说，越往后翻页越慢，也就是 m 越大会越慢，因为要定位 m 位置需要扫描的数据越来越多，导致 IO 开销比较大，这里可以利用辅助索引的覆盖扫描来进行优化，先获取 id，这一步就是索引覆盖扫描，不需要回表，然后通过 id 跟原表进行关联。\n\n适用场景：当查询和排序字段（即 where 子句和 order by 子句涉及的字段）有对应覆盖索引时，且中间结果集很大的情况时适用。\n\n#### 8.分而治之\n\n假设有 500W 的数据要进行批量更新\n\n```sql\nupdate coupons set status = 1 where status =0 and create_time >= '2020-10-01 00:00:00' and create_time <= '2020-10-07 23:59:59';\n```\n\nmysql 中一个 sql 只能使用一个 cpu core 去处理，如果 sql 很复杂或者执行很慢，就会阻塞后面的 sql 请求，造成活动连接数暴增，mysql cpu 100%，响应的接口 timeout，同时对于主从复制架构，而且做了业务读写分离，更新 500W 数据需要 5 分钟，master 上执行了 5 分钟，binlog 传到 slave 也需要执行 5 分钟，那么 slave 数据延迟就有 5 分钟，在这期间会造成业务脏数据，比如本该失效的优惠券依旧被正常使用等。\n\n优化思路：先获取 where 条件中的最小 id 和最大 id，然后分批次去更新，每个批次 1000 条，这样既能快速完成更新，又能保证主从复制不会出现延迟\n\n### 建表优化\n\n#### 1.在表中建立索引，优先考虑 where、order by 使用的字段\n\n#### 2.尽量使用数字型字段（如性别，男：1，女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销\n\n这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了\n\n#### 3.查询数据量大的表会造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序分段分页进行查询，循环遍历，将结果合并处理进行展示\n\n要查询 100000 到 100050 的数据，如下：\n\n```sql\nselect * from\n  (select ROW_NUMBER() over (order by ID asc) as rowid, * from infotab)t\nwhere t.rowid >100000 and t.rowid<=100050\n```\n\n#### 4.用 varchar/nvarchar 代替 char/nchar\n\n尽可能的使用 varchar/nvarchar 代替 char/nchar。因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些\n\n不要以为 null 不需要空间，比如 char(100)型，在字段建立时，空间就固定了，不管是否插入值（null 也包含在内），都是占用 100 个字符的空间的，如果是 varchar 这样的变长字段，null 不占用空间\n\n### sql 优化一般过程\n\n#### 通过查日志等定位执行效率低的 SQL 语句\n\n#### explain 分析 SQL 的执行计划\n\n需要重点关注 type、rows、filtered、extra。\n\n##### type\n\n由上至下，效率越来越高\n\n- ALL 全表扫描\n- index 索引全扫描\n- range 索引范围扫描，常用于<、<=、>=、between、in 等操作\n- ref 使用唯一索引扫描或唯一索引前缀扫描，返回单条记录，常出现在关联查询中\n- eq_ref 类似 ref，区别在于使用的是唯一索引，使用主键的关联查询\n- const/system 单条记录，系统会把匹配行中的其他列作为常数处理，如主键或唯一索引查询\n- null mysql 不访问任何表或索引，直接返回结果\n\n虽然由上至下，效率越来越高，但是根据 cost 模型，假设有两个索引 idx1(a,b)、idx2(a,c)，sql 为\"select \\* from t where a = 1 and b in (1,2) order by c\"；如果走 idx1，那么是 type 为 range，如果走 idx2，那么 type 是 ref；当需要扫描的行数，使用 idx2 大约是 idx1 的 5 倍以上时，会用 idx1，否则用 idx2\n\n##### Extra\n\n- Using filesort：mysql 需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配 where 子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行\n- Using temporary：使用临时表保存中间结果，性能特别差，需要重点优化\n- Using index：表示相应的 select 操作中使用了覆盖索引（Coveing Index），避免访问了表的数据行，效率不错。如果同时出现 Using where，意味着无法通过索引查找来查询到符合条件的数据\n- Using index condition：mysql5.6 之后新增的 ICP，using index condition 就是使用了 ICP（索引下推），在存储引擎层进行数据过滤，而不是在服务层过滤，利用索引现有的数据减少回表的数据\n\n#### show profile 分析\n\n了解 sql 执行的线程的状态及消耗的时间\n\n默认是关闭的，开启语句 set profiling = 1;\n\n```sql\nshow profiles;\nSHOW PROFILE FOR QUERY  #{id};\n```\n\n#### trace\n\ntrace 分析优化器如何选择执行计划，通过 trace 文件能够进一步了解为什么优化器选择 A 执行计划而不选择 B 执行计划\n\n```sql\nset optimizer_trace = \"enabled=on\";\nset optimizer_trace_max_mem_size=1000000;\nselect * from information_schema.optimizer_trace;\n```\n\n#### 确定问题并采用相应的措施\n\n- 优化索引\n- 优化 SQL 语句：修改 SQL、IN 查询分段、时间查询分段、基于上一次数据过滤\n- 改用其他实现方式：ES、数仓等\n- 数据碎片处理\n","tags":["interview","sql"]},{"title":"tree知识点(持续更新)","url":"/article/d1dca260.html","content":"\n### 二叉查找树\n\n二叉查找树，Binary Search Tree[BST]，也称有序二叉树（ordered binary tree），排序二叉树（sorted binary tree），是指一棵空树或具有下列性质的二叉树\n\n1.若任意节点的左子树不为空，则左子树上所有节点的值均小于它的根节点的值\n\n2.若任意节点的右子树不为空，则右子树上所有节点的值均大于它的根节点的值\n\n3.任意节点的左右子树也分别是二叉查找树\n\n4.没有键值相等的节点\n\n因为一棵由 n 个节点随机构造的二叉树高度为 lgN，所以一般操作的执行时间为 O(lgN)\n\n![2021-03-30-13-45-1720210330134516](https://i.loli.net/2021/04/01/125J6eGB3vKk7FM.png)\n\n上图，结合二叉查找树的三条约束来看，没有什么问题，下图依旧符合上面三条约束，却是存在问题的\n\n![2021-03-30-13-44-5720210330134457](https://i.loli.net/2021/04/01/yR21Bt84niVaoxD.png)\n\n二叉树若退化成了一颗具有 n 个节点的线性链后，操作的最坏时间复杂度为 O(N)\n\n红黑树会通过一些性质使树相对平衡，使得最终查找、插入、删除的时间复杂度最坏情况下依然为 O(lgN)\n\n### 红黑树\n\n红黑树，Red-Black Tree[RBT]，是一个自平衡（不是绝对的平衡）的二叉查找树（BST），树上的每个节点都遵循下面的规则：\n\n1.每个节点要么是红的，要么是黑色\n\n2.根节点是黑色的\n\n3.每个叶子节点（叶子节点即指树尾端 nil 指针或 NULL 节点）是黑色\n\n4.如果一个节点是红色，那么它的两个儿子是黑色\n\n5.对于任一节点而言，其到叶节点的每一条路径都包含相同数目的黑色节点\n\n正是红黑树的这 5 条性质，使得一棵 n 个节点的红黑树始终保持了 lgN 的高度，也就是红黑树查找、插入、删除的最坏时间复杂度为 lgN\n\n![2021-03-30-15-42-2920210330154228](https://i.loli.net/2021/04/01/UfemGoEVQpLJ46g.png)\n\n#### 红黑树的旋转与变色\n\n当我们在对红黑树进行插入或删除等操作时，对树的结构进行了修改，可能会违背红黑树的性质\n\n为了继续保持红黑树的性质，我们会进行两种操作：\n\n1.recolor（变色，重新标记红色或黑色）\n\n2.rotation（旋转）\n\n先尝试 recolor，如果 recolor 不能达到红黑树的要求，就尝试 rotation\n\n步骤:\n\n假设新插入的节点为 X\n\n- 1.将新插入的节点标记为红色\n\n- 2.如果 X 是根节点（root），则标记为黑色\n\n- 3.如果 X 不是根节点且 X 的 parent 不是黑色\n\n  - 3.1 如果 X 的 uncle（叔叔）是红色\n\n    - 3.1.1 将 parent 和 uncle 标记为黑色\n\n    - 3.1.2 将 grand parent（祖父）标记为红色\n\n    - 3.1.3 将 G 变成新的 X，然后重复步骤 2、3\n\n  - 3.2 如果 X 的 uncle（叔叔）是黑色，要分成四种情况处理\n\n    - 3.2.1 左左（P 是 G 的左儿子，X 是 P 的左儿子）\n\n    - 3.2.2 左右（P 是 G 的左儿子，X 是 P 的右儿子）\n\n    - 3.2.3 右右（P 是 G 的右儿子，X 是 P 的右儿子）\n\n    - 3.2.4 右左（P 是 G 的右儿子，X 是 P 的左儿子）\n\n##### uncle 是红色\n\n1.将新插入的节点 X 标记为红色\n\n2.发现 X 的 parent（P）同样为红色，这违反了红黑树的第三条规则：不能有两个连续相邻的红色节点\n\n3.发现 X 的 uncle（U）同样为红色\n\n4.将 P 和 U 标记为黑色\n\n5.将 X 和 X 的 grand parent （G）标记为相同的颜色，即红色，将 G 设为新的 X，继续重复 2、3\n\n6.发现 G 是根节点，标记为黑色\n\n7.结束\n\n![2021-03-30-16-59-1120210330165910](https://i.loli.net/2021/04/01/ClKvsw3ceyqiSXh.png)\n\n##### 左左\n\n想象这是一根绳子，手提起 P 点，然后变色\n\n![2021-03-30-17-12-2220210330171222](https://i.loli.net/2021/04/01/VCxABK57ephZUdW.png)\n\n##### 左右\n\n左旋：使 X 的父节点 P 被 X 取代，同时父节点 P 成为 X 的左孩子，然后再应用左左情况\n\n![2021-03-30-17-21-4420210330172143](https://i.loli.net/2021/04/01/YQfzqWmG6d7K8Mw.png)\n\n##### 右右\n\n与左左情况一样,想象成一根绳子\n\n![2021-04-01-11-14-1720210401111416](https://i.loli.net/2021/04/01/lbud9vPiaxWrkzc.png)\n\n##### 右左\n\n右旋:使 X 的父节点 P 被 X 取代,同时父节点 P 成为 X 的右孩子,然后再应用右右情况\n\n![2021-04-01-11-25-2220210401112522](https://i.loli.net/2021/04/01/4uFCTlLJkXyQ59h.png)\n","tags":["tree"]},{"title":"红黑树","url":"/article/f89cb603.html","content":"\n```java\n左旋\nvoid leftRotate(Tree t, TreeNode x){\n  TreeNode y = x.right; // 取得x节点的右儿子赋值给y\n\n  x.right = y.left;     // 将y的左儿子赋值给x的右儿子\n  y.left.parent = x;    // 将y的左儿子的父节点变更成x\n\n  y.parent = x.parent;   // 将x的父节点赋值给y的父节点\n  if(x.parent == null){\n    t.root = y;\n  }else if(x == x.parent.left){\n    x.parent.left = y;\n  }else{\n    x.parent.right = y;\n  }\n  y.left = x;\n  x.parent = y;\n}\n```\n\n```java\n插入\n\nvoid RBInsert(Tree t, TreeNode z){\n  TreeNode y = null;\n  TreeNode x = t.root;\n  while(x != null){\n    y = x;\n    if(z.value < x.value){\n      x = x.left;\n    }else{\n      x = x.right;\n    }\n  }\n\n  z.parent = y;\n\n  if(y == null){\n    t.root = z;\n  }else if(z.value < y.value){\n    y.left = z;\n  }else{\n    y.right = z;\n  }\n\n  z.left = null;\n  z.right = null;\n  z.color = RED;\n  RBInsertFixUp(t,z);\n}\n\n```\n\n```java\n红黑树插入后调整\n\nvoid RBInsertFixUp(Tree t,Node z){\n  while(z.parent.color == RED){ \n    if(z.parent == z.parent.parent.left){\n      TreeNode y = z.parent.parent.right;\n      if(y.color == RED){\n        z.parent.color = BLACK;\n        y.color = BLACK;\n        z.parent.parent.color = RED;\n        z = z.parent.parent;\n      }else if(z == z.parent.right){\n        z = z.parent;\n        leftRotate(t,z);\n        z.parent.color = BLACK;\n        z.parent.parent.color = RED;\n        rightRotate(t,z.parent.parent);\n      }\n    }else{\n      // 同上，调转left和right\n    }\n  }\n  t.root.color = BLACK;\n\n}\n```\n","tags":["tree"]},{"title":"java面试知识点(持续更新)","url":"/article/df4728df.html","content":"\n### finally 什么时候执行\n\n1.finally 语句在 return 语句执行之后,return 返回之前执行的\n\n2.finally 中的 return 语句会覆盖 try 中的 return 语句\n\n3.finally 里的修改语句可能影响也可能不影响 try 或 catch 里 return 已经确定的返回值\n\n### static/private/final static 哪些是线程安全的\n","tags":["interview","java"]},{"title":"spring面试知识点(持续更新)","url":"/article/adbddb32.html","content":"\n### spring 是如何实现 ioc 的\n\n### spring bean 什么时候初始化,什么时候销毁的\n\n### spring lazy-init 注解\n\nlazy-init 是 Spring 中延迟加载 bean 的属性\n\n设置为 lazy-init=true 的 bean 将不会在 ApplicationContext 启动时提前被实例化,而是在第一次向容器通过 getBean 索取 bean 实例时实例化的\n\n如果一个设置了立即加载的 bean1 引用了一个延迟加载的 bean2,那么 bean1 在容器启动时会被实例化,而 bean2 由于被 bean1 引用,也会被实例化,这种情况也符合延迟加载的 bean 在第一次被调用时才实例化的规则\n\nlazy-init 只在 scope 属性为 singleton 时才会有效,如果 scope 属性值为 pototype,那么即使设置了 lazy-init=\"false\",容器启动时也不会被实例化,而是 getBean 方法实例化\n\n### 拦截器（Interceptor）和过滤器（Filter）的执行顺序和区别\n\n1.过滤器,依赖于 servlet 容器,基于函数回调实现,可以对几乎所有请求过滤,但是缺点是一个过滤器实例只能在容器初始化时调用一次,使用过滤器的目的,是用来做一些过滤操作,比如获取我们需要的数据,或者提前设置一些参数\n\n2.拦截器,依赖于 web 框架,基于 java 反射机制实现,属于 aop 的一种应用,就是在 service 或者一个方法前,或者方法后等多个位置进行拦截,同一个拦截器实例在一个 controller 生命周期中可以多次调用,但是缺点是只能对 controller 请求进行拦截,对于其他一些比如直接访问静态资源的请求则没有办法进行拦截\n","tags":["interview","spring"]},{"title":"mysql事务导致的一些问题","url":"/article/61951fe.html","content":"\n1.第一类丢失更新\n\n撤销一个事务的时候,把其他事务已提交的更新数据覆盖了;这是完全没有事务隔离级别造成的;如果事务 1 被提交,另一个事务被撤销,那么会连同事务 1 所作的更新也被撤销\n\n2.第二类丢失更新\n\n当两个或多个事务查询相同的记录,然后各自基于查询的结果更新记录时,会造成第二类更新丢失的问题;每个事务不知道其他事务的存在,最后一个事务对记录所作的更改将覆盖其他事务之前对该记录的更改\n\n3.脏读\n\n如果一个事务对数据进行了更新,但事务还没有提交,另外一个事务就可以\"看到\"该事务没有提交的更新结果;这样造成的问题就是,如果第一个事务回滚,那么第二个事务在此之前\"看到\"的数据就是脏数据\n\n4.幻读\n\n一个事务(同一个 read view)在前后两次查询同一范围的时候，后一次查询看到了前一次查询没有看到的行\n\n5.不可重复读\n\n不可重复读是指同一个事务在整个事务过程中对同一笔数据进行读取,每次读取结果不同.如果事务 1 在事务 2 的更新操作之前读一次数据,在事务 2 的更新操作之后再读取同一笔数据一次,两次结果是不同的\n","tags":["mysql"]},{"title":"mvcc 多版本并发控制","url":"/article/ba4a4566.html","content":"\n### 什么是 mvcc\n\nmvcc，Multi-version Concurrency Control，即多版本并发控制。mvcc 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存\n\nMVCC 在 mysql InnoDB 中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读\n\n### 什么是当前读和快照读\n\n1.当前读\n\n像 select lock in shared mode(共享锁)，select for update。 update，insert， delete(排他锁)这些操作都是一种当前读，为什么叫当前读?就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录加锁\n\n2.快照读\n\n像不加锁的 select 操作就是快照读，即不加锁的非阻塞读。快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化为当前读。之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即 MVCC。可以认为 MVCC 是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销.既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本\n\n说白了 MVCC 就是为了实现读-写冲突不加锁，而这个读指的就是快照读，而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现\n\n### 当前读，快照读和 mvcc 什么关系\n\n1.准确的说，MVCC 指的是\"维持一个数据的多个版本，使得读写操作没有冲突\"这么一个概念，仅仅是一个理想概念\n\n2.而在 mysql 中，快照读就是实现 mvcc 理想模型的其中一个具体非阻塞读功能。而相对而言，当前读就是悲观锁的具体功能实现\n\n3.快照读本身也是一个抽象概念。MVCC 模型在 mysql 中的具体实现是由 3 个隐式字段，undo 日志，read view 等去完成的\n\n### mvcc 能解决什么问题\n\n数据库并发场景有 3 种，分别是:\n\n读-读:不存在任何问题，也不需要并发控制\n\n读-写:有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读\n\n写-写:有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失\n\nMVCC 带来的好处是?\n\nMVCC 是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务快照读之前的数据库的快照，所以 MVCC 可以为数据库解决以下问题\n\n1.在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能\n\n2.同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题\n\n组合:\n\n1.MVCC+悲观锁\n\nmvcc 解决读写冲突，悲观锁解决写写冲突\n\n2.mvcc+乐观锁\n\nmvcc 解决读写冲突，乐观锁解决写写冲突\n\n### mvcc 的实现原理\n\nmvcc 的实现原理主要是依赖记录中的 3 个隐式字段，undo 日志，Read view 来实现的\n\n#### 隐式字段\n\n每行记录除了我们自定义的字段外，还有数据库隐式定义的 DB_TRX_ID，DB_ROLL_PTR，DB_ROW_ID 等字段\n\nDB_TRX_ID: 6byte，最近修改(修改/插入)事务 ID:记录创建这条记录/最后一次修改该记录的事务 ID\n\nDB_ROLL_PTR: 7byte，回滚指针，指向这条记录的上一个版本(存储于 rollback segment 里)\n\nDB_ROW_ID: 6byte，隐含的自增 id(隐藏主键)，如果数据表没有主键，InnoDB 会自动以 DB_ROW_ID 产生一个聚簇索引\n\n实际上还有一个删除 flag 隐藏字段，既记录被更新或删除并不代表真的删除，而是删除 flag 变了\n\n![mvcc-2021-03-27-11-56-1620210327115615](https://i.loli.net/2021/03/27/DcY6TvGL7xl1Bq3.png)\n\n#### undo 日志\n\nundo log 主要分为两种:\n\ninsert undo log:代表事务在 insert 新记录时产生的 undo log，只在事务回滚时需要，并且在事务提交后可以被立即丢弃\n\nupdate undo log:事务在进行 update 或者 delete 时产生的 undo log。不仅在事务回滚时需要，在快照读时也需要。所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被 purge 线程统一清除\n\n##### purge 线程\n\n从前面的分析可以看出，为了实现 InnoDB 的 mvcc 机制，更新或者删除操作都只是设置一下老记录的 deleted_bit，并不真正将过时的记录删除\n\n为了不影响磁盘空间，InnoDB 有专门的 purge 线程来清理 deleted_bit 为 true 的记录。为了不影响 MVCC 的正常工作，purge 线程自己也维护了一个 read view(这个 read view 相当于系统中最老活跃事务的 read view)。\n\n如果某个记录的 deleted_bit 为 true，并且 DB_TRX_ID 相对于 purge 线程的 read view 可见，那么这条记录一定是可以被安全清除的\n\n对 MVCC 有帮助的实质是 update undo log， undo log 实际上就是存在 rollback segment 中旧记录链，它的执行流程如下:\n\n1.比如有个事务插入了 person 表插入了一条新纪录，记录如下:name 为 zhangsan，age 为 20，隐式主键是 1，事务 ID 和回滚指针，我们假设为 null\n\n![mvcc-2021-03-27-12-00-1220210327120011](https://i.loli.net/2021/03/27/d95jPMtuNVyCIZE.png)\n\n2.现在来了个事务 A 对该记录的 name 做了修改，改为 lisi\n\na.在事务 A 修改该行记录时，数据库会先对该行加排他锁\n\nb.然后把该行数据拷贝到 undo log 中，作为旧纪录，即在 undo log 中有当前行的拷贝副本\n\nc.拷贝完毕后，修改该行 name 为 lisi ，并且修改隐藏字段的事务 ID 为当前事务 A 的 Id，默认从 1 开始，之后递增，回滚指针指向拷贝到 undo log 的副本记录，即表示当前的上一个版本\n\nd.事务提交后，释放锁\n\n![mvcc-2021-03-27-13-18-2920210327131828](https://i.loli.net/2021/03/27/spNYXjCkzRmODlE.png)\n\n3.又一个事务 B，修改同一条记录，将 age 改为 25\n\na.在事务 B 修改该行数据时，数据库也先为该行加锁\n\nb.然后把该行数据拷贝到 undo log，作为旧记录，发现该行已经有了 undo log，那么最新的旧数据作为链表的表头，插在该行记录的 undo log 最前面\n\nc.修改 age 为 25，并且修改隐藏字段事务 id 为当前事务 B 的 id，自增即为 2，回滚指针指向刚刚拷贝到 undo log 的副本记录\n\nd.提交事务，释放锁\n\n![mvcc-2021-03-27-13-24-5620210327132456](https://i.loli.net/2021/03/27/WnqcEB7CONwSpmH.png)\n\n从上面我们就可以看出，不同事务或者相同事务对同一条记录进行修改，就会导致该记录的 undo log 成为一条记录版本线性表，即链表，undo log 的链首就是最新的旧记录，链尾就是最早的一条旧记录(当然就像之前说的该 undo log 的节点可能会被 purge 线程清除掉，像图中的第一条 insert undo log，其实在事务提交之后可能就被删除丢失了)\n\n#### read view (读视图)\n\n什么是 read view\n\nread view 就是事务进行快照读操作的时候产生的读视图，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的 ID(当每个事务开启时，都会被分配一个 ID，这个 ID 是递增的，所以最新的事务 ID 最大)\n\nread view 主要是用来做可见性判断的，主要是将要被修改的数据的最新记录中 DB_TRX_ID 取出来，与系统当前其他活跃事务的 ID(由 Read view 维护)去对比，如果 DB_TRX_ID 跟 Read View 的属性做了某些比较，不符合可见性，那就通过 DB_ROLL_PTR 回滚指针去取出 undo log 的 DB_TRX_ID 再比较，即遍历链表的 DB_TRX_ID(从链首到链尾，即从最近的一次修改查起)，直到找到满足特定条件的 DB_TRX_ID，那么这个 DB_TRX_ID 所在的旧记录就是当前事务能看见的最新的老版本\n\n![mvcc-2021-03-27-13-50-5720190314144440494](https://i.loli.net/2021/03/27/zpEsh6bnorYviVP.png)\n\n那么这个判断条件是什么呢?如上，它是一段判断可见性的源码，即 changes_visible 方法，该方法展示了我们拿 DB_TRX_ID 去跟 read view 某些属性进行怎样的比较\n\n在展示之前，我们可以把 read view 简单的理解成有三个全局属性\n\n- trx_list :一个数值列表，用来维护 Read view 生成时刻系统正活跃的事务 id\n\n- up_limit_id: 记录 trx_list 列表中事务 id 最小的 id\n\n- low_limit_id: read view 生成时刻系统尚未分配的下一个事务 id，也就是目前已经出现过的事务 id 的最大值+1\n\na.首先比较 DB_TRX_ID < up_limit_id，如果小于，则当前事务能看到 DB_TRX_ID 所在的记录，如果大于等于进入下一个判断\n\nb.接下来判断 DB_TRX_ID 大于等于 low_limit_id，如果大于等于代表 DB_TRX_ID 所在的记录是在 read view 生成后才出现的，那对当前事务肯定不可见，如果小于则进入下一个判断\n\nc.判断 DB_TRX_ID 是否在活跃事务之中，trx_list.contains(DB_TRX_ID)，如果在则代表 Read view 生成时刻，DB_TRX_ID 对应的事务还在活跃，还没有 commit，DB_TRX_ID 对应事务修改的数据，当前事务也是看不见的。如果不在，说明 DB_TRX_ID 对应的事务在 read view 生成之前就已经 commit，DB_TRX_ID 对应的事务修改的结果，当前事务是能看见的\n\n### mvcc 整体流程\n\n1.事务 A 和事务 C 进行中时，事务 B 对某行数据执行了快照读，数据库为该行数据生成了一个 read view 读视图，假设当前事务 ID 为 2，此时还有事务 A 和事务 C 在活跃中，事务 D 在事务 B 快照读前一刻提交更新了，所以 read view 记录了系统当前活跃事务 A，C 的 id，维护在一个列表上，假设称之为 trx_list\n\n![mvcc-2021-03-27-14-38-5820210327143858](https://i.loli.net/2021/03/27/thWsT4mCryQSzcj.png)\n\n2.read view 并不仅仅会通过一个列表 trx_list 来维护事务 B 执行快照读那刻系统正活跃的事务 Id，还会有两个属性 up_limit_id(记录 trx_list 列表中事务 ID 最小的 ID)，low_limit_id(记录 trx_list 列表中事务 ID 最大的 ID，也有人说快照读那刻系统尚未分配的下一个事务 ID 也就是目前已经出现过的事务 ID 的最大值+1)。所以在这里 up_limit_id 就是 1，low_limit_id 就是 4+1=5，trx_list 集合的值就是[1，3]，read view 如下图\n\n![mvcc-2021-03-27-15-01-1320210327150112](https://i.loli.net/2021/03/27/nIyzJmfNbRGHdgU.png)\n\n3.目前只有事务 D 修改过记录， 并在事务 B 执行快照读之前提交了事务，所以当前该行当前数据的 undo log 如下图所示。事务 B 在快照读该行记录的时候，就会拿该行记录的 DB_TRX_ID 去跟 up_limit_id，low_limit_id 和活跃事务 id 列表进行比较，判断当前事务 B 能看到该记录的版本是哪个\n\n![mvcc-2021-03-27-15-07-5220210327150752](https://i.loli.net/2021/03/27/dm9sZU1N4cOCv6a.png)\n\n4.所以先拿该记录 DB_TRX_ID 字段记录的事务 ID4 去和 read view 的 up_limit_id 比较，看 4 是否小于 up_limit_id(1)，所以不符合条件。继续判断 4 是否大于等于 low_limit_id(5)，也不符合条件。最后判断活跃事务列表中的活跃事务 id，发现 4 不在列表中，符合可见性条件，所以事务 D 修改后提交的最新结果对事务 B 快照读时是可见的，所以事务 B 能读到的最新数据记录是事务 D 所提交的版本，而事务 D 提交的版本也是全局角度上的最新的版本\n\n![mvcc-2021-03-27-15-43-5620210327154355](https://i.loli.net/2021/03/27/8EiAjucqtBNdH5L.png)\n\n5.也正是 read view 生成的时机不同，造成 RC，RR 隔离级别下快照读的结果不同\n\n### MVCC 相关问题\n\n#### RR 是如何在 RC 的基础上解决不可重复读的\n\n##### 当前读和快照读在 RR 级别下的区别\n\n![mvcc-2021-03-27-15-52-0720210327155207](https://i.loli.net/2021/03/27/1C8AVSekYQbm5hK.png)\n\n在上表的顺序下，事务 B 在事务 A 提交修改之后的快照读依旧是旧版本数据，而当前读是最新的数据\n\n![mvcc-2021-03-27-15-55-3020210327155529](https://i.loli.net/2021/03/27/GcV5LjwKzxBEdh1.png)\n\n在第二张表的顺序下，事务 B 在事务 A 提交之后的快照读和当前读都是最新的数据 400。这里与第一张表的区别仅仅是第一张表的事务 B 在事务 A 修改金额前快照读过一次金额数据，而第二章表的事务 B 在事务 A 修改金额前没有进行过快照读\n\n所以我们知道事务中快照读的结果是非常依赖该事务首次出现快照读的地方，即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力\n\n这里展示的是更新的流程，同时删除也是一样的，如果事务 B 的快照读是在事务 A 操作之后进行的，事务 B 的快照读也能读到最新的数据\n\n##### RC，RR 级别下的 InnoDB 快照读有什么不同\n\n正是 read view 生成时机的不同，从而造成 RC，RR 级别下快照读的结果的不同\n\n- 在 RR 级别下的某个事务对某记录的第一次快照读会创建一个快照和 Read View，将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的同一个 read view，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个 read view，所以之后的修改对其不可见\n\n- 即 RR 级别下，快照读生成 read view 时，read view 会记录此时其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于 Read view 创建的事务所作的修改均是可见的\n\n- 而在 RC 级别下，事务中每次快照读都会新生成一个快照和 read view ，这就是我们在 RC 级别下的事务中可以看到别的事务提交的更新的原因\n\n总之在 RC 隔离级别下，是每个快照读都会生成并获取最新的 read view 。而在 RR 级别下，则是同一个事务中的第一个快照读才会创建 Read view，之后的快照读获取的都是同一个 read view\n","tags":["mysql","mvcc"]},{"title":"linux常用操作指令","url":"/article/c2128012.html","content":"\n### 查询日志尾部最后 10 行的日志\n\ntail -n 10 test.log\n\n### 查询 10 行之后的所有日志\n\ntail -n +10 test.log\n\n### 查询前 10 行\n\nhead -n 10 test.log\n\n### 查询除了最后 10 行之外所有的日志\n\nhead -n -10 test.log\n\n### 按行号查看,过滤出关键字附近的日志\n\n1.cat -n test.log | grep \"关键字\" 得到关键字所在行号\n\n2.得到行号是 102,查看行号前后 10 行的日志\n\ncat -n test.log | tail -n +92 | head -n 20\n\ntail -n +92 表示查询 92 行之后的日志\n\nhead -n 20 表示在前面的查询结果里再查找 20 条记录\n\n### 按日期查询指定时间段的日志\n\nsed -n '/2021-03-26 10:26:46/,/2021-03-26 10:26:47/p' test.log\n\n### 查找某文件里带某个关键字\n\nfind -name '`*`.`*`' | xargs grep “248821000002741”\n\n### 查询多个关键字\n\ngrep -E \"关键字 1|关键字 2|关键字 3\" test.log\n\n### 查找指定名称的文件\n\nfind / -name test.log\n\n### 输出第 10 行\n\nsed -n '10p' file.txt\n","tags":["linux"]},{"title":"raft算法","url":"/article/52ae1042.html","content":"\nraft 算法是一种简单易懂的共识算法,它依靠状态机和主从同步的方式,在各个节点之间实现数据的一致性\n\nraft 的两个核心要点:\n\n1.选取主节点\n\n2.同步数据\n\nraft 算法在选取主节点的过程,也是通过多个节点之间的投票竞争\n\nraft 算法为节点定义了三种角色:\n\n1.Leader(主节点)\n2.Follower(从节点)\n3.Candidate(参与投票竞争的节点/候选人)\n\n选主的流程:\n\n1.在最初的,还没有一个主节点的时候,所有节点的身份都是 follower;每一个节点都有自己的计时器,当计时器达到了超时时间(Election Timeout),该节点会转变为 Candidate\n\n2.成为 Candidate 的节点,会首先给自己投票,然后向集群中其他所有的节点发起请求,要求大家都给自己投票\n\n3.其他收到投票请求且还未投票的 Follower 节点会向发起者投票,发起者收到反馈通知后,票数增加\n\n4.当得票数超过了集群节点的一半,该节点晋升为 Leader 节点;Leader 节点会立即向其他节点发出通知,告诉大家自己才是老大;收到通知的节点全部变为 Follower,同时将自己的计时器清零\n\n这里需要注意,每个节点的超时时间都是不一样的;比如 A 节点的超时时间是 3 秒,B 节点的超时时间是 5 秒,C 节点的超时时间是 4 秒,这样一来 A 节点将会最先发起投票请求,而不是所有的节点同时发起\n\n为什么这样设计呢,设想所有的节点同时发起投票,必然会导致大家的票数差不多,形成僵局,谁也当不成老大\n\n那么,成为 leader 的节点是否就坐稳了老大的位置呢?并不是,Leader 节点需要每隔一段时间向集群其他节点发送心跳通知,表明它还活着;\n\n一旦 Leader 节点挂掉,发不出通知,那么计时到达了超时时间的 Follower 节点会转变为 Candidate 节点,发起选主投票,周而复始.\n\n数据同步的流程:\n\n1.客户端提交数据到 Leader 节点\n\n2.由 Leader 节点把数据复制到集群内的所有 Follower 节点,如果一次复制失败,会不断进行重试\n\n3.Follower 节点们接收到数据,会反馈给 Leader 节点\n\n4.如果 leader 节点接收到超过半数的 Follower 反馈,表明复制成功.于是提交自己的数据,并通知客户端数据提交成功\n\n5.由 Leader 节点通知集群内所有的 Follower 节点提交数据,从而完成数据同步流程\n\n共识算法的应用场景:\n\n1.在用于共享配置和服务发现的 K-V 存储系统 etcd 中,使用的就是 Raft 算法来保证分布式一致性\n\n除了 raft 之外,还有哪些算法解决了拜占庭将军问题:\n\n1.Paxos 算法\n\n早期的共识算法,由拜占庭将军问题的提出者 Leslie Lamport 所发明;谷歌的分布式锁服务 Chubby 就是以 Paxos 算法为基础\n\n2.ZAB 算法\n\nZookeeper 所用的一致性算法,在流程上和 Raft 算法比较接近\n\n3.PBFT 算法\n\n区块链技术所用的共识算法之一,适用于私有链的共识\n","tags":["raft"]},{"title":"面试问题及答案","url":"/article/b0523a70.html","content":"\n### new Object()占多少个字节\n\n- mark word(8 字节)+klass(4 字节,默认开启指针压缩)+padding(4 字节) = 16 字节\n\n- mark word(8 字节)+klass(8 字节,不开启指针压缩) = 16 字节\n\n### User (int id,String name) User u = new User(1,\"李四\")\n\nmark word(8 字节)+klass(4 字节,默认开启指针压缩)+instance data int(4 字节) + 开启普通对象指针压缩后 String(4 字节)+padding(4 字节) = 24 字节\n\n### 线程交替打印\n\n实现两个线程交替打印,实现字母在前数字在后,可以用信号量,synchronized 关键字和 Lock 实现\n\n```java\nimport java.util.concurrent.CountDownLatch;\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class Main {\n private static Lock lock = new ReentrantLock();\n private static Condition c1 = lock.newCondition();\n private static Condition c2 = lock.newCondition();\n private static CountDownLatch count = new CountDownLatch(1);\n\n public static void main(String[] args) {\n  String c = \"ABCDEFGHI\";\n  char[] ca = c.toCharArray();\n  String n = \"123456789\";\n  char[] na = n.toCharArray();\n\n  Thread t1 = new Thread(() -> {\n   try {\n    lock.lock();\n    count.countDown();\n    for(char caa : ca) {\n     c1.signal();\n     System.out.print(caa);\n     c2.await();\n    }\n    c1.signal();\n   } catch (InterruptedException e) {\n    e.printStackTrace();\n   } finally {\n    lock.unlock();\n   }\n  });\n\n  Thread t2 = new Thread(() -> {\n   try {\n    count.await();\n    lock.lock();\n    for(char naa : na) {\n     c2.signal();\n     System.out.print(naa);\n     c1.await();\n    }\n    c2.signal();\n   } catch (InterruptedException e) {\n    e.printStackTrace();\n   } finally {\n    lock.unlock();\n   }\n  });\n\n  t1.start();\n  t2.start();\n }\n}\n\n```\n\n### 线程之间如何通信\n\n- 共享内存: 隐式通信\n\n- 消息传递: 显示通信\n\n### 线程之间如何同步\n\n- 在共享内存的并发模型中,同步是显示做的; synchronized\n\n- 在消息传递的并发模型中,由于消息发布必须在消息接收之前,所以同步是隐式\n\n### volatile 和 Synchronized 区别\n\n#### volatile 可见性/原子性,不能做到复合操作的原子性\n\n1.对于声明了 volatile 的变量进行写操作的时候,JVM 会向处理器发送一条 Lock 前缀的指令,会把这个变量所在缓存行的数据写回到主内存\n\n2.在多处理器的情况下,保证各个处理器缓存一致性的特点,就会实现缓存一致性协议\n\n#### synchronized 可重入锁/互斥性/可见性/有序性\n\n### 如何保证多线程顺序执行\n\n- 通过 join: 让主线程等待子线程执行结束之后才能继续进行\n- 单线程的线程池: Executors.newSingleThreadExecuotr();\n\n### Lock 和 Synchronized 区别\n\nLock: java5 以后出现的 JUC 包中的(java.util.concurrent.locks)\n\n1.Synchronized 锁什么时候释放\n\n- 获取锁的线程执行完了该代码块\n\n- 线程执行出现异常\n\n### 线程和进程的概念\n\n每个应用程序是一个进程,一个进程里可以运行多个线程,多个线程是为了更好的利用 CPU 资源\n\n### 两个 Integer 的引用对象传给一个 swap 方法在方法内部进行交换,返回后,两个引用的值是否会发生变化\n\n```java\nprivate static void swap(Integer a, Integer b) throws NoSuchFieldException, IllegalAccessException {\n        Field field = Integer.class.getDeclaredField(\"value\");\n        field.setAccessible(true);\n        Integer temp = new Integer(a.intValue());\n        field.set(a, b);\n        field.set(b, temp);\n    }\n```\n\n### 阻塞 IO 和非阻塞 IO\n\n### 七层网络模型\n\n应用层\n表示层\n会话层\n传输层\n网络层\n数据链路层\n物理层\n\n### mysql 的 binlog\n\n记录 mysql 的数据更新和潜在更新\n\n主从复制依赖 binlog\n\nmaster 写数据之后写到 binlog,发送事件通知\n\nslave IO 线程读取 binlog,写入 relay log\n\nslave sql 线程从 relay log 读取语句执行\n\n三种格式:\nstatement: 基于 sql 语句\n\nrow: 基于行模式,记录变更的数据\n\nmixed: 混合模式,\n\n### cookie 和 session 的关联关系\n\ncookie 在客户端保存信息,session 在服务端保存信息\n\n服务端生成 JSESSIONID,当作 key 存入 ConcurrentHashMap,value 存储客户端信息,将 JSESSIONID 返回给客户端\n\n客户端将 JSESSIONID 存入 cookie\n\n把用户信息存储到 session 中,关闭浏览器,session 就失效了\n\n分布式架构 session 共享和 session 复制\n\n1.session 复制:每个节点都复制 session\n\n2.客户端保存唯一 id,服务端把 session 存入 redis\n\n3.jwt\n\n### AOP 底层实现原理\n\n- 动态代理\n\n- 字节码\n\n### 为什么不能直接调用 run()方法启动线程\n\nJVM 执行 start()方法,会另外启动一个线程去执行 thread 的 run()方法,这时执行 start()的方法和执行 run()方法的线程会并行,\n\n重复执行 start()方法,会抛出 IllegalThreadStateException\n\n### 如何保证多线程下 i++结果正确\n\n- 使用 CAS+原子类\n\n- 使用锁机制\n\n- 使用 synchronized\n\n### 谈谈你理解的 HashMap,讲讲其中的 get put 过程\n\n#### 1.8 做了什么优化?\n\n#### 是线程安全的嘛?\n\n#### 不安全会导致哪些问题?\n\n#### 如何解决?有没有线程安全的并发容器?\n\n### ConcurrentHashMap 是如何实现的?1.7、1.8 实现有何不同,为什么这么做\n\n### 1.8 中 ConcurrentHashMap 的 sizeCtl 作用,大致说下协助扩容跟标志位\n\n### HashMap 为什么不用跳表替换红黑树呢?\n\n### synchronized 跟 ReentrantLock 使用区别跟底层实现以及重入底层原理\n\n### 描述下锁的四种状态跟升级过程\n\n### CAS 是什么?CAS 的弊端是什么?\n\n### 你对 volatile 的理解,可见性跟指令重排咋实现的\n\n### 一个对象创建过程是怎么样的对象在内存中如何分布的,看 JVM 即可\n\n### 聊一聊单例模式,为什么 DCL 要用 volatile\n\n### 你对 as-if-serial 跟 happpends-before 的理解\n\n### ThreadLocal 说一说,咋解决内存泄露\n\n### 自旋锁一定比重量级锁效率高吗?偏向锁是否效率一定提高\n\n### 线程池聊一聊如何用 注意细节,如何实现\n\n### 你对 JMM 理解?\n\n### Synchronized 可以实现指令重排么?它是如何保证有序性的?\n\n### 聊一聊 AQS,为什么 AQS 底层是 CAS + Volatile\n\n### 为什么不建议用 uuid 做 MySQL 的主键\n\n#### 1.适用自增 id 的内部结构\n\n![2021-04-08-14-07-4420210408140743](https://i.loli.net/2021/04/08/1SZF4tA7e6s2NJl.png)\n\n自增主键的值是顺序的，所以 innoDB 把每一条记录都存储在之前记录的后面。当达到页面的最大填充因子的时候（innoDB 默认的最大填充因子是页大小的 15/16，会留出 1/16 的空间留作以后的修改）\n\n这样做的好处是：\n\n- 下一条记录就会写入新的页中，一旦数据按照这种顺序的方式加载，主键页就会近乎于顺序的记录填满，提升了页面的最大填充率，不会有页的浪费\n\n- 新插入的行一定会在原有的最大行的下一行，mysql 定位和寻址很快，不会为计算新行的位置而做出额外的消耗\n\n- 减少了页分裂和碎片的产生\n\n#### 2.使用 uuid 的索引内部结构\n\n![2021-04-08-14-35-0820210408143507](https://i.loli.net/2021/04/08/QtkPNfz9H85voxZ.png)\n\n插入 UUID：新的记录可能会插入之前记录的中间，新的行需要强制移动之前的记录\n\n被写满已经刷新到磁盘上的页可能会被重新读取\n\n因为 UUID 相对顺序的自增 id 来说是毫无规律可言的，新行的值不一定要比之前的主键的值大，所以 innoDB 无法做到总是把新行插入到索引的最后，而是需要为新行寻找新的合适的位置从而来分配新的空间\n\n这个过程需要做很多额外的操作，数据的毫无顺序会导致数据分布散乱。将会导致以下的问题：\n\n- 写入的目标页很可能已经刷新到磁盘上并且从缓存中移除，或者还没有被加载到缓存中，innoDB 在插入之前不得不先找到并从磁盘读取目标页到内存中，这将导致大量的随机 IO\n\n- 因为写入时乱序的，innoDB 不得不频繁的做页分裂操作，以便为新的行分配空间，页分裂导致移动大量的数据，一次插入最少需要修改 3 个页以上\n\n- 由于频繁的页分裂，页会变得稀疏并被不规则的填充，最终会导致数据有碎片\n\n在把随机值载入到聚簇索引以后，有时候会需要做一次 OPTIMEIZE TABLE 来重建表并优化页的填充，这将又需要一定的时间消耗\n\n结论：使用 innodb 应该尽可能的按主键的自增顺序插入，并且尽可能使用单调的增加的聚簇键的值来插入新行\n\n#### 3.使用自增 id 的缺点\n\n自增 id 也会存在以下几点问题：\n\n- 1.别人一旦爬取你的数据库，就可以根据数据库的自增 id 获取到你的业务增长信息，很容易分析出你的经营情况\n\n- 2.对于高并发的负载，innodb 在按主键进行插入的时候会造成明显的锁竞争，主键的上界会成为争抢的热点，因为所有的插入都发生在这里，并发插入会导致间隙锁竞争\n\n- 3.Auto_Increment 锁机制会造成自增锁的抢夺，有一定的性能损失\n","tags":["interview"]},{"title":"多线程面试知识点(持续更新)","url":"/article/1bbbbb30.html","content":"\n### 1.线程间同步\n\n#### 为何要使用同步?\n\njava 允许多线程并发控制,当多个线程同时操作一个可共享的资源变量时,将会导致数据的不准确,相互之间产生冲突,因此可以加入同步锁以避免在该线程没有完成对数据的操作之前,数据被其他线程调用,从而保证了该变量的唯一性和准确性\n\n#### 同步的方式\n\n1.同步方法或同步代码块:synchronized 关键字或 Lock 锁\n\n2.volatile 关键字\n\n3.使用 ThreadLocal\n\n4.阻塞队列\n\n5.使用原子变量\n\n### 2.ThreadLocal\n\n#### ThreadLocal 是什么\n\nThreadLocal 是一个本地线程副本变量工具类;主要用于将私有线程和该线程存放的副本对象做一个映射,各个线程之间的变量互不干扰,在高并发场景下,可以实现无状态的调用,适合各个线程不共享变量值的操作\n\n#### ThreadLocal 工作原理\n\n每个线程内部都维护了一个 ThreadLocalMap,是一个键值对数据格式,key 是一个弱引用,也就是 ThreadLocal 本身,value 存的是线程变量的值\n\n也就是说 ThreadLocal 本身并不存储线程的变量值,它只是一个工具,用来维护线程内部的 Map,帮助存和取变量\n\n#### ThreadLocal 如何解决 Hash 冲突\n\n与 HashMap 不同,ThreadLocalMap 结构非常简单,没有 next 引用,也就是说 ThreadLocalMap 中解决 hash 冲突的方式并非链表的方式,而是采用线性探测的方式.所谓线性探测,就是根据初始 Key 的 hashcode 值确定元素在 table 数组中的位置,如果发现这个位置上已经被其他 key 值占用,则利用固定的算法寻找一定步长的下个位置,依次判断,直至找到能够存放的位置\n\n```java\n/\n * Increment i modulo len.\n */\nprivate static int nextIndex(int i, int len) {\n    return ((i + 1 < len) ? i + 1 : 0);\n}\n\n/\n * Decrement i modulo len.\n */\nprivate static int prevIndex(int i, int len) {\n    return ((i - 1 >= 0) ? i - 1 : len - 1);\n}\n```\n\n#### ThreadLocal 的内存泄露是怎么回事\n\nThreadLocal 在 ThreadLocalMap 中是以一个弱引用身份被 Entry 中的 key 引用的,因此如果 ThreadLocal 没有外部强引用来引用它,那么 ThreadLocal 会在下次 JVM 垃圾回收时被回收;这个时候 Entry 中的 Key 已经被回收,但是 value 又是一强引用所以不会被垃圾回收器回收,这样 ThreadLocal 的线程如果一直持续运行,value 就一直得不到回收,这样就会发生内存泄漏\n\n如何解决:\n\n使用完 ThreadLocal 后,及时调用 remove()方法释放内存空间\n\n#### 为什么 ThreadLocal 的 key 是弱引用\n\n- key 使用强引用,这样会导致一个问题:引用 ThreadLocal 的对象被回收了,但是 ThreadLocalMap 还持有 ThreadLocal 的强引用,如果没有手动删除,ThreadLocal 不会被回收,则导致内存泄漏\n\n- key 使用弱引用,这样的话,引用 ThreadLocal 的对象被回收了,由于 ThreadLocalMap 持有 ThreadLocal 的弱引用,即使没有手动删除,ThreadLocal 也会被回收;value 在下一次 ThreadLocalMap 调用 set,get,remove 的时候会被清除\n\n比较以上两种情况,我们可以发现:由于 ThreadLocalMap 的生命周期跟 Thread 一样长,如果都没有手动删除对应 key,都会导致内存泄漏,但是使用弱引用可以多一层保障,弱引用的 ThreadLocal 不会内存泄漏,对应的 value 在下一次 ThreadLocalMap 调用 set,get,remove 的时候被清除,算是最优的解决方案\n\n#### ThreadLocal 的应用场景\n\n会话管理\n\n### CountDownLatch 与 CyclicBarrier 区别\n\nCountDownLatch: 一个或者多个线程,等待其他线程完成某件事情之后才能执行\n\nCyclicBarrier: 多个线程互相等待,直到到达同一个同步点,再继续一起执行\n\nCountDownLatch 是递减计数,CyclicBarrier 是递增计数\n\nCountDownLatch 不可重复利用,CyclicBarrier 可以重复利用\n\nCountDownLatch 初始值为 N,N>0,CyclicBarrier 初始值 N=0\n\nCountDownLatch 调用 countDown(),N-1,CyclicBarrier 调用 await(),N+1\n\nCountDownLatch 在 N>0 时,调用 await() 一直阻塞,CyclicBarrier 在 N 小于指定值时,一直阻塞\n\nCountDownLatch 在计数为 0 时释放等待线程,CyclicBarrier 在计数达到指定值时释放等待线程\n\n### 为什么要使用线程池\n\n- 管理线程,避免增加创建线程和销毁线程的系统资源消耗\n- 提高相应速度\n- 资源重复利用\n\n### 线程池核心的执行流程\n\n- 提交任务,判断核心线程是否已满,未满则创建新的核心线程执行任务\n- 如果核心线程池已满,判断队列是否已满,未满则将任务存入队列\n- 如果队列已满,判断非核心线程数是否已满,未满则创建非核心线程执行任务\n- 如果非核心线程已满,执行拒绝策略\n\n### 线程池提供的四种拒绝策略\n\n- AbortPolicy(抛出一个异常,默认策略)\n- DiscardPolicy(直接丢弃任务)\n- DiscardOldestPolicy(丢弃队列里最老的任务,将当前任务继续存入队列)\n- CallerRunsPolicy(由调用线程池所在线程执行任务)\n\n### 几种工作阻塞队列\n\n- ArrayBlockingQueue(用数组实现的有界阻塞队列,按 FIFO 顺序)\n- LinkedBlockingQueue(基于链表结构的阻塞队列,按 FIFO 排序,可以选择性设置容量,不设置默认为 Integer.MAX_VALUE,即无界队列)\n- DelayQueue(支持延迟获取元素的阻塞队列)\n- PriorityBlockingQueue(具有优先级的无界队列)\n- SynchronousQueue(一个不存储元素的阻塞队列,每个插入操作必须等到另外一个线程执行移除操作,否则插入一直处于阻塞状态)\n\n### 线程生命周期\n\n- NEW:创建后尚未启动的线程处于此状态\n- RUNNABLE:包括操作系统线程状态中的 Running 和 Ready,也就是线程可能处于执行中状态,也可能正在等待 CPU 为之分配执行时间\n- WAITING:无限期等待状态,处于此状态的线程不会被分配 CPU 执行时间,需要等待被其他线程显式唤醒(notify/notifyAll),主要包括:没有显示设置 timeout 的 Object.wait();没有显示设置 timeout 的 Thread.join();LockSupport.park();\n- TiMED_WAITING:有限期等待状态,处于此状态的线程不会被分陪 CPU 执行时间,无须等待其他线程显式唤醒,在一定时间之后会自动唤醒,主要包括:Thread.sleep(timeout);Object.wait(timeout);Thread.join(timeout);LockSupport.parkNanos(timeout);LockSupport.parkUnit(timeout)\n- BLOCKED:阻塞状态,处于此状态的线程不会被分配 CPU 执行时间,发生情况:竞争对象监视器锁或 Object.wait()结束后重新竞争对象监视器控制权\n- TERMINATED:终止状态,线程执行完毕,生命周期结束\n\n### 阻塞与等待的区别\n\n#### 阻塞\n\n当一个线程试图获取对象锁(非 JUC 中的锁,即 synchronized),而该锁被其他线程持有,则该线程进入阻塞状态;它的特点是使用简单,由 JVM 调度器来唤醒自己,而不需要另一个线程来显式唤醒自己,不响应中断\n\n#### 等待\n\n当一个线程等待另一个线程通知调度器一个条件时,该线程进入等待状态;它的特点是需要等待另外一个线程显式地唤醒自己,实现灵活,语义更丰富,可响应中断;例如调用:Object.waite(),Thread.join().以及等待 Lock 或 Condition\n\n虽然 synchronized 和 JUC 里的 Lock 都实现锁的功能,但线程进入的状态是不一样的;synchronized 会让线程进入阻塞状态,而 JUC 中的 Lock 是用 park()/unpark()来实现阻塞/唤醒的,会让线程进入等待状态;虽然等锁时进入的状态不一样,但被唤醒后又都进入 Runnable 状态,从行为效果来看是一样的\n\n### yield()和 sleep() 的区别\n\n1. yield 和 sleep 都能暂停当前线程,都不会释放锁资源,sleep 可以指定具体休眠的时间,而 yield 依赖 cpu 的时间划分\n\n2. sleep 给其他线程运行机会时不考虑线程的优先级,因此会给低优先级的线程以运行的机会;yield 方法只会给相同或者更高优先级的线程以运行的机会\n\n3. 调用 sleep 方法使线程进入等待状态,等待睡眠时间到达,而调用 yield 方法,线程会进入就绪状态,也就是 sleep 需要等待设置的时间后才会进入的就绪状态,而 yield 会立即进入就绪状态\n\n4. sleep 方法会抛出 InterruptedException,而 yield 不抛出任何异常\n\n5. yield 不能被中断,而 sleep 方法可以接受中断\n\n6. sleep 方法比 yield 方法有更好的移植性\n\n### wait 和 sleep 的区别\n\n1. wait 来自 Object,sleep 来自 Thread\n\n2. wait 释放锁,sleep 不释放锁\n\n3. wait 必须在同步代码块中使用,sleep 不需要\n\n4. wait 不需要捕获异常,sleep 需要\n\n### 死锁\n\n#### 产生条件\n\n- 互斥条件: 一个资源或者说一个锁只能被一个线程占用,当一个线程首先获取到这个锁之后,在该线程释放该锁之前,其他的线程都无法获取到这个锁\n\n- 占有且等待: 一个线程已经获取到一个锁,再获取另外一个锁时,即使获取不到也不会释放已经获得的锁\n\n- 不可剥夺条件: 任何一个线程都无法强制获得其他线程已经拥有的锁\n\n- 循环等待条件: 线程 A 拿着线程 B 想要获取的锁,线程 B 拿着线程 A 想要获取的锁\n\n#### 如何避免\n\n- 加锁顺序: 线程按照相同的顺序加锁\n\n- 限时加锁: 线程获取锁的过程中限定一些时间,如果给定的时间内无法获取锁就放弃,这里需要用到 Lock 的 api\n\n### wait 虚假唤醒\n\n### notify 底层\n\n#### 为何 wait 和 notify 要依赖 synchronized\n\nsynchronized 代码块通过 javap 生成的字节码中包含 monitorenter 和 monitorexit 指令,执行 monitorenter 可以获得对象的 monitor,而 wait 方法通过调用 native 方法 wait(0)实现,wait(0)方法要求线程必须拥有对象的 monitor\n\n#### notify 执行后唤醒的线程立马被 CPU 执行吗\n\nnotify/notifyAll 调用时并不会真正释放对象锁,只是把等待中的线程唤醒然后放入到对象的锁池中,但是锁池中的所有线程都不会马上运行,只有拥有锁的线程执行完代码块释放锁,别的线程拿到锁之后才能被执行\n","tags":["interview","thread"]},{"title":"jvm相关面试知识点(持续更新)","url":"/article/903a0625.html","content":"\n### 1.JVM 内存模型\n\n运行时数据区域\n\n#### 线程私有\n\n线程私有部分,生命周期和线程一致\n\n##### 虚拟机栈(Stack)\n\n每个线程在创建的时候都会创建一个虚拟机栈(Stack),其内部保存一个个的栈帧(Stack Frame),对应着一次次 Java 方法调用;\n\n每个栈帧中都拥有局部变量表/操作数栈/动态链接/方法出口信息等\n\n局部变量表主要存放了编译器可知的各种基本数据类型和对象引用(Reference 类型,它不同于对象本身,可能是一个指向对象起始地址的引用指针,也可能是指向一个代表对象的句柄或其他与此对象相关的位置)\n\n每个线程在栈中保存自己的数据,其他线程无法访问;\n\n每一个方法从被调用到执行完成的过程,都对应着一个栈帧从入栈到出栈的过程;\n\n在栈中我们可能遇到两种异常:StackOverFlowError 和 OutOfMemoryError\n\n- StackOverFlowError :若 Java 虚拟机栈的内存不允许动态拓展,那么当线程请求的栈深度超过当前 Java 虚拟机栈的最大允许深度,将抛出此异常\n\n- OutOfMemoryError :当 Java 虚拟机栈的内存允许动态拓展,那么当线程在拓展栈时无法申请到足够的内存,将抛出此异常\n\n##### 本地方法栈(Native Method Stack)\n\n本地方法栈和虚拟机栈类似,区别只在于本地方法栈为 Native 服务;\n\nNative 方法就是一个 Java 方法调用非 Java 方法的接口,比如 JNI;\n\n在 HotSpot 虚拟机中本地方法栈和 Java 虚拟机栈合二为一;\n\n##### 程序计数器(Program Counter Register)\n\nJava 代码最终都要编译成一条条字节码,然后由字节码解释器一行行的执行,而程序计数器可以看作是当前线程所执行的字节码的行号计数器;\n\n字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令,分支/循环/跳转/异常处理/线程恢复等功能都需要依赖这个计数器来完成;\n\n如果正在执行的是一个 Java 方法,那么这个计数器记录的是正在执行的字节码指令地址;如果正在执行的是 Native 方法,那么计数器的值为 undefined;\n\n每条线程都有一个独立的程序计数器,各线程的程序计数器互不影响;\n\n程序计数器是唯一一个不会 OOM 的内存区域\n\n#### 线程共享\n\n线程共享部分内容\n\n##### 堆(Heap)\n\nJava 内存中占用空间最大的一个区域\n\n堆唯一的作用就是存放对象,不过并非所有对象都在堆中\n\n堆如果空间不足,就会抛出 OOM\n\n堆是垃圾收集器管理的主要区域,因此也被称为 GC 堆(Garbage Collected Heap)\n\n###### 分代\n\n由于现在收集器基本上都采用分代垃圾收集算法,所以 Java 堆还可以细分为: 新生代和老年代;其中新生代又分为:Eden 空间,From Survivor 空间和 To Survivor 空间;\n\n进一步划分的目的是更好地回收内存,或者更快地分配内存\n\n\"分代回收\"是基于这样一个事实:对象的生命周期不同,所以针对不同生命周期的对象可以采用不同的回收方式,以便提高回收效率\n\n从内存分配的角度来看,线程共享的 Java 堆中可能会划分出多个线程私有的分配缓冲区(Thread Local Allocation Buffer)TLAB\n\n- 新生代(Young Generation):大多数对象在新生代中被创建,其中很多对象的生命周期很短,每次新生代的垃圾回收(Minor GC)后只有少量对象存活,所以选用复制算法,只需要少量的复制成本就可以完成回收\n\n新生代又分为三个区,一个 Eden 区,两个 Survivor 区(一般而言),大部分对象在 Eden 区中生成,当 Eden 区满时,还存活的对象将被复制到两个 Survivor 区中的一个,当这个 Survivor 区满时,此区的存活且不满足\"晋升\"条件的对象将被复制到另外一个 Survivor 区,对象每经历一次 Minor GC,年龄+1,达到\"晋升年龄阈值\"后,被放到老年代,这个过程也被称为\"晋升\";显然\"晋升年龄阈值\"的大小直接影响着对象在新生代中的停留时间,在 Serial 和 ParNew 两种回收器中,\"晋升年龄阈值\"通过参数 MaxTenuringThreshold 设定,默认值为 15\n\n- 老年代(Old Generation):在新生代中经历了 N 次垃圾回收后仍存活的对象,就会被放到老年代,该区域中对象存活率高;老年代的垃圾回收(Major GC),通常使用\"标记-清除\"或者\"标记-整理\"算法;\n\n- 整堆包括新生代和老年代的垃圾回收称为 Full GC(HotSpot 虚拟机中,除了 CMS 外,其他能收集老年代的垃圾回收器都会收集整个 GC 堆,包括新生代)\n\n- 永久代(Perm Generation): 主要存放元数据,例如 Class,Method 的元信息,与垃圾回收要回收的 Java 对象关系不大,相对于新生代和老年代来说,该区域的划分对垃圾回收影响较小;\n\n在 jdk1.8 中移除整个永久代,取而代之的是一个叫元空间(Metaspace)的区域(永久代使用的是 JVM 的堆内存空间,而元空间使用的是物理内存,直接受到本机的物理内存限制)\n\n##### 方法区(Method Area)\n\n用于存储已经被虚拟机加载的类信息,常量池,静态变量,JIT 编译后的代码等数据;\n\n虽然 java 虚拟机规范把方法区描述为堆的一个逻辑部分,但是它却有一个别名叫做非堆(Non-Heap),目的是与 Java 堆区分开\n\nHotSpot 虚拟机中方法区常被称为\"永久代\",本质上两者并不等价,仅仅是因为 HotSpot 虚拟机用永久代来实现方法区而已,这样 HotSpot 虚拟机的垃圾收集器就可以像管理 Java 堆一样管理这部分内存了,但是这并不是一个好主意,因为这样更容易遇到内存溢出问题;\n\n相对而言,垃圾收集行为在这个区域是比较少出现的,但并非数据进入方法后就\"永久存在\"了\n\n###### 运行时常量池(Runtime Constant Pool)\n\n运行时常量池是方法区的一部分,Class 文件中除了有类版本,字段,方法,接口等描述信息,还有常量池信息(用于存放编译期生成的各种字面量和符号引用),这部分内容将在类加载后进入方法区的运行时常量池中\n\n运行时常量池相对于 Class 文件常量池的另外一个重要特征就是具备动态性,Java 语言并不要求常量一定只有在编译期才能产生,也就是并非预置 Class 文件中的常量池内容才能进入运行时常量池,运行期间也可能将新的常量放入常量池中,这种特性被开发人员利用的比较多的便是 String 的 intern()方法\n\n既然运行时常量池是方法区的一部分,自然受到方法区的内存限制,当常量池无法再申请到内存时会抛出 OOM\n\nJDK1.7 及之后版本的 JVM 已经将字符串常量池从方法区移了出来,在 java 堆中开辟了一块区域存放字符串常量池\n\n###### 永久代\n\n作为和堆一样可以被线程共享的内存区域,堆之外的空间被成为非堆(Non-Heap).可以粗略的理解为非堆里面包含了永久代,而永久代里又包含了方法区\n\n我们常常把永久代和方法区等同起来,然而永久代其实是 HotSpot 虚拟机把分代 GC 的范围拓展到方法区的产物\n\n###### 元空间\n\n在 JDK8 中移除了永久代,引入了元空间(metaspace),原先的 class,field 等变量放入 metaspace;元空间并不在虚拟机中,而是使用本地内存;默认情况下元空间的大小仅受本地内存的限制,但是可以通过参数来进行指定\n\n#### 直接内存\n\n一般使用 Native 函数操作 C++代码来实现直接分配堆外内存,不是虚拟机运行时数据区的一部分,也不是虚拟机规范中定义的内存区域,但这部分内存也被频繁的使用.而且也可能导致 OOM\n\nJDK1.4 中新加入的 NIO(New Input/Output)中,引入了一种基于通道(Channel)与缓冲区(Buffer)的 I/O 方式,它可以直接使用 Native 函数库直接分配堆外内存,然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作;这样就能在一些场景中显著提高性能,因为避免了在 Java 堆和 Native 堆之间来回复制数据.可以有效提高读写效率,但是创建/销毁却比普通 buffer 慢\n\n本机直接内存的分配不会收到 java 堆的限制,但是既然是内存就会受到本机总内存大小以及处理器寻址空间的限制;\n\n### 2.对象创建过程\n\n#### 1.类加载检查\n\n虚拟机遇到一条 new 指令时,首先将去检查这个指令的参数能否在常量池中定位到一个类的符号引用,并检查这个符号引用代表的类是否已经被加载,解析和初始化过,如果没有,那么必须先执行相应的类加载过程\n\n#### 2.分配内存\n\n在类加载检查通过后,接下来虚拟机将会为新生的对象分配内存.对象所需的内存大小在类加载完成后便可完全确定,为对象分配空间等于把一块确定大小的内存从 java 堆中划分出来;\n\n分配方式有\"指针碰撞\"和\"空闲列表\"两种,选择哪种分配方式由 java 堆是否规整决定,而 java 堆是否规整又由所采用的垃圾回收器是否带有压缩整理功能决定\n\n- 指针碰撞: 假设 java 堆中内存是完整的,已分配的内存和空闲内存分别在不同的一侧,通过一个指针作为分界点,需要分配内存时,仅仅需要把指针往空闲的一端移动与对象大小相等的距离;使用的 GC 收集器:Serial, ParNew,适用内存规整(即没有内存碎片)的情况下\n\n- 空闲列表: 事实上,java 堆中的内存并不是完整的,已分配的内存和空闲内存相互交错,JVM 通过维护一个空闲列表,记录可用的内存块信息,当分配操作发生时,从列表中找到一个足够大的内存块分配给对象实例,并更新列表上的记录;适用的 GC 收集器:CMS,适用堆内存不规整的情况下\n\nJava 堆内存是否规整,取决于 GC 收集器的算法是\"标记-清除\"还是\"标记-整理\",值得注意的是,复制算法内存也是规整的;\n\n- 内存分配并发问题\n\n在创建对象的时候有一个很重要的问题,就是线程安全,因为在实际开发过程中,创建对象是很繁琐的事情,例如正在给 A 对象分配内存,但是指针还没有修改,这时候可能使用原来的指针给对象 B 分配内存的情况;作为虚拟机来说,必须要保证线程是安全的.通常来讲,虚拟机采用两种方式来保证线程安全\n\n1.CAS+失败重试:虚拟机采用 CAS 配合失败重试的方式保证更新操作的原子性\n2.TLAB:为每一个线程预先在 Eden 区分配一块内存.JVM 在给线程中的对象分配内存时,首先在各个线程的 TLAB 分配,当对象大于 TLAB 中的剩余内存或 TLAB 的内存已经用尽时,再采用上述的 CAS 进行内存分配,虚拟机是否启用 TLAB,可以通过-XX:+/-UseTLAB 参数来设定,可以通过 -XX:TLABWasteTargetPercent 设置 TLAB 空间所占用 Eden 空间的百分比大小\n\n#### 3.初始零值\n\n内存分配完成后,虚拟机需要将分配到的内存空间都初始化为零值(不包括对象头),这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就可以使用,程序能访问到这些字段的数据类型所对应的零值;如果使用 TLAB,这一分配过程也可以提前到 TLAB 分配时进行\n\n#### 4.设置对象头\n\n接下来,虚拟机要对对象进行必要的设置,比如这个对象是哪个类的实例,如何才能找到类的元数据信息,对象的 hashCode,对象的 GC 分代年龄等信息,这些信息存放在对象头中,根据虚拟机当前的运行状态不同,对象头会有不同的设置方式\n\n#### 5.执行 init 方法\n\n在上面的工作都完成后,从虚拟机的视角来看,一个新的对象已经产生了,但从 java 程序的视角来看,对象创建才刚开始,init 方法还没有执行,所有的字段还都为零;所以一般来说,执行 new 指令之后会接着执行 Init 方法,把对象按照程序员的意愿进行初始化,这样一个真正可用的对象才算完全生产出来\n\n### 3.降低 java 垃圾回收开销\n\n1.预测集合的容量\n\n2.直接处理数据流\n\n3.使用不可变的对象\n\n4.拼接字符串时不用'+'\n\n5.尽量少创建一次性对象\n\n6.建立对象池,对频繁使用,占用内存大的对象回收管理\n\n### 4.类加载过程\n\n类的生命周期,包括以下 7 个阶段\n\n- 加载(Loading):\n- 连接(验证,准备,解析)\n- 初始化(Intilization)\n- 使用(Using)\n- 卸载(Unloading)\n\n其中解析过程在某些情况下可以在初始化阶段之后再开始,这是为了支持 Java 的动态绑定\n\n#### 类加载的时机\n\n加载阶段,java 虚拟机规范中并没有进行约束,但初始化阶段,java 虚拟机严格规定了有且只有如下 5 种情况必须立即进行初始化(初始化前,必须经过加载,验证,准备阶段):\n\n1.使用 new 实例化对象时,读取和设置类的静态变量/静态非字面值变量(静态字面值变量除外)时,调用静态方法时\n\n2.对类进行反射时\n\n3.初始化一个类时,如果父类没有初始化,需要先初始化其父类\n\n4.启动程序所使用的 main 方法所在类\n\n5.使用动态语言支持时\n\n以上 5 种场景又被称为主动引用,除此之外的引用称为被动引用,被动引用有如下情况:\n\n1.通过子类引用父类的静态变量,只会触发父类的初始化,不会触发子类的初始化\n\n2.定义对象数组和集合,不会触发该类的初始化\n\n3.类 A 引用类 B 的 static final 常量不会导致类 B 的初始化(注意静态常量必须是字面值常量,否则还是会触发类 B 的初始化)\n\n4.通过类名获取 Class 对象,不会触发类的初始化,如 System.out.printlin(Person.class)\n\n5.通过 Class.forName 加载指定类时,如果指定参数 initialize 为 false 时,也不会触发类的初始化\n\n6.通过 ClassLoader 默认的 loadClass 方法,也不会触发初始化动作\n\n注意: 被动引用不会导致类的初始化,但不代表不会经历加载,验证,准备阶段\n\n#### 类加载的方式\n\n##### 隐式加载\n\n1.创建类对象\n\n2.使用类的静态域\n\n3.创建子类对象\n\n4.在 JVM 启动时,BootstrapClassLoader 会加载一些 JVM 自身运行所需的 class\n\n5.在 JVM 启动时,ExtClassLoader 会加载指定目录下的一些特殊的 class\n\n6.在 JVM 启动时,AppClassLoader 会加载 classpath 路径下的 class,以及 main 函数所在的类 class\n\n##### 显式加载\n\n1.ClassLoader.loadClass(className),只加载和连接,不会初始化\n\n2.Class.forName(String name,boolean initialize,ClassLoader classLoader),使用 classLoader 进行加载和连接,根据参数 initialize 决定是否要初始化\n\n#### 加载\n\n类加载指的是将 class 文件读入内存,并为之创建一个 java.lang.Class 对象,即程序中使用的任何类,系统都会为之创建一个 java.lang.Class 对象;系统中所有的类都是由这个对象实现的\n\n类的加载由类加载器完成,JVM 提供的类加载器叫系统类加载器(System ClassLoader),此外还可以通过继承 ClassLoader 基类来自定义类加载器\n\n在加载阶段,虚拟机需要完成以下 3 件事情:\n\n1.通过一个类的全限定名,来获取定义此类的二进制字节流\n\n2.将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构\n\n3.在内存种生成一个代表这个类的 java.lang.Class 对象,作为方法区这个类的各种数据的访问入口\n\n通常可以用下面几种方式加载类的二进制文件:\n\n- 从本地文件系统加载 class 文件\n\n- 从 jar 包中加载 class 文件,如 jar 包的数据库驱动类\n\n- 通过网络加载 class 文件\n\n- 从专有数据库中提取 class 文件\n\n- 把一个 Java 源文件动态编译并执行加载\n\n#### 连接\n\n连接阶段负责把类的二进制数据合并到 JRE 中,其又可以分为如下三个阶段\n\n##### 1.验证: 确保加载的类信息符合 JVM 规范,无安全问题\n\n- 1.文件格式的验证,文件中是否有不符合规范或者附加的其他信息,例如常量中是否有不被支持的长量\n\n- 2.元数据的验证,保证其描述的信息符合 Java 语言规范的要求,例如类是否有父类,是否继承了不被允许的 final 类等\n\n- 3.字节码的验证,保证程序语义的合理性,比如要保证类型转换的合理性\n\n- 4.符号引用的验证,比如校验符号引用中通过全限定名是否能够找到对应的类,校验符号引用中的访问性(public,private)是否可以被当前类访问等\n\n##### 2.准备: 为类变量分配内存,并设置初始值\n\n主要是为类变量(注意,不是实例变量)分配内存,并且赋予初值\n\n特别需要注意,初值,不是代码中具体写的初始化的值,而是 java 虚拟机根据不同的变量类型的默认初始值,如 int 类型的初值为 0,reference 为 null\n\n##### 3.解析: 将类的二进制数据中的符号引用替换为直接引用\n\n将常量池内的符号引用替换为直接引用的过程\n\n举个例子来说,现在调用方法 hello(),这个方法的地址是 123456,那么 hello()就是符号引用,123456 就是直接引用\n\n在解析阶段,虚拟机会把所有的类名,方法名,字段名这些符号引用替换为具体的内存地址或偏移量,也即是直接引用\n\n#### 初始化\n\n##### 该阶段主要是对类变量进行初始化,是执行类构造器的过程\n\n- 只对 static 修饰的变量或语句进行初始化\n\n- 如果初始化一个类的时候,其父类尚未初始化,则优先初始化其父类\n\n- 如果同时包含多个静态变量和静态代码块,则按照自上而下的顺序依次执行\n\n##### 类初始化时机\n\n- 创建类的实例时(new, 反射, 序列化)\n\n- 调用某个类的静态方法时\n\n- 使用某个类或接口的静态 Field 或对该 Field 赋值时\n\n- 使用反射来强制创建某个类或接口对应的 java.lang.Class 对象,如 Class.forName(\"Person\");\n\n- 初始化某个类的子类时,此时该子类的所有父类都会被初始化\n\n- 直接使用 java.exe 运行某个主类时\n\n### 5.类加载器\n\n对于任意一个类,都需要由他的类加载器和这个类本身一同确定其在 JVM 中的唯一性;也就是说,如果两个类的加载器不同,即使两个类来源于同一个字节码文件,那这两个类依旧不相等(两个类的 Class 对象不 equals)\n\nJava 类加载器可以分成三种:\n\n1.根(又叫启动,引导)类加载器(Bootstrap ClassLoader)\n\n它负责加载 Java 核心类(String,System 等).它比较特殊,因为它是由原生 C++实现的,并不是 java.lang.ClassLoader 的子类,所以 String.class.getClassLoader()为 null\n\n2.拓展类加载器(Extension ClassLoader)\n\n加载 jre/lib/ext 包下面的 jar 文件,我们可以通过把自己开发的类打包成 jar 文件放入拓展目录来为 java 拓展核心类以外的新功能\n\n3.应用(系统)类加载器(Application or System ClassLoader)\n\n根据程序的类路径来加载 java 类\n\n它负责在 JVM 启动时加载来自 Java 命令的 -classpath 选项,java.class.path 属性,或 CLASSPATH 环境变量所指定的 Jar 包和类路径;程序可以通过 ClassLoader 的静态方法 getSystemClassLoader 获取系统加载器\n\n每个 java 类都维护着一个指向定义它的类加载器的引用,通过类名.class.getClassLoader()可以获取到此引用;然后通过 loader.getParent()可以获取类加载器的上层加载器\n\n### 6.类加载机制\n\njava 类加载机制主要有以下三种:\n\n- 双亲委派模型: 如果一个类加载器收到了加载类的请求,它首先不会去加载,而是委托给自己的父类加载器去加载,父类又委托给父类,因此所有的类加载都会委托给顶层的父类,一直到最顶层的启动类加载器;只有在父类加载器无法完成类的加载工作时,当前类加载器才会自己去加载这个类;注意类加载器中的父子关系并不是类继承上的父子关系,而是类加载器实例之间的关系;使用双亲委派模型,Java 类随着它的加载器一起具备了一种带优先级的层次关系,通过这种层次模型,可以避免类的重复加载,也可以避免核心类被不同的类加载器加载到内存中造成冲突和混乱,从而保证了 java 的核心库的安全;\n\n- 全盘负责: 当一个类加载器加载某个 class 时,该 class 所依赖和引用的其他的 class 也将由该类加载器载入,除非显示的使用另外一个类加载器来载入\n\n- 缓存机制: 缓存机制保证所有加载过的 class 都会被缓存,当程序中需要使用某个类时,类加载器先从缓冲区搜索该类,若搜寻不到将读取该类的二进制数据并转换成 class 对象存入缓冲区中,这就是为什么修改了 class 后需重启 JVM 才能生效\n\n### JVM 的 Class 对象的存储位置和作用\n\n类型信息是一个 java 类的描述信息(class meta), classLoader 加载一个类时从 class 文件中提取出来并存储在方法区.它包含以下信息:\n\n1.类型的完整有效名,类的修饰符(public, abstract, final 的某个子集),类型直接接口的一个有序列表及继承的父类;\n\n类型名称在 java 类文件和 jvm 中都已以完整有效名出现;在 java 源代码中,完整的有效名由类所属的包名称加一个\".\",再加上类名组成;例如,类 Object 所属的包为 java.lang,它的完整名称为 java.lang.Object,但在类文件中,所有的\".\"都被斜杠\"/\"代替,就成为 java/lang/Object.完整的有效名在方法区中的表示根据不同的实现而不同\n\n2.类型的常量池(constant pool)\n\n3.域(Field)信息\n\n4.方法(Method)信息\n\n5.除了常量外的所有静态(static)变量\n\n6.classloader 的引用\n\nClassLoader 加载一个类并把类型信息保存到方法区后,会创建一个 Class 对象,存放在堆区,不是方法区,它为程序提供了访问类型信息的方法\n\n方法区:\n\n在一个 JVM 实例的内部,类型信息存储在一个称为方法区的内存逻辑区中.类型信息是由类加载器在类加载时从类文件中提取出来的.类(静态)变量也存储在方法区中\n\nJVM 实现的设计者决定了类型信息的内部表现形式,如,多字节变量在类文件是以大端模式(big-endian)存储的,但在加载到方法区后,其存放形式由 jvm 根据不同的平台来具体定义\n\nJVM 在运行应用时要大量使用存储在方法区的类型信息;在类型信息的表示上,设计者除了要尽可能提高应用的运行效率外,还要考虑空间问题;根据不同的需求,JVM 的实现者可以在时间和空间上追求一种平衡\n\n因为方法区是被所有线程共享的,所以必须考虑数据的线程安全;假如两个线程都在试图找 java 的类,在 java 类还没有被加载的情况下,只应该有一个线程去加载,而另外一个线程等待\n\n方法区的大小不必是固定的,jvm 可以根据应用的需要动态调整,同样方法区也不必是连续的,方法区可以在堆(甚至是虚拟机自己的堆)中分配;jvm 可以允许用户和程序指定方法区的初始大小,最小和最大容量;\n\n方法区同样存在垃圾收集,因为通过用户定义的类加载器可以动态拓展 java 程序,一些类也会成为垃圾;jvm 可以回收一个未被引用类所占的空间,以便使方法区的空间最小\n\n用于存储已被虚拟机加载的类型信息\\常量\\静态变量\\即时编译器编译后的代码缓存等\n\n常量池:\n\njvm 为每个已加载的类型都维护一个常量池,常量池就是这个类型用到的常量的一个有序集合,包括实际的常量(String,int 和浮点常量)和对类型/域和方法的符号引用.池中的数据项像数组项一样,是通过索引访问的\n\n因为常量池中存储了一个类型所使用到的所有类型/域和方法的符号引用,所以它在 java 程序中的动态连接起到了核心的作用\n\njvm 必须在方法区中保存类型的所有域相关的信息以及域的声明顺序:\n\n类型信息:\n\n对每个加载的类型(类 Class\\接口 interface\\枚举 enum\\注解 annotation),JVM 必须在方法区中存储以下类型信息:\n\n1.这个类型的完整有效名称(全名=包名.类名)\n\n2.这个类型直接父类的完整有效名(对于 interface 或者 java.lang.Object,都没有父类)\n\n3.这个类型的修饰符(public/abstract/final 的子集)\n\n4.这个类型直接接口的有序列表\n\n域的相关信息:\n\n1.域名称\n\n2.域类型\n\n3.域修饰符(public/private/protected/static/final/volatile/transient 的子集)\n\n方法信息:\n\njvm 必须保存所有方法的以下信息,同域信息一样包括声明顺序\n\n1.方法名\n\n2.方法的返回类型(或 void)\n\n3.方法参数的数量和类型(有序的)\n\n4.方法的修饰符(public/private/protected/static/final/synchronized/native/abstract 的子集)\n\n5.方法的字节码(bytecodes),操作数栈和方法栈帧的局部变量的大小(abstract 和 native 方法除外)\n\n6.异常表(abstract 和 native 方法除外)\n","tags":["interview","jvm"]},{"title":"mysql面试知识点(持续更新)","url":"/article/a748be8.html","content":"\n### mysql 客户端和服务端之间如何通信\n\n1.通信类型:长连接或短连接(mysql 都支持，一般为长连接，放在连接池中)\n\n查看连接:show full processlist;\n\n查看连接参数:show global status like 'Thread%'\n\n![mysql-interview-2021-03-26-13-30-5220210326133051](https://gitee.com/AtlsHY/picgo/raw/master/images/etapP2QIrOLhbcZ.png)\n\nThreadpool_idle_threads: 线程池中空闲的线程数量\n\nThreadpool_threads: 线程池中所有的线程数量\n\nThread_cached: The number of threads in the thread cache; 缓存中的线程数\n\nThread_connected: The number of currently open connetions; 处于连接状态中的线程数\n\nThread_created: The number of threads created to handle connections; 被创建的线程数\n\nThread_running: The number of threads that are not sleeping; 处于激活状态的线程数\n\n2.通信协议:socket(不是通信协议)和 TCP/IP 协议\n\nmysql 客户端和数据库实例不在同一台服务器上时，在连接时没有指定-h 参数，会使用 scoket 方式登录，需要用到服务器上的一个物理文件(/var/lib/mysql/mysql.sock);\n\n如果指定-h 参数，就会使用 TCP 协议\n\n3.通信方式:半双工\n\n### 1.mysql 如何配置主从同步\n\n1.修改主库的配置\n\n2.创建从服务器的用户和权限\n\n3.重启 master\n\n4.查看 master 状态\n\n5.修改从库配置\n\n6.重启 slave\n\n7.slave 连接 master\n\n8.启动 slave 同步\n\n### 2.获取 mysql 自增主键的方法\n\n1.mybatis:useGeneratedKeys\n\n2.jdbc:Statement.RETURN_GENERATED_KEYS\n\n### 3.sql 优化\n\n1.为表建立主键\n\n2.定义字段时选取合适的类别和长度\n\n3.不使用 select'\\*'，明确查询字段，返回无用的字段会降低查询效率\n\n4.单条 sql 不要 join 超过三张表，关联字段必须有索引且数据类型一致\n\n5.单条 sql 子查询不要超过两层\n\n6.sql 中不要进行计算或者嵌套判断\n\n7.where 子句，group by 中用到的字段增加索引\n\n8.where 子句中等号的左侧不能使用函数或者表达式，会导致数据库引擎放弃索引进行全表扫描\n\n9.不要使用 like '%name'，即左模糊\n\n10.不要使用负向查询条件(!=、<>、not)，会导致数据库引擎放弃索引，进行全表扫描\n\n11.不要使用 or，会导致数据库引擎放弃索引查询而进行全表扫描\n\n12.传入变量类型与查询条件中字段类型应该匹配，禁止隐式转换\n\n13.不要使用外键\\视图\\触发器\\存储过程等\n\n14.尽量避免进行 null 值的判断，会导致数据库引擎放弃索引而进行全表扫描\n\n### 4.主键索引和唯一索引的区别\n\n1.主键是一种约束，目的是对这个表的某一列进行限制，唯一索引是一种索引，是为了更快的查询\n\n2.主键不允许存在 null 值，唯一索引可以存在空值\n\n3.一个表最多只能有一个主键，但是可以包含多个唯一索引\n\n4.主键创建后一定包含一个唯一性索引，唯一索引并不一定都是主键\n\n5.主键可以被其他表引为外键\n\n6.主键数据必须唯一，索引数据可以不唯一\n\n### 5.多个单个索引和联合索引的区别\n\n1.多个单列索引在多条件查询时只会生效第一个索引\n\n2.联合索引最左前缀原则:当创建(a，b，c)联合索引时，相当于创建了(a)单列索引，(a，b)联合索引以及(a，b，c)联合索引\n\n3.联合索引比对每个列分别建索引更有优势，因为索引建立得越多就越占磁盘空间，在更新数据的时候速度会更慢.另外建立多列索引时，顺序也是需要注意的，应该将严格的索引放在前面，这样筛选的力度会更大，效率更高\n\n### 6.建立索引的原则\n\n1.选择唯一性索引\n\n2.为经常需要排序，分组或者联合操作的字段建立索引\n\n3.为经常用作查询条件的字段建立索引\n\n4.限制索引的数目，因为建索引有一定开销\n\n5.索引字段长度不能太长\n\n6.联合索引最左前缀顺序很重要\n\n7.尽量选择区分度高的列作为索引\n\n8.频繁进行数据操作的表，不要建立太多的索引\n\n9.删除无用的索引\n\n### 7.分库分表策略\n\n1.水平分库\n\n概念:以字段为依据，按照一定的策略(hash，range 等)，将一个库中的数据拆分到多个库\n\n结果:每个库的结构都是一样的，每个库的数据都不一样，没有交集，所有库的数据的并集是全量数据\n\n场景:系统绝对并发量上来了，分表难以解决问题，并且还没有明显的业务归属来垂直分库\n\n2.水平分表\n\n概念:以字段为依据，按照一定的策略(hash，range 等)，将一个表中的数据拆分到多个表\n\n结果:每个表的结构都是一样的，每个表的数据都不一样，没有交集，所有表的数据的并集是全量数据\n\n场景:单表数据量太大，影响 sql 效率，加重了 cpu 负载\n\n3.垂直分库\n\n概念:以表为依据，按照业务归属不同，将不同的表拆分到不同的库中\n\n结果:每个库的结构都不一样，每个库的数据也不一样，没有交集，所有库的并集是全量数据\n\n场景:绝对并发量上来了，并且可以抽象出单独的业务模块，模块化，一类业务模块一个库\n\n4.垂直分表\n\n概念:以字段为依据，按照字段的活跃性，将表中字段拆分到不同的表(主表和拓展表)中\n\n结果:每个表的结构不一样，每个表的数据也不一样，一般来说每个表的字段至少有一列交集，一般是主键，用于关联数据;所有表的并集是全量数据\n\n场景:表的字段很多，并且热点数据和非热点数据在一起，单行数据所需的存储空间大，以至于数据库缓存的数据行减少，查询时会去读取磁盘产生 IO\n\n### 8.mysql 两种常见引擎的对比\n\n1.Innodb:\n\n提供了对数据库 ACID 事务的支持\n\n并且实现了 SQL 标准的四种隔离级别\n\n提供了行级锁和外键约束\n\n没有保存表的行数\n\n锁的粒度更小，写操作不会锁定全表\n\n2.MyISAM:\n\n没有提供对数据库事务的支持\n\n不支持行级锁和外键，即表级锁\n\n存储了表的行数\n\n适合读操作远远多于写操作，且不需要操作数据库事务的场景\n\n区别:\n\n- MyISAM 是非事务安全的，InnoDB 是事务安全的\n\n- MyISAM 锁的力度是表级，InnoDB 是行级\n\n### Mysql InnoDB 引擎主键的数据结构\n\n### 为什么用自增列作为主键\n\n1.如果我们定义了主键（Primary Key），那么 InnoDB 会选择主键作为聚集索引，如果没有显式定义主键，则 InnoDB 会选择第一个不包含 NULL 的值的唯一索引作为主键索引，如果也没有这样的唯一索引，则 InnoDB 会选择内置 6 字节长的 RowID 作为隐含的聚集索引（RowID 随着行记录的写入而主键递增，这个 RowID 不像 Oracle 的 RowId 那样可引用，是隐含的）\n\n2.数据记录本身被存于主索引（一棵 B+树）的叶子节点上，这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，Mysql 会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB 默认为 15/16），则开辟一个新的页（节点）\n\n3.如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页\n\n4.如果使用非自增主键，由于每次插入主键的值近似于随机，因此每次新纪录都要被插入到现有索引页的中间某个位置，此时 Mysql 不得不为新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中已经被清掉，此时又要从磁盘上读回来，增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过 OPTIMIZE TABLE 来重建表并优化填充页面\n\n### 为什么使用数据索引能提高效率\n\n1.数据索引的存储是有序的\n\n2.在有序的情况下，通过索引查询一个数据是无需遍历索引记录的\n\n3.极端情况下，数据索引的查询效率为二分法查询效率，趋近于 O(log2N)\n\n### 索引是什么\n\n官方介绍索引是帮助 Mysql 高效获取数据的数据结构。更通俗的说，数据库索引好比是一本的目录，能加快数据库的查询速度\n\n一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往是存储在磁盘上的文件中的（可能存储在单独的索引文件中，也可能和数据一起存储在数据文件中）\n\n我们通常所说的索引，包括聚集索引、覆盖索引、组合索引、前缀索引、唯一索引等，没有特别说明，默认都是使用 B+树结构组织（多路搜索树，并不一定是二叉的）的索引\n\n### 索引的优势和劣势\n\n#### 优势\n\n- 可以提高数据检索的效率，降低数据库的 IO 成本\n\n- 通过索引对数据及逆行排序，降低数据排序的成本，降低了 CPU 消耗\n\n  - 被索引的列会自动进行排序，包括[单列索引]和[组合索引]，只是组合索引的排序要复杂一些\n\n  - 如果按照索引列的顺序及逆行排序，对应 order by 语句来说，效率就会提高很多\n\n#### 劣势\n\n- 索引会占据磁盘空间\n\n- 索引虽然会提高查询效率，但是会降低更新表的效率。比如每次对表进行增删改操作，mysql 不仅要保存数据，还要保存或更新对应的索引文件\n\n### 索引类型\n\n#### 主键索引\n\n索引列中的值必须是唯一的，不允许有空值\n\n#### 普通索引\n\nmysql 中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值\n\n#### 唯一索引\n\n索引列中的值必须是唯一的，但是允许为空值\n\n#### 全文索引\n\n只能在文本类型 CHAR、VARCHAR、TEXT 类型字段上创建全文索引。字段长度比较大时，如果创建普通索引，在进行 like 模糊查询时效率比较低，这时可以创建全文索引。MylSAM 和 InnoDB 都可以使用全文索引\n\n#### 空间索引\n\nMysql 在 5.7 之后的版本支持了空间索引，而且支持 OpenGIS 几何数据模型。Mysql 在空间索引这方面遵循 OpenGIS 集合数据模型规则\n\n#### 前缀索引\n\n在文本类型如 CHAR、VARCHAR、TEXT 类型上创建索引时，可以指定索引列的长度，但是数值类型不能指定\n\n#### 其他（按照索引列数量分类）\n\n1.单列索引\n\n2.组合索引\n\n组合索引的使用，需要遵循最左前缀匹配原则（最左匹配原则）。一般情况下在条件允许的情况下使用组合索引提代多个单列索引使用\n\n### 索引的数据结构\n\n#### Hash 表\n\nHash 表，在 Java 中的 HashMap、TreeMap 等就是 Hash 表结构，以键值对的方式存储数据。我们使用 Hash 表存储表数据 Key 可以存储索引列，Value 可以存储行记录或者行磁盘地址。Hash 表在等值查询时效率很高，时间复杂度为 O(1)，但是不支持范围快速查找，范围查找时还是只能通过全表扫描方式。\n\n显然这种并不适合作为经常需要查找和范围查找的数据库索引使用。\n\n#### 二叉查找树\n\n![2021-04-02-13-28-2020210402132819](https://i.loli.net/2021/04/02/4krG592BgMoFOHn.png)\n\n二叉树特点： 每个节点最多有 2 个分叉，左子树和右子树数据顺序左小右大\n\n这个特点就是为了保证每次查找都可以折半而减少 IO 次数，但是二叉树就很考验第一个根节点的取值，因为很容易在这个特点下出现我们并不想发生的情况“树不分叉了”\n\n![2021-04-02-13-47-0920210402134708](https://i.loli.net/2021/04/02/YvdUmQJky4rtTa6.png)\n\n显然我们在选择上应该避免这种不稳定的情况\n\n#### 平衡二叉树\n\n平衡二叉树是采用二分法思维，平衡二叉查找树除了具备二叉树的特点，最主要的特征是树的左右两个子树的层级最多相差 1。在插入删除数据时通过左旋/右旋操作保持二叉树的平衡，不会出现左子树很高、右子树很矮的情况\n\n使用平衡二叉查找树查询的性能接近于二分查找法，时间复杂度是 O(log2N)。查询 id = 6，只需要 2 次 IO\n\n![2021-04-02-13-52-3920210402135238](https://i.loli.net/2021/04/02/EX5VdyDsF7HlYSi.png)\n\n平衡二叉查找树依旧存在一些问题：\n\n1.时间复杂度和树高相关。树有多高就需要检索多少次，每个节点的读取都对应一次磁盘 IO 操作。树的高度就等于每次查询数据时磁盘 IO 操作的次数。在表数据量大时，查询性能就会很差。（假设磁盘每次寻道时间为 10ms，1 百万的数据量，log2N 约等于 20 次磁盘 IO，耗时 20\\*10=0.2s）\n\n2.平衡二叉树不支持范围查询快速查找，范围查询时需要从根节点多次遍历，查询效率不高\n\n#### B 树: 改造二叉树\n\nmysql 的数据是存储在磁盘文件中的，查询处理数据时，需要先把磁盘中的数据加载到内存中，磁盘 IO 操作非常耗时，所以我们优化的重点就是尽量减少磁盘 IO 操作。访问二叉树的每个节点就会发生一次 IO，如果想要减少磁盘 IO 操作，就需要尽量降低树的高度，那么如何降低树的高度呢？\n\n假如 Key 为 bigint = 8 字节，每个节点有 2 个指针，每个指针为 4 个字节，一个节点占用的空间为 16 个字节（8+4\\*2=16）\n\n因为在 mysql 的 InnoDB 要存储引擎一次 IO 会读取一页的（默认一页 16k）的数据量，而二叉树一次 IO 有效数据量只有 16 字节，空间利用率极低。为了最大化利用一次 IO 空间，一个简单的想法是在每个节点存储多个元素，在每个节点尽可能多的存储数据。每个节点可以存储 1000 个索引（16K/16=1000），这样就将二叉树改造成了多叉树，通过增加树的叉数，将树从高瘦变为矮胖。构建 1 百万条数据，树的高度只需要 2 层就可以（1000\\*1000=1 百万），也就是说只需要 2 次磁盘 IO 就可以查询到数据。磁盘 IO 次数变少了，查询数据的效率也就提高了。\n\n这种数据结构我们称为 B 树，B 树是一种多叉平衡查找树，如下图主要特点\n\n1.B 树的节点中存储着多个元素，每个内节点有多个分支\n\n2.节点中的元素包含键值和数据，节点中的键值从大到小排列。也就是说，在所有的节点都存储数据\n\n3.父节点当中的元素不会出现在子节点中\n\n4.所有的叶子节点都位于同一层，叶节点具有相同的深度，叶节点之间没有指针连接\n\n![2021-04-02-14-45-2720210402144526](https://i.loli.net/2021/04/02/iX5sI7aLy4HxhGR.png)\n\n举个例子，在 B 树中查询数据的情况：\n\n假如我们查询值等于 10 的数据，查询路径磁盘块 1->磁盘块 2->磁盘块 5\n\n第一次磁盘 IO：将磁盘块 1 加载到内存中，在内存中从头遍历比较，10<15，走指针 P1，到磁盘块 2\n\n第二次磁盘 IO：将磁盘块 2 加载到内存中，在内存中从头遍历比较，10>7,走指针 P2，到磁盘块 5\n\n第三次磁盘 IO：将磁盘块 5 加载到内存中，在内存中从头遍历比较，8<10，10=10，找到 10，取出 data，如果 data 存储的是行记录，取出 data，查询结束；如果存储的是磁盘地址，还需要根据磁盘地址到磁盘中取出数据，查询结束\n\n相比二叉平衡查找树，在整个查找过程中，虽然数据的比较次数没有明显的减少，但是磁盘 IO 次数会大大减少。同时，由于我们的比较是在内存中进行的，所以比较的耗时可以忽略。B 树的高度一般 2 至 3 层就能满足大部分的应用场景，所以使用 B 树构建索引可以很好的提升查询的效率。\n\nB 树依然存在可以优化的地方：\n\n1.B 树不支持范围查询的快速查找，假如我们要查找 10 和 35 之间的数据，查到 15 之后，需要回到根节点重新遍历查找，需要从根节点进行多次遍历，查询效率有待提高\n\n2.如果 data 存储的是行记录，行的大小随着列数增多，所占空间会变大。这是一个页中可存储的数据量就会变少，树相应就会变高，磁盘 IO 次数就会变大。\n\n#### B+树：改造 B 树\n\nB+树，作为 B 树的升级版，Mysql 在在 B 树基础上继续改造，使用 B+树构建索引。B+树和 B 树最主要的区别在于非叶子节点是否存储数据\n\n- B 树：非叶子节点和叶子节点都会存储数据\n\n- B+树：只有叶子节点才存储数据，非叶子节点只存储键值。叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表\n\n![2021-04-02-19-19-2820210402191928](https://i.loli.net/2021/04/02/xAJa6z7pycOdrHt.png)\n\nB+树的最底层叶子节点包含了所有的索引项。从图上可以看到，B+树在查找数据的时候，由于数据都存放在最底层的叶子节点上，所以每次查找都需要检索到叶子节点才能查询数据\n\n所以在需要查询数据的情况下每次的磁盘的 IO 和树高有直接的关系，但是从另一方面来说，由于数据都被放到了叶子节点，放索引的磁盘块存储的索引数量是会跟着增加的，相对于 B 树来说，B+树的树理论上是比 B 树要矮的\n\n也存在索引覆盖查询的情况，在索引中数据满足了当前查询语句所需要的全部数据，此时只需要找到索引即可立即返回，不需要检索到最底层的叶子节点\n\n##### 例如：等值查询\n\n假如我们查询值等于 9 的数据。查询路径磁盘块 1->磁盘块 2->磁盘块 6\n\n第一次磁盘 IO：将磁盘块 1 加载到内存中，在内存中从头遍历比较，9<15，走 P1 指针，到磁盘寻址磁盘块 2\n\n第二次磁盘 IO：将磁盘块 2 加载到内存中，在内存中从头遍历比较，7<9<12，走 P2 指针，到磁盘寻址磁盘块 6\n\n第三次磁盘 IO：将磁盘块 6 加载到内存中，在内存中从头遍历比较，在第 1 个索引中找到 9，取出 data，如果 data 存储的行记录，取出 data，查询结束。如果存储的是磁盘地址，还需要根据磁盘地址到磁盘中取出数据，查询结束。（这里要区分的是在 InnoDB 中 data 存储的是行数据，而 MyIsam 中存储的是磁盘地址）\n\n##### 范围查询\n\n假如我们想要查找 9 和 26 之间的数据，查找路径是磁盘块 1->磁盘块 2->磁盘块 6->磁盘块 7\n\n首先查找值等于 9 的数据，将值等于 9 的数据缓存到结果集。这一步和前面等值查询流程一致，发生了三次磁盘 IO\n\n查到 9 之后，底层的叶子节点是一个有序列表，我们从磁盘块 6、键值 9 开始向后遍历，筛选出所有符合条件的数据\n\n第四次磁盘 IO：根据磁盘 6 后继指针到磁盘中寻址定位到磁盘块 7，将磁盘块 7 加载到内存中，在内存中从头遍历比较，9<26<=26，将 data 缓存到结果集\n\n主键具备唯一性（后面不会有<=26 的数据），不需要再向后查找，查询结束。\n\n可以看到 B+树可以保证等值和范围查询的快速查找，mysql 的索引就采用了 B+树的数据结构\n\n### mysql 的索引实现\n\n#### MyIsam 索引\n\n以一个简单的 user 表为例。user 表存在两个索引，id 列为主键索引，age 为普通索引\n\n```sql\nCREATE TABLE `user`\n(\n  `id`       int(11) NOT NULL AUTO_INCREMENT,\n  `username` varchar(20) DEFAULT NULL,\n  `age`      int(11)     DEFAULT NULL,\n  PRIMARY KEY (`id`) USING BTREE,\n  KEY `idx_age` (`age`) USING BTREE\n) ENGINE = MyISAM\n  AUTO_INCREMENT = 1\n  DEFAULT CHARSET = utf8;\n```\n\n![2021-04-06-11-22-1720210406112217](https://i.loli.net/2021/04/06/dSJY7yenMvN54Ar.png)\n\nMyIsam 的数据文件和索引文件是分开存储的。MyIsam 使用 B+树构建索引树时，叶子节点中存储的键值为索引列的值，数据为索引所在行的磁盘地址\n\n##### MyIsam 主键索引\n\n![2021-04-06-11-22](https://i.loli.net/2021/04/06/W5NSqFPQle7UOZH.png)\n\n表 user 的索引存储在索引文件 user.MYI 中，数据存储在数据文件 user.MYD 中。\n\n简单分析下查询时的磁盘 IO 情况\n\n###### 根据主键等值查询\n\n```sql\nselect * from user where id = 28;\n```\n\n1.先在主键树中从根节点开始检索，将根节点加载到内存，比较 28<75，走 P1 指针（1 次磁盘 IO）\n\n2.将左子树节点加载到内存中，比较 16<28<47，走 P2 指针，向下检索（1 次磁盘 IO）\n\n3.检索到叶节点，将叶节点加载到内存中，比较 16<28，18<28，28=28。查找到值等于 28 的索引项（1 次磁盘 IO）\n\n4.从索引项中获取磁盘地址，然后到数据文件 user.MYD 中获取整行记录（1 次磁盘 IO）\n\n5.将获取到的数据返回给客户端\n\n磁盘 IO 次数：3 次索引检索+记录数据检索\n\n###### 根据主键范围查询数据\n\n```sql\nselect * from user where id between 28 and 47;\n```\n\n1.先在主键树中从根节点开始检索，将根节点加载到内存，比较 28<75，走 P1 指针（1 次磁盘 IO）\n\n2.将左子树节点加载到内存中，比较 16<28<47，走 P2 指针，向下检索（1 次磁盘 IO）\n\n3.检索到叶节点，将叶节点加载到内存中，比较 16<28，18<28，28=28。查找到值等于 28 的索引项（1 次磁盘 IO）\n\n4.根据磁盘地址从数据文件中获取行记录缓存到结果集中，我们的查询语句范围查找时，需要向后遍历底层叶子链表，直至到达最后一个不满足筛选条件\n\n5.向后遍历底层叶子链表，将下一个节点加载到内存中，遍历比较，28<47=47（1 次磁盘 IO）\n\n6.根据磁盘地址从数据文件中获取行记录缓存到结果集中\n\n7.最后将符合查询条件的结果集返回给客户端\n\n磁盘 IO 次数：4 次索引检索+记录数据检索\n\n###### 备注\n\n以上分析仅供参考，MyISAM 在查询时，会将索引节点缓存到 MySQL 缓存中，而数据缓存依赖于操作系统自身的缓存，所以并不是每次都走磁盘，这里只是为了分析索引的使用过程\n\n##### MyIsam 辅助索引\n\n在 MyISAM 中辅助索引和主键索引的结构是一样的，没有任何区别，叶子节点的数据存储的都是行记录的磁盘地址，只是主键索引的键值是唯一的，而辅助索引的键值可以重复\n\n查询数据时，由于辅助索引的键值不唯一，可能存在多个拥有相同的记录，所以即使是等值查询，也要按照范围查询的方式在辅助索引树中检索数据\n\n#### InnoDB 索引\n\n##### InnoDB 主键索引（聚簇索引）\n\n每个 InnoDB 表都有一个聚簇索引，聚簇索引使用 B+树构建，叶子节点存储的数据是整行记录。一般情况下，聚簇索引等同于主键索引，当一个表没有创建主键索引时，InnoDB 会自动创建一个 ROWID 字段来构建聚簇索引。InnoDB 创建索引的具体规则如下：\n\n1.在表上定义主键 Primary key，InnoDB 将主键索引用作聚簇索引\n\n2.如果表没有定义主键，InnoDB 会选择第一个不为 NULL 的唯一索引列作为聚簇索引\n\n3.如果以上两个都没有，InnoDB 会使用一个 6 字节长整型的隐式字段 ROWID 字段构建聚簇索引。该 ROWID 字段会在插入新行时自动递增\n\n除聚簇索引之外的所有索引都称为辅助索引。在 InnoDB 中，辅助索引中的叶子节点存储的数据是该行的主键值。在检索时，InnoDB 使用此主键值在聚簇索引中搜索记录\n\n这里以 user_innodb 为例，user_innodb 的 id 列为主键，age 为普通索引\n\n```sql\nCREATE TABLE `user_innodb` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `username` varchar(20) DEFAULT NULL,\n  `age` int(3) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `idx_age` (`age`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n```\n\n![2021-04-06-13-25-0320210406132502](https://i.loli.net/2021/04/06/P3gMFD4TnsI2kz8.png)\n\nInnoDB 的数据和索引存储在一个文件 user_innodb.ibd 中。InnoDB 的数据组织方式，是聚簇索引。\n\n主键索引的叶子节点会存储数据行，辅助索引只会存储主键值\n\n![2021-04-06-13-25-5120210406132550](https://i.loli.net/2021/04/06/EMR1euPpLgkVlY3.png)\n\n###### 等值查询数据\n\n```sql\nselect * from user_innodb where id = 28;\n```\n\n1.先在主键树中从根节点开始检索，将根节点加载到内存，比较 28<75，走 P1 指针（1 次磁盘 IO）\n\n2.将左子树加载到内存，比较 16<28<47，走 P2 指针（1 次磁盘 IO）\n\n3.检索到叶节点，将叶节点加载到内存，比较 16<28，18<28，28=28。查找到值等于 28 的索引项，直接可以获取整行数据，将记录返回给客户端（1 次磁盘 IO）\n\n磁盘 IO 次数：3 次\n\n##### InnoDB 辅助索引\n\n除聚簇索引之外的所有索引被称为辅助索引，InnoDB 的辅助索引只会存储主键值而非磁盘地址或整行数据\n\n以表 user_innodb 的 age 为例，age 索引的结构如下图：\n\n![2021-04-06-13-32-3920210406133239](https://i.loli.net/2021/04/06/ad3NRzP7fTplv9C.png)\n\n底层叶子节点按照（age，id）的顺序排序，先按照 age 从小到大排序，age 列相同时按照 id 从小到大排序\n\n使用辅助索引需要检索两次索引：首先检索辅助索引获得主键，然后使用主键到主键索引中检索获得记录\n\n###### 辅助索引等值查询数据\n\n```sql\nselect * from user_innodb where age = 19;\n```\n\n1.从辅助索引叶子节点获取到符合条件数据的主键\n\n2.从主键索引获取到对应主键的数据\n\n磁盘 IO 次数：辅助索引 3 次+主键索引 3 次（回表）\n\n根据在辅助索引中获取的主键 id，到主键索引树中检索数据的过程被称为回表查询\n\n##### InnoDB 组合索引\n\n创建一个表 abc_innodb，id 为主键索引，创建了一个联合索引 idx_abc(a,b,c)\n\n```sql\nCREATE TABLE `abc_innodb` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `a` int(11) DEFAULT NULL,\n  `b` int(11) DEFAULT NULL,\n  `c` varchar(10) DEFAULT NULL,\n  `d` varchar(10) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `idx_abc` (`a`,`b`,`c`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n```\n\n```sql\nselect * from abc_innodb order by a,b,c,id;\n```\n\n![2021-04-06-13-51-3520210406135134](https://i.loli.net/2021/04/06/PESqvdT3w4kBryh.png)\n\n组合索引的数据结构：\n\n![2021-04-06-14-03-0720210406140306](https://i.loli.net/2021/04/06/ZX5yToNqSxFD3dB.png)\n\n###### 组合索引的查询过程\n\n```sql\nselect * from abc_innodb where a=13 and b=16 and c=4;\n```\n\n1.加载根节点，与(13,14,3)比较。发现大于，走右路\n\n2.加载右子树，与(14,14,14)比较，发现小于，走左路\n\n3.加载左叶子节点，按顺序比较，找到对应的值\n\n4.将结果返回给客户端\n\n- 最左匹配原则\n\n最左前缀匹配原则和联合索引的索引存储结构和检索方式是有关系的\n\n在组合索引树中，最底层的叶子节点按照第一列 a 从左到右递增排序，但是 b 列和 c 列是无序的，b 列只有在 a 列值相等的情况下小范围内递增有序，而 c 列只能在 a、b 两列相等的情况下小范围内递增有序\n\n就像上面的查询，B+树会先比较 a 列来确定下一步应该搜索的方向，往左还是往右。如果 a 列相同再比较 b 列。但是如果查询条件没有 a 列，B+树就不知道第一步应该从哪个节点查起。\n\n可以说创建的 idx_abc(a,b,c)联合索引，相当于创建了(a)，(a,b)，(a,b,c)三个索引\n\n组合索引的最左前缀匹配原则：使用组合索引列查询时，mysql 会一直向右匹配直至遇到范围查询（>、<、between、like）就停止查询\n\n##### InnoDB 覆盖索引\n\n覆盖索引并不是索引的结构，覆盖索引是一种很常见的优化手段。因为在使用辅助索引的时候，我们只可以拿到主键值，相当于获取数据还需要再根据主键查询主键索引再获取到数据。但是如果我们要查询的字段均为索引列，就意味着我们只需要查询到辅助索引的叶子节点就可以返回了，不需要回表操作，这种情况就是索引覆盖。\n\n可以看一下执行计划：\n\n- 覆盖索引的情况\n\n![2021-04-06-14-20-2020210406142019](https://i.loli.net/2021/04/06/ap7oOxPKECJyvNU.png)\n\n- 未覆盖索引的情况\n\n![2021-04-06-14-20-5720210406142057](https://i.loli.net/2021/04/06/1JluIUSGkE2hOd9.png)\n\n### B+树索引和哈希索引的区别\n\nB+树是一个平衡多叉树，从根节点到每个叶子节点的高度差值不超过 1，而且同层级的节点间有指针相互链接，是有序的\n\n哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似 B+树那样从根节点到叶子节点逐级查找，只需要一次哈希算法即可，是无序的\n\n#### 哈希索引的优势\n\n等值查询：哈希索引具有绝对的优势（前提是：没有大量重复键值，如果大量重复键值时，哈希索引的效率会很低，因为存在哈希碰撞）\n\n#### 哈希索引不适用的情况\n\n1.不支持范围查询\n\n2.不支持索引完成排序\n\n3.不支持联合索引的最左前缀原则\n\n常用的 InnoDB 引擎中默认使用的是 B+树索引，它会实时监控表上索引的使用情况，如果认为建立哈希索引可以提高查询效率，则自动在内存中的“自适应哈希索引缓冲区”建立哈希索引（在 InnoDB 中默认开启自适应哈希索引），通过观察搜索模式，MySQL 会利用 index key 的前缀建立哈希索引，如果一个表几乎大部分在缓冲池中，那么建立一个哈希索引能够加快等值查询\n\n注意：在某些工作负载下，通过哈希索引查找带来的性能远大于额外的监控索引搜索情况和保持这个哈希表结构所带来的开销。但某些时候，在负载高的情况下，自适应哈希索引中添加的 read/write 锁也会带来竞争，比如高并发的 join 操作。like 操作和%的通配符也不适用于自适应哈希索引，可能要关闭自始应哈希索引。\n\n### 为什么说 B+树比 B 树更适合实际应用中操作系统的文件索引和数据库索引\n\n1.B+树的磁盘读写代价更低，B+的内部节点并没有指向关键字具体信息的指针。因此其内部相对于 B 树更小。如果把所有同一内部节点的关键字存放于同一盘块中，那么盘块所能容纳的关键字数量也就越多。一次性读入内存中的需要查找的关键字也就越多。相对来说 IO 读写次数也就降低了\n\n2.B+树的查询效率更稳定，由于非叶子节点不是指向最终文件内容的节点，而只是叶子节点中关键字的索引。所以任何关键字的查找都必须走一条从根节点到叶子节点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当\n\n### 为什么使用索引\n\n- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性\n- 可以大大加快数据的检索速度\n- 帮助服务器避免排序和临时表\n- 将随机 IO 变为顺序 IO\n- 可以加速表和表之间的连接\n\n### MyISAM 和 InnoDB 实现 B+树索引方式的区别是什么\n\n- MyISAM：B+ Tree 叶节点的 data 域存放的是数据记录的地址，在检索索引的时候，首先按照 B+ Tree 搜索算法搜索索引，如果指定的 key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据。这被称为\"非聚簇索引\"\n- InnoDB：其数据本身就是索引文件，其表数据文件本身就是按 B+ Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录，这个索引的 key 是数据表的主键，因此 InnoDB 表数据本身就是主索引，这被称为\"聚簇索引\"或者\"聚集索引\"。而其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址。\n\n在根据主索引搜索时，直接找到 Key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。因此，在设计表的时候，不建议用过长的字段为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。\n\n### MySQL 是如何执行一条 SQL 语句的\n\n![一个mysql请求的处理流程图](https://i.loli.net/2021/04/21/Edo3zeSs1ijxRTB.png)\n\n- 连接器：管理连接，权限验证\n- 查询缓存：命中缓存则直接返回结果\n- 分析器：对 sql 进行词法分析、语法分析（查询判断的 sql 字段是否存在也是在这步）\n- 优化器：执行计划生成、选择索引\n- 执行器：操作引擎，返回结果\n- 存储引擎：存储数据、提供读写接口\n\nserver 层按顺序执行 sql 的步骤为：\n\n- 客户端请求\n- 连接器（验证用户身份，给予权限）\n- 查询缓存（存在缓存则直接返回，不存在则继续后续操作）\n- 分析器（对 sql 进行词法分析和语法分析）\n- 优化器（对执行的 sql 优化，选择最优的执行方案）\n- 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）\n- 去引擎层获取数据返回（如果开启查询缓存则会尝试缓存查询结果）\n\n从上图可以看出，mysql 的处理流程主要分为 4 个步骤：\n\n- 客户端与服务端通信\n- 查询优化处理过程\n- 查询执行引擎\n- 返回结果给客户端\n\n#### 客户端与服务端通信\n\n一般通信方式有 3 种：单工，半双工，全双工。单工就是只能单向传输，要么 A 端传给 B 端，要么 B 端传给 A 端；半双工是可以双向传输的，但是同一时间只能是一个方向传输，也就是 A 端传给 B 端的时候，B 端只能等待，反过来也是一样；全双工是双向随便传输\n\nmysql 客户端与服务端的通信方式是半双工的，也就是说，我们的一个数据库连接在向数据库发送数据的时候，此时这个数据库连接是不能给客户端返回数据的，一定是数据返回完毕以后，客户端才能再次发起查询操作。这也就是我们在做数据查询的时候用 where 条件和 limit 限制结果行数的原因，否则客户端连接需要等到数据库把所有的查询结果返回后，才能进行下一个操作。\n\n从上面的分析可以看出，MySQL 数据库半双工通信的一个重要特点是：客户端一旦开始发送指令，服务端需要接收完毕才能响应，客户端只有在完全接收到服务端响应的数据后，才能再次发送指令。我们在程序开发中，一般用多个连接进行数据交互，通过数据库连接池来进行管理。\n\n其实 mysql 的每一个连接都有其对应的状态来标识它目前所处的阶段，和线程类似，我们可以通过下面的命令查看数据库连接的状态：\n\n```sql\nshow [full] processlist;\n```\n\n常用的几个状态描述：\n\n|     | 状态值                  | 状态描述                                             |\n| --- | ----------------------- | ---------------------------------------------------- |\n| 1   | login                   | 连接线程的初始状态，直到客户端已经成功通过身份验证   |\n| 2   | executing               | 该线程已开始执行一条语句                             |\n| 3   | optimizing              | 服务器正在对查询执行初始优化                         |\n| 4   | updating                | 线程正在搜搜或者更新要更新的行                       |\n| 5   | sending data            | 正在将数据发送到客户端，一般会执行大量的磁盘访问操作 |\n| 6   | sorting result          | 正在对结果排序                                       |\n| 7   | waiting for commit lock | 正在等待提交锁                                       |\n\n当发现数据连接长时间占用的时候，可以用 kill 命令杀死线程：\n\n```sql\nkill processlist_id;\n```\n\n#### 查询优化处理过程\n\n解析器解析 sql 语句：通过 lex 此法分析器（就是把一个完整的 sql 语句分析成独立的单词）、yacc 语法分析器（就是分析是否符合语法规则，比如单引号是否闭合等）进行分析，将 sql 语句按 sql 标准解析成解析树（select_lex）对象，主要功能是把 sql 语句的字符串解析成数据库服务器可以处理的解析对象，便于后续进行预处理和生成执行计划\n\n预处理：预处理会根据 mysql 的语法规则对解析树对象进行合法性检查，比如检查表名列名是否存在、检查名字和别名保证没有歧义。预处理之后得到一个新的解析树\n\n优化器生成执行计划：优化器的主要作用是找到这个 sql 语句最优的执行计划，mysql 的查询优化器和 oracle 的类似，都是基于成本的计算，优化器会尝试使用不同的执行计划，以便于找到一个最优的执行计划（一般随机读取 4K 的数据库进行分析）\n\n可以使用以下命令查看查询的成本：\n\n```sql\nshow status like 'Last_query_cost';\n```\n\n优化器最终会把解析树变成一个查询执行计划。mysql 提供了一个执行计划的工具，我们在 sql 语句前面加上 explain，就可以看到执行计划的信息\n\n#### 查询执行引擎\n\n查询执行模块，也就是查询执行引擎，根据优化器生成的最优执行计划调用对应存储引擎的 API 进行执行计划的执行，并获取查询应该返回的结果集\n\n#### 返回结果给客户端\n\n如果没有开启缓存，把查询到的结果集返回到客户端；如果开启了缓存，执行缓存操作，把结果集存入缓存，然后把结果返回给客户端，即使结果集是空的，也要返回。\n\n### mysql 的缓存介绍\n\n一般情况下，我们不会用到数据库自带的缓存，所以 mysql 默认是不开启缓存的，只有以读为主的业务，数据不变化的情况下，可以开启数据库的缓存\n\n查看缓存是否开启：\n\n```sql\nshow variables like 'query_cache%';\n```\n\n![2021-04-22-09-54-45querycache](https://i.loli.net/2021/04/22/7ZCJhj6oGITn9D1.png)\n\nquery_cache_type：OFF，表示缓存关闭，默认是关闭的，可以通过修改 MySQL 配置文件 my.cnf 进行调整，重启服务后生效\n\nquery_cache_limit：1048576，表示单次查询缓存的结果集大小 1M，超过 1M 则不会缓存\n\nquery_cache_size：1048576，表示缓存开辟的空间大小\n\n查看缓存操作情况：\n\n```sql\nshow status like 'Qcache%';\n```\n\nQcache_hits：表示缓存命中次数\n\nQcache_inserts：表示缓存插入次数\n\n缓存生效的条件是在缓存开启的情况下，执行的 sql 语句字符串一模一样的时候，可以从缓存直接读取数据，但是当缓存数据相关的表存在数据变化的时候，原有的缓存就会失效\n\nmysql 的缓存开启后，当 sql 查询语句带有 sqlnocache 关键字或者带有函数操作或者单次查询结果集超过 query_cache_limit 设置的值或者查询系统表时，不会用到缓存\n\n### drop、delete 于 truncate 的共同点和区别\n\n#### 第一种回答\n\ndrop、delete、truncate 都表示删除，但是三者有一些区别\n\ndelete 用来删除表的一部分数据，执行 delete 之后，用户需要提交（commit）或者回滚（rollback）来执行删除或者撤销删除，会触发这个表上所有的 delete 触发器\n\ntruncate 删除表中所有的数据，这个操作不能回滚，也不会触发表上的触发器，truncate 比 delete 更快，占用的空间更小\n\ndrop 命令从数据库中删除表，所有的数据行、索引和权限也会被删除，所有的 DML 触发器也不会被触发，这个命令也不会回滚\n\n因此，在不需要一张表的时候，用 drop；在想删除部分数据行的时候，用 delete；在保留表而删除所有数据的时候用 truncate\n\n#### 第二种回答\n\n- drop 直接删除表\n- truncate 删除表中数据，再插入时自增 id 又从 1 开始\n- delete 删除表中数据，可以加 where 子句\n\n#### 具体解析\n\n- delete 语句执行删除的过程是每次从表中删除一条数据，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。truncate 则一次性的从表中删除所有的数据，并不把单独的删除操作记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器，执行速度快\n- 表和索引所占空间。当表被 truncate 后，这个表和索引所占的空间会恢复到初始大小，而 delete 操作不会减少表或索引所占用的空间，drop 语句将表所占用的空间全部释放掉\n- 一般而言，drop>truncate>delete\n- 应用范围：truncate 只能对 table，delete 可以是 table 和 view\n- truncate 和 delete 只删除数据；而 drop 则删除整个表（结构和数据）\n- truncate 与不带 where 的 delete 只删除数据，而不删除表的结构（定义）。drop 语句将删除表的结构、被依赖的约束（constrain）、触发器（trigger）、索引（index）；依赖于该表的存储过程、函数将被保留，但其状态会变为：invalid\n- delete 语句为 DML（Data Manipulation Language），这个操作会被放到 rollback segment 中，事务提交后才生效。如果有相应的 trigger，执行的时候将被触发\n- truncate、drop 是 DDL（Data Define Language），操作立即生效，原数据不放到 rollback segment 中，不能回滚\n- 在没有备份的情况下，谨慎使用 drop 与 truncate。要删除部分数据行采用 delete 且注意结和 where 来约束影响范围。回滚段要足够大。要删除表用 drop；若想保留表而将表中数据删除，如果与事务无关，用 truncate 即可实现。如果和事务有关，或者是想触发 trigger，还是用 delete\n- truncate table 表名速度快而且效率高。因为 truncate 在功能上与不带 where 子句的 delete 语句相同：二者均删除表中的全部行。但 truncate 比 delete 速度快，且使用的系统和事务日志资源少。delete 语句每次删除一行并在事务日志中为所删除的每行记录一项。truncate 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。\n- truncate 删除表中的所有行，但表结构及其列、约束、索引等保持不变。新行标识所用的计数值重置。如果想保留标识计数值，请用 delete。如果要删除表定义及其数据，请用 drop\n- 对于有外键约束引用的表，不能使用 truncate，而应使用不带 where 子句的 delete。由于 truncate 不记录在日志中，所以它不能激活触发器\n\n### 文件索引和数据库索引为什么使用 B+ Tree\n\n主要原因：B+树只要遍历叶子节点就可以实现整棵树的遍历，而且在数据库中基于范围查询时非常频繁的，而 B 树种只能中序遍历所有节点，效率太低\n\n文件与数据库都是需要较大的存储，也就是说，他们都不可能全部存储在内存中，故需要存储到磁盘上。而所谓索引，则为了数据的快读定位与查找，那么索引的结构组织要尽量减少查找过程中磁盘 I/O 的存取次数，因此 B+树相比于 B 树更加合适。数据库系统巧妙利用了局部性原理与磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次 I/O 就可以完全读入，而红黑树这种结构，高度明显要深得多，并且由于逻辑上很近的节点（父子节点）物理上可能很远，无法利用局部性\n\n更重要的是，B+树还有一个更重要的好处：方便扫库\n\nB 树必须用中序排序的方式按序扫库，而 B+树直接从叶子节点挨个遍历就好。B+树支持 range-query 非常方便，而 B 树不支持，这是数据库选用 B+树的主要原因。\n\nB+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部结构相对于 B 树更小。如果把所有同一内部节点的关键字存放在同一块盘中，那么盘块所能容纳的关键字数量也就越多。一次性读入内存中的需要查找的关键字也就越多，相对来说 I/O 次数也就降低了；\n\nB+树的查询效率更加稳定：由于内部节点并不是最终指向文件内容的节点，而只是叶子节点中关键字的索引，所以，任何关键字的查找必须走一条从根节点到叶子节点的路，所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。\n\n### 联合索引在索引树中的结构\n","tags":["interview","mysql"]},{"title":"代理模式面试知识点(持续更新)","url":"/article/f72b9de4.html","content":"\n### 1.代理模式概念\n\n为某个对象提供一个代理,以控制这个对象的访问;代理类负责为委托类预处理消息,过滤消息并转发消息,以及进行消息被委托类执行后的后续处理\n\n通过代理类,能有效控制对委托类对象的直接访问,也可以很好的隐藏和保护委托类对象,同时也为实施不同控制策略预留了空间,从而在设计上获得了更大的灵活性\n\n### 2.静态代理和动态代理的区别\n\n- 静态代理要求委托类和代理类都实现同一个接口,代理对象的一个接口只服务于一种类型的对象\n\n- 静态代理中代理类在编译期就已经确定,而动态代理则是运行期间动态生成\n\n- 静态代理的效率相对来说更高一些,但是代码冗余大,一旦需要修改接口,代理类和委托类都需要修改\n\n- 动态代理依靠反射来生成代理类\n\n### 3.jdk 动态代理实现步骤\n\n1.jdk 动态代理只能用于代理接口,因此需要先创建一个接口以及其实现类\n\n2.创建代理类,实现 invocationHandler 接口\n\n3.引入 Object 类作为目标对象,重写有参构造器,重写 invoke 方法,加入代理方法,并调用 Object 类的方法\n\n4.利用 Proxy.newInstance()生成代理对象,并调用目标方法\n\n### 4.cglib 动态代理实现步骤\n\nCGLIB（Code Generation Library）是一个高性能开源的代码生成包,采用非常底层的字节码技术,对指定的目标类生成一个子类,并对子类进行增强\n\n1.创建被代理类\n\n2.创建代理类,实现 MethodInterceptor 接口,实现 intercept 方法\n\n3.利用 Enhancer 绑定被代理对象和代理类,\n\n4.利用 Enhancer.create()方法创建代理对象,调用代理对象方法\n\n### 5.反射应用场景\n\n- 逆向代码\n\n- 注解\n\n- 动态生成类\n\n- 生成动态代理\n","tags":["interview","proxy"]},{"title":"事务相关面试知识点(持续更新)","url":"/article/4004f64d.html","content":"\n### 1.什么是事务\n\n事务是访问数据库的一个操作序列，数据库应用系统通过事务来完成对数据库的存取。事务的正确执行使得数据库从一个状态转换为另一个状态\n\n事务有 ACID 的原则：\n\n- 原子性(atomicity):即不可分割,事务要么全部被执行,要么全部不被执行,如果事务中所有的子事务全部提交成功,则所有的数据库操作都被提交,数据库状态会发生变化;如果有子事务失败,则其他子事务的数据库操作全部被回滚,数据库回到执行事务之前的状态,不回发生状态变化\n\n- 一致性(consistency):事务的执行使数据库从一种正确状态转换为另一种正确状态\n\n- 隔离性(isolation):在事务正常提交之前,不允许把该事务对数据库数据的任何改变提供给其他事务,即在事务正确提交之前,它可能的结果对其他事务不可见\n\n- 持久性(durability):事务正确提交之后,其结果将永远保存在数据库中,即使在事务提交之后有了其他故障,事务的处理结果也会得到保存\n\n### 2.并发下事务会产生的问题\n\n- 脏读:事务 A 读到了事务 B 还没有提交的数据\n\n- 幻读:一个事务在前后两次查询同一范围的时候,后一次查询看到了前一次查询没有看到的行\n\n- 不可重复读:事务 A 首先读取了一条数据,执行逻辑的时候,事务 B 将这条数据改变了,然后事务 A 再次读取的时候,发现数据不匹配了\n\n### 3.Spring 事务的隔离级别\n\n- default:默认隔离级别,Spring 将使用数据库默认的隔离级别\n\n- read_uncommitted:读未提交,能够读取到没有被提交的数据,导致脏读,幻读,不可重复读\n\n- read_committed:读已提交,能够读取到已经被提交的数据,能解决脏读,导致幻读和不可重复读\n\n- repeatable_read:重复读取,即在数据读出来之后加锁,解决了脏读,不可重复读,无法解决幻读\n\n- serializable:串行化,最高的事务隔离级别,解决了以上所有问题,性能差，行级锁\n\nmysql 默认的事务隔离级别是 repeatable_read\n\n### 4.Spring 事务传播机制\n\n- REQUIRED:支持当前事务,如果没有事务会创建一个新的事务\n\n- REQUIRED_NEW:挂起当前事务,创建一个新的事务\n\n- MANDATORY:支持当前事务,如果当前不存在事务则抛出异常\n\n- SUPPORTS:支持当前事务,如果当前没有事务会以非事务方式执行\n\n- NOT_SUPPORTED:以非事务方式执行,如果当前存在事务则将当前事务挂起\n\n- NESTED:如果当前存在事务,则在嵌套事务内执行,如果当前不存在事务,则会创建一个新的事务\n\n- NEVER:以非事务方式执行,如果当前存在事务抛出异常\n\n### Spring @Transactionl 注解什么时候失效\n\n在 spring aop 代理下，只有目标方法被外部调用，目标方法才由 spring 生成的代理对象来管理，这会造成自调用问题\n\n若同一类中的其他方法没有@Transactionl 注解的方法内部调用有@Transactionl 注解的方法，有@Transactionl 注解的方法的事务会被忽略，不会发生回滚\n\n@Transactional 只能被应用到 public 方法上\n","tags":["interview","transaction"]},{"title":"java集合面试知识点(持续更新)","url":"/article/4ca75bdb.html","content":"\n### 1.数组和集合的区别\n\n- 数组能存放基础数据类型和对象,而集合存放的都是对象,集合无法存放基础数据类型.数组和集合存放的都是对象的引用地址\n- 数组容量固定无法动态改变,集合容量可以动态改变\n- 数组无法判断其中实际存放多少元素,length 只告诉了数组的容量,而集合的 size()可以确切知道元素的个数\n- 集合有多种实现方式和不同适用场景,不像数组仅采用顺序表方式\n- 集合以类的形式存在,具有继承,封装,多态等面向对象特性,通过简单的方法和属性即可以实现各种复杂操作,大大提高了软件开发的效率\n\n### 2.java 集合分类\n\nCollection 和 Map,是集合框架的接口\n\n#### Collection 的子接口\n\n- Set:接口,实现类:HashSet,LinkedHashSet 等\n\n- Set 的子接口:SortedSet 接口,实现类:TreeSet\n\n- List:接口,实现类:ArrayList,LinkedList,Vector 等\n\n#### List 集合\n\n有序列表,允许存放重复的元素\n\n实现类:\n\n##### ArrayList\n\n数组实现,查询快,增删慢,轻量级,线程不安全,底层是 Object 数组,所以 ArrayList 具有数组的查询速度快以及增删速度慢的特点\n\n##### LinkedList\n\n双向链表实现,增删快,查询慢,线程不安全,底层是双向循环链表,在此链表上每一个数据节点都由三部分组成: 前指针(指向前面的节点),数据,后指针(指向后面的节点).最后一个节点的后指针指向第一个节点的前指针,形成一个循环链表.双向循环链表的查询效率低但是增删效率高\n\n##### Vector\n\n数组实现,重量级,线程安全\n\n##### CopyOnWriteArrayList\n\n支持高效率并发且是线程安全的,读操作无锁的 ArrayList.所有可变操作都是通过对底层数组进行一次新的复制来实现\n\n适合使用在读操作远远大于写操作的场景里,比如缓存,它不存在扩容的概念,每次写操作都要复制一个副本,在副本的基础上修改之后改变 Array 引用,因为写操作要大面积复制数组,所以性能很差\n\n由于写操作的时候,需要拷贝数组,会消耗内存,如果原数组的内容比较多的情况下,可能导致 young gc 或者 full gc\n\n不能用于实时读的场景,像拷贝数组,新增元素都需要时间,所以调用一个 set 操作后,读取到的数据可能还是旧的,只能做到最终一致性\n\n### ArrayList 和 LinkedList 的区别\n\n- ArrayList 底层是基于动态数组的数据结构,LinkedList 底层是基于双向链表的数据结构\n\n- 对于 ArrayList 和 LinkedList 而言,在列表末尾增加一个元素所花的开销都是固定的,对于 ArrayList 而言,主要是在内部数组中增加一项,指向所添加的元素,偶尔可能会导致对数组重新进行分配,而对 LinkedList 而言,这个开销是统一的,分配一个内部 Entry 对象\n\n- 在 ArrayList 中间插入或者删除一个元素意味着这个列表中剩余的元素都会被移动,而在 LinkedList 中间插入或删除一个元素的开销是固定的\n\n- 对于随机访问 get 和 set,ArrayList 性能由于 linkedList,时间复杂度 O(1),因为 LinkedList 要移动指针 ,时间复杂度 O(n)\n\n- 对于新增和删除操作 add 和 remove,LinkedList 比较占优,因为 ArrayList 要移动数据\n\n- LinkedList 不支持高效率的随机元素访问\n\n- ArrayList 的空间浪费主要体现在 list 列表的结尾预留一定的容量空间,而 linkedList 的空间花费则体现在它的每个元素都要消耗相当的空间\n\n### LinkedList 特性\n\nLinkedList 是采用双向循环链表实现的\n\n利用 LinkedList 实现栈(Stack),队列(queue),双向队列(double-ended queue).它具有 addFirst(),addLast(),getFirst(),getLast(),removeFirst(),removeLast()等方法\n\n经常用来增删操作较多而查询操作较少的情况下:\n\n队列和堆栈\n\n队列:先进先出的数据结构\n\n栈:后进先出的数据结构\n\n注意:使用栈的时候一定不能提供方法让不是最后一个元素的元素获得出栈的机会\n\n用 LinkedList 实现队列:\n\n队列(queue)是限定所有的插入只能在表的一端进行,而所有的删除都在表的另一端进行的线性表\n\n表中允许插入的一端成为队尾(Rear),允许删除的一端称为对头(Front)\n\n队列的操作是先进先出的原则进行的\n\n队列的物理存储可以用顺序存储结构,也可以用链式存储结构\n\n用 LinkedList 实现栈:\n\n栈(Stack)也是一种特殊的线性表,是一种后进先出的结构\n\n栈是限定仅在表尾进行插入和删除运算的线性表,表尾称为栈顶(Top),表头称为栈底(Bottom)\n\n栈的物理存储结构可以用顺序表存储结构,也可以用链式存储结构\n\n### 3.Set 集合\n\n拓展 Collection 接口\n\n无序集合,不允许存放重复的元素,允许使用 Null 元素\n\n对 add(),equals()和 hashCode()方法添加了限制\n\nHashSet 和 TreeSet 是 Set 的实现\n\nSet->HashSet->LinkedHashSet\n\nSet->SortedSet->TreeSet\n\nHashSet 由 HashMap 实现,value 都是 new Object();\n\n实现类:\n\n- HashSet:equals 返回 true, hashCode 返回相同的整数;哈希表;存储的数据是无序的\n\n- LinkedHashSet: LinkedHashMap;存储的数据是有序的\n\n#### HashSet\n\nHashSet 直接实现了 Set 接口,其底层其实是包装了一个 HashMap 去实现的,HashSet 采用 HashCode 算法来存取集合中的元素,因此具有比较好的读取和查找性能\n\n特征:\n\n不仅不能保证元素插入的顺序,而且元素在以后的顺序中也可能变化(这是由于 HashSet 按 HashCode 存储元素决定的,对象变化则可能导致 HashCode 变化)\n\nHashSet 是非线程安全的\n\nHashSet 元素值可以为 Null\n\n如何能达到不存在重复元素的目的?\n\n\"键\"就是我们要存储的元素,而\"值\"是一个常量,而\"键\"在 Map 中是不能重复的,这就保证了我们存入 Set 中的所有元素都不重复\n\n#### LinekdHashSet\n\nLinkedHashSet 底层由 LinkedHashMap 实现\n\n#### TreeSet\n\nTreeSet 实现了 SortedSet 接口,这是以中排序的 Set 集合,底层是由 TreeMap 实现的,本质上是一个红黑树,相对于 HashSet,TreeSet 额外提供了一些按排序位置访问元素的方法,比如 first(),last(),higher(),lower(),subSet(),headSet(),tailSet()等\n\nTreeSet 的排序分两种类型,一种是自然排序,另一种是定制排序\n\n- 自然排序: 调用 compareTo 方法比较元素大小,然后按照升序排序,所以自然排序中的元素,都比需实现了 Comparable 接口,否则会抛出异常.判读元素是否重复也是调用元素的 compareTo 方法,如果返回 0 则是重复元素,\n\n- 定制排序: 在集合中写排序规则,需要关联一个 Comparator 对象,由 Comparator 提供排序逻辑\n\n#### EnumSet\n\nEnumSet 是专门为枚举类型设计的集合,因此集合元素必须是枚举类型,否则会抛出异常,EnumSet 也是有序的,其顺序就是 Enum 类内元素定义的顺序,EnumSet 的存取速度非常快,批量操作的速度也很快,\n\nEnumSet 主要提供的方法有 allOf(),complementOf(),copyOf(),noneOf(),of(),range 等,EnumSet 并没有提供任何构造函数,要创建一个 EnumSet 集合对象,只需要调用 allOf 等方法\n\n#### CopyOnWriteArraySet\n\n基于 CopyOnWriteArrayList 实现,线程安全\n\n### 4.Map\n\n集合框架的第二类接口树\n\n提供了一组键值对的映射,其中存储的每个对象都有一个响应的关键字(key),关键字决定了对象在 Map 中的存储位置\n\n关键字应该是唯一的,每个 key 只能映射一个 value\n\n#### 实现类\n\n##### HashMap\n\n键值对,key 不能重复,但是 value 可以重复,允许 null 的 key 或者 value\n\n最常用的 Map,根据 key 的 hashCode 存储数据,具有很快的访问速度\n\n最多只允许一条记录的 key 是 null,value 不限\n\n不支持线程同步,多线程并发变更 HashMap 结构会导致数据不同步或者抛出异常\n\n可以用 Collection.synchronizedMap(HashMap)方法使 HashMap 具有同步能力\n\n###### 底层数据实现\n\njdk1.8: 数组+单向链表+红黑树,链表插入数据时采用尾插法,链表长度大于 8 且数组长度大于等于 64 时转为红黑树,数据量小于 6 时转回链表\n\n当链表长度为 6 时,查询的平均长度为 n/2=3,红黑树 log(6)=2.6;为 8 时,链表 8/2=4,红黑树 log(8)=3\n\n链表转换成树之前,还会判断数组长度是否大于 64,这是为了避免在哈希表建立初期,多个键值对恰好被放入了同一链表中而导致不必要的变化\n\n如果链表长度大于 8 但是数据元素个数小于 64,只会触发扩容\n\n###### HashMap 初始化\n\n默认大小是 16,负载因子是 0.75,如果传入初始大小 k,初始化大小为离 k 最近的大于 k 的 2 的整数次幂,如果传入 10,初始大小为 16\n\n###### HashMap 插入流程\n\n1.判断数组是否为空,为空则进行初始化\n\n2.计算 key 的 hash=((null == key) ? 0 : key.hashCode() ^ k.hashCode >>> 16),通过(n-1)&hash 计算当前应存放在数组中的下标 index\n\n3.查看 table[index]是否存在数据,没有数据就构造一个 Node 节点存放在 table[index]中\n\n4.存在数据说明发生了 hash 冲突,继续判断 key 是否相等,相等就用新的 value 替换原数据\n\n5.如果 key 不相等,判断当前节点类型是否为树形节点,如果是树形节点,构造一个树形节点插入红黑树中\n\n6.如果不是树形节点,继续遍历链表判断 Node 后面的节点是否为空,不为空判断 key 是否相等,如果相等则结束遍历,替换旧值\n\n7.如果遍历到链表尾部,构造 Node 节点加入链表中,判断链表长度是否大于 8,大于 8 的话将链表转换为红黑树\n\n8.插入完成之后判断当前节点数是否大于阈值(即数组长度\\*负载因子),如果大于阈值,开始将数组扩容为原数组的二倍\n\n###### HashMap 删除流程\n\n##### TreeMap\n\n对 key 排好序的 Map,key 要实现 Comparable 接口或者传入 Comparator\n\n##### LinkedHashMap\n\n维护着一个运行于所有条目的双向链表,存储的数据是有序的,记录数据存入的顺序\n\n##### HashTable\n\n线程安全的,不允许 Null 的 key 或 value\n\n##### Properties\n\nkey 和 value 都是 String 类型,用来读取配置文件\n\n### HashMap 和 HashTable 区别\n\n都实现了 Map 接口\n\nHashMap 没有考虑同步,线程不安全,HashTable 使用了 synchronized 关键字,线程安全\n\nHashMap 允许 一个 key 和多个 value 都为 null,后者都不允许为 null\n\nHashMap 的迭代器是 fail-fast,而 HashTable 的迭代器不是 fail-fast,所有当多线程修改 HashMap 结构,会抛出 ConcurrentModificationException,但迭代器本身的 remove()方法移除元素则不会抛出\n\n单线程下 HashTable 比 HashMap 要慢\n\nHashMap 不能保证随着时间推移 Map 中的元素次序是不变的\n\n### ConcurrerntHashMap 和 HashTable 区别\n\nConcurrentHashMap 结合了 HashMap 和 HashTable 二者的优势,HashTable 每次同步执行都要锁住整个结构,ConcurrentHashMap 锁的方式是细粒度的\n\n### ConcurrentHashMap 实现原理\n\n#### jdk1.7：数组(Segment)+数组(HashEntry)+链表(HashEntry 节点)\n\n- ConcurrentHashMap 分段锁对整个桶数组进行了分割分段(Segment),每一把锁只锁容器其中一部分数据,多线程访问容器里不同数据段的数据,就不会存在锁竞争,提高并发访问率\n\n- Segment 是一种可重入锁(ReentrantLock),在 ConcurrentHashMap 中扮演锁的角色,HashEntry 则用于存储键值对数据.\n\n- 一个 ConcurrentHashMap 里包含一个 HashEntry 数组,每个 HashEntry 是一个链表结构的元素,每个 Segment 守护着一个 HashEntry 数组里的元素,当对 HashEntry 数组的数据进行修改时,必须先获得与它对应的 Segment 锁\n\n##### 实现原理\n\nConcurrentHashMap 初始化时,计算出 Segment 数组的大小 ssize 和每个 Segment 中的 HashEntry 数组的大小 cap,并初始化 Segment 数组的第一个元素;其中 ssize 的大小为 2 的幂次方,默认为 16,cap 大小也是 2 的幂次方,最小值为 2,最终结果根据初始化容量 initialCapacity 进行计算,其中 Segment 在实现上继承了 ReentrantLock,这样就自带了锁的功能\n\n当执行 put 方法插入数据时,根据 key 的 hash 值,在 Segment 数组中找到相应的位置,如果相应位置的 Segment 还未初始化,则通过 CAS 进行赋值,接着执行 Segment 对象的 put 方法通过加锁机制插入数据\n\n1.线程 A 执行 tryLock()方法成功获取锁,则把 HashEntry 对象插入到相应的位置\n\n2.线程 B 获取锁失败,则执行 scanAndLockForPut()方法,在 scanAndLockForPut()方法中,会通过重复执行 tryLock()方法尝试获取锁,在多处理器环境下,重复次数为 64,单处理器重复次数为 1,当执行 tryLock()方法的次数超过上限时,则执行 lock()方法挂起线程 B\n\n3.当线程 A 执行完插入操作时,会通过 unlock()方法释放锁,接着唤醒线程 B 继续执行\n\n##### size 实现\n\n因为 ConcurrentHashMap 时可以并发插入数据的,所以在准确计算元素时存在一定的难度,一版的思路时统计每个 Segement 对象中的元素的个数,然后进行累加,但是这种方式计算出来的结果并不一定是准确的,因为在计算后面几个 Segment 的元素个数时,已经计算过的 Segment 同时可能有数据的插入或者删除,在 1.7 的实现中采用了如下方式:\n\n先采用不加锁的方式,连续计算元素的个数,最多计算 3 次\n\n- 1.如果前后两次计算结果相同,则说明计算出来的元素个数是准确的;\n\n- 2.如果前后两次计算结果都不同,则给每个 Segment 加锁,再计算一次元素的个数\n\n#### jdk1.8：Node 数组+链表/红黑树\n\n- 底层依然采用数组+链表+红黑树的存储结构\n\n- 对每个数组元素加锁(Node),\n\n- 采用 Node+CAS+Synchronized 来保证并发安全进行\n\n##### HashMap 实现原理\n\n只有执行第一次 put 方法时,才会调用 initTable()初始化 Node 数组\n\n当执行 put 方法插入数据时\n\n1.根据 Key 的 hashcode 值,计算 hash=(k.hashcode ^ (k.hashcode >>> 16)) & 0x7fffffff,在 Node 数组中找到相应的下标 index = (n-1)&hash\n\n2.如果相应位置的 Node 还未初始化,则构造一个 Node,通过 CAS 插入相应的数据,结束循环\n\n3.如果对应位置 Node 不为空,且对应 Node 的 hash 值为 MOVED(-1),说明 table 正在扩容,当前线程会帮助扩容,然后获取扩容之后的 table 重新开始循环\n\n4.如果相应位置的 Node 不为空,并且 Node 不处于移动状态,则对该节点加 synchronized 锁,防止并发出现的问题\n\n5.如果目标位置上的元素依旧为之前获取到的节点,如果目标节点的 hash 值大于等于 0,则是链式结构\n\n6.将 binCount 置为 1,然后循环链表,每遇到一个元素,binCount 增加 1,如果目标节点 key 的 hash 与要存入的 hash 相等并且键值相等,替换旧值,结束循环;否则循环到链表尾部,构造新的 Node 节点插入链表尾部\n\n7.如果该节点是 TreeBin 类型的节点,说明是红黑树结构,将 binCount 置为 2,通过 putTreeVal 方法往红黑树中插入节点\n\n8.如果 binCount 不为 0,说明 put 操作对数据产生了影响,如果 binCount>= 8 ,则通过 treeifyBin 方法转化为红黑树,如果 oldVal 不为空,说明是一次更新操作,没有对元素个数产生影响,则直接返回旧值,结束循环\n\n9.如果插入的是一个新的节点,则执行 addCount()方法尝试更新元素个数 baseCount,判断是否需要对 table 进行扩容\n\n##### HashMap size 实现\n\n1.8 中使用一个 volatile 类型的变量 baseCount 记录元素的个数,当插入新数据或删除数据时,会通过 addCount()方法更新 baseCount\n\n1.初始化时 counterCells 为空,在并发量很高时,如果存在两个线程同时执行 CAS 修改 baseCount 值,则失败的线程会继续执行方法体中的逻辑,使用 counterCell 记录元素个数的变化\n\n2.如果 counterCell 数组 counterCells 为空,调用 fullAddCount()方法进行初始化,并插入对应的记录数,通过 CAS 设置 cellsBusy 字段,只有设置成功的线程才能初始化 counterCell 数组\n\n3.如果通过 CAS 设置 cellsBusy 字段失败的化,则继续尝试通过 CAS 修改 baseCount 字段,如果修改 baseCount 字段成功的话,就退出循环,否则继续循环插入 CounterCell 对象\n\n所以在 1.8 中的 size 实现比 1.7 简单的多,因为元素个数保存在 baseCount 中,部分元素的变化个数保存在 counterCell 数组中,通过累加 baseCount 和 CounterCell 数组中的数量,即可得到元素的总个数\n\n### 为什么 HashMap 引入红黑树而不是其他树\n\n#### 1.为什么不用二叉排序树\n\n二叉排序树在添加元素的时候极端情况下会出现线性结构\n\n由于二叉树左子树所有节点的值均小于根节点的值这一特点，如果我们添加的元素都比根节点小，会导致左子树线性增长，这样就失去了用树型结构替换链表的初衷，导致查询时间增长\n\n#### 2.为什么不用平衡二叉树\n\n1.红黑树不追求“完全平衡”，即不像 AVL 那样要求节点的|balFact|<= 1，它只要求部分达到平衡，但是提出了为节点增加颜色，红黑是用非严格的平衡来换取增删节点的时候旋转次数的降低，任何不平衡都会在 3 次之内解决，而 AVL 是严格平衡树，因此在增加和删除节点的时候，根据不同情况，旋转的次数比红黑树要多\n\n2.AVL 更平衡，结构上更加直观，时间效能针对读取而言更高；维护稍慢，空间开销较大\n\n3.红黑树，读取略逊于 AVL，维护强于 AVL，空间开销与 AVL 类似，内容多时略优于 AVL，维护优于 AVL\n\n就插入节点导致树失衡的情况，AVL 和 RBT 都是最多两次树旋转来实现复衡 rebalance，旋转的量级是 O(1)，删除节点导致失衡，AVL 需要维护从被删除节点到根节点 root 这条路径上所有节点的平衡，旋转的量级为 O(logN)，而 RBT 最多只需要旋转 3 次实现复衡，只需 O(1)，所以说 RBT 删除节点的 rebalance 效率更高，开销更小\n\nAVL 树的结构相对于 RBT 更为平衡，插入和删除引起失衡，RBT 效率更高；当然由于 AVL 高度平衡，因此 AVL 搜索的效率更高\n\n针对插入和删除节点导致失衡后的 rebalance 操作，红黑树能够提供一个比较“便宜”的解决方案，降低开销，是对 search、insert 以及 delete 效率的折衷，总体来说，RBT 的统计性能高于 AVL\n\n故引入 RBT 是功能、性能、空间开销的折衷结构\n\n基本上主要的几种平衡树看来，红黑树有着良好的稳定性和完整的功能，性能表现也不错，综合实力强；\n","tags":["interview","collection","list","set","map"]},{"title":"锁面试知识点(持续更新)","url":"/article/ce3641e9.html","content":"\n### synchronized 和 ReentrantLock 区别\n\n- 都是可重入锁\n\n- synchronized 是 JVM 层面的锁，是 java 关键字，Reentrantlock 是 lock 接口的实现，是 API 层面的锁\n\n- Reentrantlock 显式获得锁，释放锁，synchronized 隐式获取锁，释放锁\n\n- ReentrantLock 可响应中断，synchronized 是不可以响应中断的，阻塞的线程会一直阻塞\n\n- synchronized 的实现涉及到锁的升级，是同步阻塞，ReentrantLock 通过利用 CAS 自旋机制保证线程操作的原子性和 volatile 保证数据可见性，非同步阻塞，采用的是乐观并发策略\n\n- ReentrantLock 可以实现公平锁\n\n- ReentrantLock 可以通过 Condition 绑定多个条件\n\n- synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象，而 ReentrantLock 需要主动释放锁才能避免死锁\n\n- ReentrantLock 可以知道有没有成功获取锁，synchronized 不能\n\n- synchronized 锁的是对象，锁是保存到对象头里面的，根据对象头数据来标识是否有线程获得锁/争抢锁，ReentrantLock 锁的是线程，根据进入的线程和 int 类型的 state 标识锁的获得/争抢\n\n### synchronized 保证了那些特性\n\n- 原子性: 确保线程互斥地访问同步代码\n\n- 可见性: 保证共享变量的修改对其他线程可见。线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中获取最新的值。线程解锁前，必须把共享变量中的值刷新到主内存中。\n\n- 有序性: 对一个监视器锁的释放操作先行发生于后面对该监视器锁的获取操作(happens-before)\n\n### java 对象布局\n\n一个对象包括对象头，实例数据和对齐填充。\n\n#### 对象头\n\n![对象头布局](https://i.loli.net/2021/04/12/JorHIv395VpRdqB.png)\n\n##### Mark Word\n\n用于存储对象自身的运行数据，如 hashCode、GC 分代年龄、垃圾回收标志、锁状态标志、线程持的有锁、偏向线程 id、偏向时间戳等。这些信息都是与对象自身定义无关的数据，所以 Mark Word 被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说在运行期间 Mark Word 里存储的数据会随着锁标志位的变化而变化。这部分数据的长度在 32 位和 64 位(未开启指针压缩)中分别为 32 位和 64 位\n\n![Mark Word](https://i.loli.net/2021/04/12/YSjCKdcPNAmnvUu.png)\n\n##### klass 指针\n\n对象指针，对象指向它的类的元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说查找对象的元数据信息并不一定要经过对象本身\n\n##### 数组长度\n\n如果对象是一个数组，那在对象头中还必须有一块区域用于记录数组长度。\n\n#### 实例数据\n\n- 是对象真正存储的有效信息，也就是程序代码中定义的各种类型的字段内容\n\n- 无论是从父类继承的还是子类定义的都要记录起来\n\n- 这部分的存储顺序会受到虚拟机分配策略参数和字段在 Java 源码中定义顺序的影响\n\n#### 对齐填充\n\n- 对齐填充不是必然存在的，仅仅起着占位符的作用\n- 由于 HotSpot VM 的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，也就是对象的大小必须是 8 字节的整数倍\n\n### synchronized 原理\n\n#### 1.synchronized 修饰代码块\n\nsynchronized 代码块是由 monitorenter 和 monitorexit 指令实现的，monitor 对象是同步的基本实现单元。\n\n#### 2.synchronized 修饰方法\n\n方法的同步并没有通过指令 monitorenter 和 monitorexit 来完成，不过相对于普通方法，其常量池中多了 ACC_SYNCHRONIZED 标识符，JVM 就是通过该标识符来实现方法的同步的：当方法调用时，调用指令检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取 monitor，获取成功之后才能执行方法体，方法执行完成之后再释放 monitor。在方法执行期间，任何其他线程都无法再获取同一个 monitor 对象\n\n##### monitor\n\nMonitor 可以理解为一个同步工具或者一种同步机制，通常被描述为一个对象。每一个 Java 对象就有一把看不见的锁，称为内部锁或者 Monitor 锁\n\nMonitor 是线程私有的数据结构，每一个线程都有一个可用 monitor record 列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个 monitor 关联，同时 monitor 中有一个 Owner 字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用\n\n##### monitorenter\n\n每个对象有一个监视器锁(monitor)，当 monitor 处于占用时就会处于锁定状态，线程执行 monitorenter 指令尝试获取 monitor 对象的所有权，过程如下\n\n- 1.如果 monitor 的进入数为 0，则该线程占有 monitor，然后将进入数置 1，该线程即为 monitor 的所有者\n\n- 2.如果线程已经占有该 monitor，重复进入，则将 monitor 的进入数+1\n\n- 3.如果其他线程已经占有了 monitor，则该线程进入阻塞状态，直到 monitor 的进入数为 0，再重新尝试获取 monitor 的所有权\n\n##### monitorexit\n\n执行 monitorexit 的线程必须是 monitor 的所有者\n\n- 1.指令执行时，monitor 的进入数-1\n\n- 2.如果减 1 后进入数为 0，则线程释放 monitor 的所有权\n\n- 3.其他被这个 monitor 阻塞的线程可以尝试去获取这个 monitor 的所有权\n\n### synchronized 锁升级及撤销\n\n#### 1.无锁\n\n无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功\n\n无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。CAS 的原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的\n\n#### 2.偏向锁\n\n##### 偏向锁概念\n\n偏向锁会偏向于第一个获得它的线程，会在对象头和栈帧中的锁记录里存储锁偏向的 ThreadId，以后该线程进入和退出同步块不需要进行 CAS 操作进行加锁和解锁，只需要简单地测试以下对象头的 Mark Word 里是否存储着指向当前线程的偏向锁。\n\n不过一旦出现多个线程竞争时必须撤销偏向锁，所以撤销偏向锁性能的消耗必须小于之前节省下来的 CAS 原子操作的性能消耗，不然就得不偿失了\n\n##### 原理\n\n- 虚拟机会把对象头的偏向锁标志设为 01，即偏向模式\n\n- 同时使用 CAS 操作把获取到这个锁的线程 id 记录在对象的 MarkWord 中，如果 CAS 操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作\n\n- 它同样是个带有效益权衡性质的优化，也就是说它并不一定总是对程序运行有利，如果程序中大多数的锁总是被多个不同的线程访问比如线程池，那偏向模式就是多余的\n\n- 在 JDK5 中偏向锁默认是关闭的，而到了 JDK6 中偏向锁已经默认开启。但在应用程序启动几秒钟之后才激活，可以通过调整设置关闭延迟，如果确定应用程序中所有锁通常情况下处于竞争状态，也可以关闭偏向锁\n\n![偏向锁](https://i.loli.net/2021/04/11/8e7YIhLRcMbBtAj.png)\n\n##### 偏向锁有三种状态\n\n- 匿名偏向: 这是允许偏向锁的初始状态，MarkWord 中的 ThreadId 为 0，第一个试图获取该对象锁的线程会遇到这种状态，可以通过 CAS 操作修改 ThreadId 来获取这个对象的锁\n\n- 可重偏向: 这个状态下 Epoch(偏向时间戳)是无效的，下一个线程会遇到这种情况，在批量重偏向操作中，所有未被线程持有的对象都会被设置成这个状态，然后在下个线程获取的时候能够重偏向\n\n- 已偏向: 这个状态最简单，就是被线程持有着，此时 ThreadId 为其偏向的线程\n\n##### 批量重偏向和批量撤销\n\n- 批量重偏向: 当一个线程创建了大量对象(同一个 class 的)并执行了初始的同步操作，后来另一个线程也来将这些对象作为锁对象进行操作，会导致偏向锁重偏向操作。Hotspot 默认是 20 个，可以调整。重偏向只能触发一次\n\n- 批量撤销: 批量撤销就是如果线程 B 在达到批量重偏向之后继续获取对象锁，这个数量达到了批量撤销阈值(40 个)，那么 JVM 就认为当前场景存在多线程竞争，会标记该 class 不可偏向，之后再对于该 class 对象的锁直接走轻量级锁流程。触发批量撤销的线程仍然能够使用偏向锁，是从下一个线程开始变成轻量级锁\n\n##### 偏向锁加锁及升级逻辑\n\n1.线程 A 第一次访问同步块时，先检测对象头 Mark Word 中的标志位是否为 01，依此判断此时对象锁是否处于无锁状态或者偏向锁状态\n\n2.然后判断偏向锁标志位是否为 1，如果不是，则进入轻量级锁逻辑，如果是，则进入下一步流程\n\n3.判断是偏向锁时，检查对象头 Mark Word 中记录的 ThreadId 是否是当前线程的 id，如果是，表明当前线程已经获得对象锁，以后该线程进入同步块时，不需要 CAS 进行加锁\n\n4.如果对象头 Mark Word 中的 ThreadId 不是当前线程的 id，则进行 CAS 操作，尝试将当 MarkWord 中的 ThreadId 替换为当前线程 id。如果当前对象锁状态处于匿名偏向锁状态(可偏向未锁定)，则会替换成功(将 MarkWord 中的 ThreadId 由匿名 0 改为当前线程 id)，获取到锁，执行同步代码块\n\n5.如果对象锁已经被其他线程占用，则会替换失败，开始进行偏向锁撤销，这也是偏向锁的特点，一旦出现线程竞争，就会撤销偏向锁\n\n偏向锁的撤销是指在获取偏向锁的过程中因不满足条件导致要将锁对象改为非偏向状态，而偏向锁释放是指退出同步块时的过程\n\n6.偏向锁的撤销需要等待全局安全点(safe point，代表了一个状态，在该状态下所有线程都是暂停的)，暂停持有偏向锁的线程，检查持有偏向锁的线程状态(遍历当前 JVM 所有线程，如果能找到，说明偏向线程还存活)，如果线程还存活则检查线程是否在执行同步代码块中的代码，如果是则升级为轻量级锁，进行 CAS 竞争。\n\n每次进入同步块(即执行 monitorenter)的时候都会以从高往低的顺序在栈中找到第一个可用的 Lock Record，并设置偏向线程 ID。每次解锁(monitorexit)的时候都会从最低的一个 Lock Record 移除。所以如果能够找到对应的 LockRecord 说明偏向的线程还在执行同步代码块\n\n7.如果持有偏向锁的线程未存活，或者持有偏向锁的线程未在执行同步代码块，则进行校验是否允许重偏向，如果不允许重偏向则撤销偏向锁，将 MarkWord 设置为无锁状态(未锁定不可偏向状态)，然后升级为轻量级锁，进行 CAS 竞争锁。\n\n8.如果允许重偏向，设置为匿名偏向锁状态，CAS 将偏向锁重新指向当前线程\n\n9.唤醒暂停的线程，从安全点继续执行代码\n\n##### 偏向锁释放逻辑\n\n偏向锁的释放并不是主动的，而是被动的，持有偏向锁的线程执行完同步代码后不会主动释放锁，而是等待其他线程来竞争才会释放锁，也就是 ThreadId 不会改变，退出同步块释放偏向锁时，则依次删除对应的 Lock Record，但是不会修改对象头中的 ThreadId\n\n##### 偏向锁关闭\n\n偏向锁在 Java6 和 Java7 中是默认启用的，但是它在应用程序启动几秒之后才激活，如果有必要可以使用 JVM 参数来关闭延迟：-XX:BaisedLockingStartupDelay=0。如果确定应用程序中所有的锁通常情况下处于竞争状态，可以通过 JVM 参数关闭偏向锁：-XX:-UseBaisedLocking=false，那么程序默认会进入轻量级锁状态\n\n##### 好处\n\n偏向锁是在只有一个线程执行同步块时进一步提高性能，适用于一个线程反复获取同一个锁的情况.偏向锁可以提高带有同步但无竞争的程序性能\n\n#### 3.轻量级锁\n\n##### 轻量级锁概念\n\n轻量级锁是 JDK6 引进的，它的轻量是相较于通过系统互斥量实现的传统锁，轻量锁并不是为了取代重量级锁，而是在没有大量线程竞争的情况下，减少系统互斥量的使用，降低性能的损耗。\n\n轻量级锁能够提升程序性能的依据是\"对绝大部分的锁，在整个同步周期内都不会存在竞争\"。\n\n轻量级锁适用的场景是线程交替执行同步块的场景，如果存在同一时间访问同一锁的场景，就会导致轻量级锁膨胀为重量级锁\n\n##### 轻量级锁加锁流程\n\n轻量级锁加锁的前提是锁对象不能带有偏向特征。加锁的过程可分为两种情况来讨论:一种是无锁状态(锁标志位为 01，偏向标志位为 00)，可直接尝试加锁。另一种是有锁状态，需要检查是否为当前线程持有的锁。\n\n无锁状态下可以直接加锁，流程:\n\n- 1.线程在自己当前的栈帧中创建用于存储锁记录的空间 LockRecord\n\n- 2.线程将 MarkWord 拷贝到线程栈的 LockRecord 中，官方称之为 Displaced Mark Word\n\n- 3.将 LockRecord 中的 Owner 指针指向加锁的对象(存放对象地址)\n\n- 4.CAS 将锁对象的对象头的 Mark Word 替换为指向锁记录的指针，如果成功，当前线程获取到锁，如果失败，表示其他线程竞争锁，当前线程便尝试自旋获取锁。\n\n- 5.锁标志位变成 00，表示轻量级锁\n\n有锁状态下，如果是当前线程持有的锁，说明是重入，不需要争抢锁，会在栈帧中创建 Displaced Mark Word 为空的 Lock Record，用来记录锁的重入次数\n如果不是当前线程持有的锁，就要升级为重量级锁。\n\n##### 轻量级锁解锁\n\n使用 CAS 操作将当前线程栈帧中的 Displaced Mark Word 替换回锁对象头中，替换成功则解锁成功。替换失败则膨胀成重量级锁之后再解锁\n\n##### 膨胀过程\n\n有两种情况会膨胀成重量级锁。\n\n- 1.cas 自旋 10 次还没有获取锁，因为 CAS 会消耗 CPU。\n\n- 2.其他线程正在 CAS 获取锁，第三个线程竞争锁，锁也会膨胀成重量级锁\n\n##### 分类\n\n轻量级锁又分为自旋锁和自适应自旋锁\n\n###### 自旋锁\n\n所谓自旋，就是指当有另外一个线程来竞争锁资源时，这个线程会在原地循环等待，而不是把该线程给阻塞，直到原来获得锁的线程释放锁了之后，这个线程就可以获得锁\n\n锁在原地循环的时候是会消耗 cpu 资源的\n\n- 如果同步代码块执行的很慢，需要消耗大量的时间，那么自旋可能会大量消耗 CPU\n\n- 因为可能存在多个线程竞争锁，持有锁的线程释放锁之后，锁资源可能会被其他线程抢占，导致某些线程一直获取不到锁\n\n因此必须给自旋锁设置一个重试次数，默认 10 次，超过 10 次，锁会再次膨胀，升级为重量级锁\n\n###### 自适应自旋锁\n\n所谓自适应自旋锁，就是线程空循环等待的自旋次数并非固定的，而是会动态根据实际情况来改变自旋等待的次数\n\n1.假如 A 线程刚刚成功获取一个锁，等它释放锁了之后，锁被线程 B 获取，在线程 B 执行同步代码块期间，线程 A 又需要获取锁，此时只能自旋等待，但是虚拟机认为，线程 A 刚刚获得过该锁，那么这次自旋也很有可能再次成功获取锁，所以会增加线程 A 自旋的次数\n\n2.另外对于某个锁，一个线程自旋之后，很少成功获得该锁，那么以后这个线程再次尝试获取锁时，可能直接忽略掉自旋过程，直接升级成重量级锁，以免空等浪费资源\n\n#### 4.重量级锁\n\n重量级锁升级后是不可逆的，也就是说重量级锁无法再变为轻量级锁\n\n重量级锁是依赖对象内部的 monitor 锁来实现的，而 monitor 又依赖操作系统的 MutexLock(互斥锁)来实现的，所以重量级锁也被成为互斥锁\n\n重量级锁之所以被称为重量级，是因为 Java 线程是映射到操作系统的原生线程上的，如果要阻塞或唤醒一个线程，都需要依赖操作系统从当前用户态转换到核心态，这种状态转换需要耗费处理器很多时间，对于简单同步块，可能状态转换时间比用户代码执行时间还长，导致实际业务处理所占比偏小，性能损失较大\n\n### synchronized 锁的对象\n\n- 修饰在普通方法和普通代码块上，对象锁\n\n- 修饰静态方法或者静态代码块，类锁\n\n### 锁粗化和锁消除\n\n- 锁粗化: 将多次连在一起的加锁，解锁操作合并为一次，将多个连续的锁扩展为一个大范围的锁\n\n- 锁消除: Java 虚拟机在即时编译时，通过对上下文内容的扫描，去除不可能存在共享资源竞争的锁，通过消除这种没必要的锁，可以节省毫无意义的请求锁的时间\n\n### synchronized 如何实现可重入\n\n每个锁关联一个持有者线程和一个计数器，当计数器为 0 时，说明该锁没有被任何线程所持有，那么任何线程都可能获得该锁，当一个线程成功获取到锁之后，JVM 会记下持有锁的线程，并将计数器+1，此时其他线程请求该锁，则必须等待，而该锁持有者线程如果想要再次请求该锁，可以直接拿到，同时将计数器+1，当线程退出一个同步代码块之后，计数器会-1，如果计数器减为 0 则释放该锁\n\n### 对 synchronized 优化\n\n- 减少 synchronized 的范围:同步代码块中尽量短，减少同步代码执行时间，减少锁的竞争\n\n- 降低 synchronized 的锁力度:将一个锁拆分为多个锁提高并发度，尽量不要用类名.class 作为锁对象\n\n- 读写分离: 读取的时候不加锁，写入更新和删除的时候加锁\n\n### ReentrantLock\n\nReentrantLock 主要利用 CAS+AQS 队列来实现，支持公平锁和非公平锁，支持可重入\n\nReentrantLock 主要依赖 AQS 维护一个阻塞队列，多个线程加锁时，失败则会进入阻塞队列等待唤醒，重新尝试加锁\n\n![ReentrantLock](https://i.loli.net/2021/04/13/pHRoWU3TzvlmiZK.png)\n\n根据代码可知，ReentrantLock 里面有一个内部类 Sync，Sync 继承 AQS(AbstratcQueuedSynchronizer)，加锁和解锁的大部分操作实际上都是在 Sync 中实现的。它有公平锁 FairSync 和非公平锁 NonFairSync 两个子类。ReentrantLock 默认使用非公平锁，也可以通过构造器来显式的指定使用公平锁。\n\n#### 非公平锁\n\n资源释放，任何线程都有机会获得资源，而不管其申请顺序\n\nNonFairSync 继承自 ReentrantLock.Sync，而 Sync 继承自 AbstractQueuedSynchronizer。\n\nNonFairSync 的 tryAccquire 函数，会调用父类的 nofairTryAccqiure 函数:如果资源释放时，新的线程会尝试 CAS 获取锁，而不管阻塞队列中是否有比之先申请资源的线程\n\n非公平锁可能出现后申请锁的线程先获取到锁的情况。\n\n非公平锁的优点是可以减少唤起线程的开销，整体的吞吐量高，因为线程有几率不阻塞直接获取锁，CPU 不必唤醒所有线程\n\n非公平锁的缺点是处于等待队列中的线程可能会饿死，或者等很久才获得锁\n\n![NonFairSync](https://i.loli.net/2021/04/13/9u6iz8VHghd1TGC.png)\n\n![nonfairTryAcquire](https://i.loli.net/2021/04/13/y7GEuzlCxPSQrUm.png)\n\n##### 非公平锁加锁流程\n\n- 1.尝试获取锁，如果获取锁成功，直接返回\n\n检查 state 字段，若为 0，表示锁未被占用，那么 CAS 尝试占用，若不为 0，检查锁是否被当前线程占用，若被自己占用，则更新 state 字段，增加锁的重入次数，如果前面都没有成功，则获取锁失败，\n\n- 2.入队\n\n如果锁已经被其他线程获取，后面的线程执行 tryAccquire 失败，将进入等待队列\n\n- 3.挂起\n\n已经进入等待队列的线程先尝试获取锁，如果获取失败，线程会被挂起\n\n##### 非公平锁解锁流程\n\n先 tryRelease 尝试释放锁，若释放成功，那么查看头节点状态是否为 SIGNAL，如果是则唤醒头节点的下个节点关联的线程，如果释放失败那么返回 false 表示解锁失败\n\ntryRelease 中，若当前线程并没有持有锁，则抛出异常，若持有着锁，计算释放后的 state 值是否为 0，若为 0 表示已经成功释放，并且清空独占线程，最后更新 state 值，返回 true\n\n#### 公平锁\n\nFairSync 同样继承自 ReentrantLock.Sync，ReentrantLock 调用 lock 方法，最终会调用 Sync 的 tryAcquire 函数，获取资源。\n\n公平锁的优点是等待线程不会饿死。\n\n公平锁的缺点是整体整体吞吐消息相对于非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU 唤醒阻塞线程的开销要比非公平锁大。\n\n![FairSync](https://i.loli.net/2021/04/13/cGwX3jsuHNLiUtv.png)\n\n##### 公平锁加锁流程\n\n公平锁加锁不会检查 state 状态，直接 accquire(1)\n\n多个线程申请获取同一资源，必须按照申请顺序，依次获取资源\n\nFairSync 的 tryAccquire 函数定义: 当前线程只有在队列为空或者是队首节点的时候，才能获取资源，否则会被加入到阻塞队列中\n\n#### 可重入性\n\n获取独占资源的线程，可以直接重复获得该资源，不需要重复争取锁\n\nReentantLock 在申请资源的时候，都会判断当前线程是否是该资源的持有者，如果是，只是将 state 的值+1，记录当前线程的重入次数\n\nReentantLock 在释放资源的时候，都会调用 tryRelease，只有 state 为 0 的时候，才会真正释放资源\n\n重入多少次就必须释放多少次\n\n#### 超时机制\n\ntryLock(long timeout， TimeUnit unit)提供了超时获取锁的功能，在指定时间内获取到锁则返回 true，没有获取到锁则返回 false\n\n这种机制避免了线程无限期的等待锁释放\n\n##### 过程\n\n1.如果线程被中断了，直接抛出 InterruptedException，如果未中断，先尝试获取锁，获取成功直接返回，获取失败则进入 doAccquireNanos\n\n2.doAccquireNanos: 线程先进入等待队列，然后开始自旋，尝试获取锁，获取成功就返回，失败则在队列里找一个安全点把自己挂起直到超时时间过期.这里为什么还需要循环呢?因为当前线程节点的前驱状态可能不是 SIGNAL，那么在当前这轮循环中线程不会被挂起，然后更新超时时间，开始新一轮的尝试\n\n### 等待通知\n\nsynchronized 与 wait()和 nitofy()/notifyAll()方法相结合可以实现等待/通知模型\n\nReentrantLock 借助 Condition 可以实现等待/通知模型，且 Condition 具有更好的灵活性\n\n- 一个 Lock 里面可以创建多个 Condition 实例，实现多路通知\n\n- notify 方法进行通知时，被通知的线程是 Java 虚拟机随机选择的，但是 ReentrantLock 结合 Condition 可以实现有选择性的通知\n\n- Condition 类的 await 方法和 Object 的 wait 方法等效\n\n- Condition 类的 signal 方法和 Object 的 notify 方法等效\n\n- Condition 类的 signalAll 方法和 Object 的 notifyAll 方法等效\n\n### ReentrantReadWriteLock\n\n针对读多写少的情况，java 提供了 ReentrantReadWriteLock。读写锁允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程都会阻塞\n\n#### ReadWriteLock\n\n读写锁在读的时候上读锁，写的时候上写锁.这样就可以解决读与读之间互斥导致的性能问题\n\n读写锁支持锁降级，遵循按照获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁，不支持锁升级\n\n### AbstractQueuedSynchronizer 基本原理\n\nAbstractQueuedSynchronizer，AQS，抽象队列同步器\n\nAQS 是一个用于构建锁和同步器的框架，许多同步器都可以通过 AQS 很容易并且高效的构造出来，不仅 Reentrant 和 Semaphore 是基于 AQS 构建的，还包括 CountDownLatch，ReentrantReadWriteLock，SynchronousQueue 和 FutureTask\n\nAQS 实现了独占锁/共享锁，可中断锁/不可中断锁的逻辑\n\nAQS 使用 CLH 队列表示排队等待锁的线程，CLH 队列是一个先进先出的双向队列，队列头节点称作\"哨兵节点\"或者\"哑节点\"，它不与任何线程关联，其他的节点与等待线程关联，每个节点维护一个等待状态 waitStatus\n\nstate 称为共享资源或者同步状态，用 volatile 修饰，保证多线程下的可见性\n\nAQS 底层使用了模板方法模式，自定义同步器在实现时只需要实现共享资源 state 的获取与释放方法即可，至于具体线程的等待队列的维护(如资源获取失败入队/唤醒出队等)，AQS 已经在上层实现好\n\nAQS 中还有另外一个非常重要的内部类 ConditionObject，它实现了 Condition 接口，主要用于条件锁\n\nConditionObject 中也维护了一个队列，这个队列主要用于等待条件的成立，当条件成立时，其他线程将 signal 这个队列中的元素，将其移动到 AQS 的队列中，等待占有锁的线程释放锁后被唤醒\n\nCondition 典型的应用场景是在 BlockingQueue 中的实现，当队列为空时，获取元素的线程阻塞在 notEmpty 条件上，一旦队列中添加了一个元素，将通知 notEmpty 条件，将其队列中的元素移动到 AQS 队列中等待被唤醒\n\n### 多线程并发编程的三个特性\n\n- 可见性: 可见性是指当多个线程访问同一个共享变量时，一个线程修改了这个变量的值，其他的线程能够立即看到修改后的值\n\n- 原子性: 原子性指一个操作或者一组操作要么全部执行，要么全部不执行\n\n- 有序性: 有序性是指程序执行的顺序按照代码的先后顺序执行\n\n### java 内存模型定义的八种原子性操作\n\n- lock(锁定): 作用于主内存的变量，把一个变量标识为一个线程独占\n\n- unlock(解锁): 作用于主内存的变量，把一个处于锁定状态的变量解锁，解除锁定之后的变量才能被其他线程锁定\n\n- read(读取): 作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便后续的 load 动作使用\n\n- load(载入): 作用于工作内存的变量，把 read 操作从主内存中得到的变量值放入工作内存的变量副本中\n\n- use(使用): 作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时执行这个操作\n\n- assign(赋值): 作用于工作内存的变量，把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作\n\n- store(存储): 作用于工作内存的变量，把工作内存中的一个变量值传送到主内存中，以便后续的 write 的操作\n\n- write(写入): 作用于主内存的变量，把 store 操作从工作内存中传送的一个变量的值写入到主内存的变量中\n\n#### java 内存模型规则\n\nJava 内存模型还规定了在执行上述八种基本操作时，必须满足如下规则：\n\n- 如果要把一个变量从主内存中复制到工作内存，需要顺序执行 read 和 load 操作，如果把变量从工作内存中同步回主内存中，就要按顺序的执行 store 和 write 操作。但是 java 内存模型只要求上述操作按顺序执行，并没有邀请保证操作是连续的，也就是操作不是原子的，一组操作可以中断\n\n- 不允许 read 和 load，store 和 write 操作之一单独出现，必须成对出现\n\n- 不允许一个线程丢弃它最近的 assign 操作，即变量在工作内存中改变了之后必须同步回主内存中\n\n- 不允许一个线程无原因地(没有发生过任何 assign 操作)把数据从工作内存同步到主内存\n\n- 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化(load 或 assign)的变量，即对一个变量执行 use 和 store 之前，必须先执行过 assign 和 load 操作\n\n- 一个变量在同一时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一线程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会解锁。lock 和 unlock 必须成对出现\n\n- 如果对一个变量执行 lock 操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量之前需要重新执行 load 或 assign 操作初始化变量的值\n\n- 如果一个变量事先没有被 lock 锁定，则不允许对它进行 unlock 操作。也不允许去 unlock 一个被其他线程锁定的变量\n\n- 对一个变量执行 unlock 之前，必须先把此变量同步到主内存中(执行 store 和 write 操作)\n\n### CAS\n\n#### CAS 缺点\n\n1.循环时间开销大\n\n通过 do while 循环操作，如果替换失败，会一直进行尝试，如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销\n\n```java\npublic final int getAndAddInt(Object var1， long var2， int var4) {\n        int var5。\n        do {\n            var5 = this.getIntVolatile(var1， var2)。\n        } while(!this.compareAndSwapInt(var1， var2， var5， var5 + var4))。\n\n        return var5。\n    }\n```\n\n2.只能保证一个共享变量的原子操作\n\n当对一个共享变量执行操作时，可以使用循环 CAS 的方式来保证原子操作。但是对多个变量操作时，CAS 就无法保证操作的原子性，可以用加锁实现\n\n3.引来 ABA 问题\n\n可以通过 StampedReference 类解决\n","tags":["interview","synchronized","lock"]},{"title":"dubbo面试知识点(持续更新)","url":"/article/33ce6d02.html","content":"\n### 1.dubbo 负载均衡策略\n\n- 随机模式 RandomLoadBalance：按权重设置随机概率,在一个截面上碰撞的概率较高,但调用量越大分布越均匀,而且按概率使用权重后也比较均匀,有利于动态调整提供者权重\n\n- 轮询模式 RoundRobinLoadBlance：按公约后的权重设置轮询比例,但存在响应慢的服务提供者会堆积请求\n\n- 最少活跃调用 LeastActiveLoadBlance：相同活跃数的随机,活跃数指调用前后计数差,使慢的提供者收到更少请求,因为越慢的提供者的调用前后计数差会越大\n\n- 一致性 hash 调用 ConsistentHashLoadBalance：相同参数的请求总是发到统一提供者,当某台提供者挂掉时,原本发往该提供者的请求,基于虚拟节点,平摊到其他提供者,不会引起剧烈变动\n\n### 2.dubbo 集群容错\n\n- Failover cluster：失败重试,当服务消费者调用服务提供者失败后自动切换到其他服务提供者进行重试,通常用于读操作或者具有幂等的写操作,需要注意的是重试会带来更长延迟.可通过 retries=2 来设置重试次数（不含第一次）\n\n- Failfast cluster：快速失败,当服务消费方调用服务提供者失败后,立即报错,也就是只调用一次,通常这种模式用于非幂等性的写操作\n\n- Failsafe cluster：失败安全,当服务消费者调用服务提供者出现异常时,直接忽略异常.这种模式通常用于写入审计日志等操作\n\n- Failback cluster：失败自动恢复.当服务消费者调用服务提供者出现异常之后,在后台记录失败的请求,并按照一定的策略后期再进行重试,这种模式通常用于消息通知操作\n\n- Forking cluster：并行调用.当消费者调用一个接口方法后,dubboclient 会并行调用多个提供者提供的服务,只要一个成功返回,这种模式通常用于实时性要求较高的读操作,但需要浪费更多服务资源,可通过 forks=2 来设置最大并行数\n\n- Broadcast cluster：广播调用.当消费者调用一个接口方法后,dubboclient 会逐个调用所有服务提供者,任意一台调用异常则这次调用就标志失败,这种模式通常用于通知所有提供者更新缓存或日志等本地资源信息.\n\n### 3.dubbo 支持的协议\n\n#### dubbo 协议（默认）\n\n- 采用单一长连接和 NIO 异步通讯,适合小数据量大并发的服务调用,以及服务消费者机器远大于服务提供者机器数的情况,不适合传送大数据量的服务,比如传文件、传视频等,除非请求量很低;\n\n- 连接个数：单连接,\n\n- 连接方式：长连接,\n\n- 传输协议: TCP,\n\n- 传输方式: NIO 异步传输,\n\n- 序列化方式: Hessian 二进制序列化,\n\n- 适用场景：常规远程服务方法调用\n\n- dubbo 协议缺省每服务每提供者每消费者使用单一长连接,如果数据量较大,可以使用多个连接\n\n- 为防止大量连接撑挂,可以在服务提供方限制大连接接受数,以实现服务提供方自我保护\n\n##### 常见问题\n\n- 为什么要消费者比提供者个数多：因为 dubbo 协议采用单一长连接,假设网络为千兆网卡（1024Mbit=128MByte）,根据测试经验数据每条连接最多只能压满 7MByte,理论上 1 个服务提供者需要 20 个服务消费者才能压满网卡\n\n- 为什么不能传大包：因为 dubbo 协议采用单一长连接,如果每次请求的数据包大小为 500KByte,假设网络为千兆网卡,每条连接最大 7MByte,单个服务提供者的 TPS（每秒处理事务数）最大为：128MByte/500KByte=262.单个消费者调用单个服务提供者的 TPS 最大为：7MByte/500KByte=14.如果能接受,可以考虑使用,否则网络将成为瓶颈\n\n- 为什么采用异步单一长连接：因为服务的现状大都是服务提供者少,通常只有几台机器,而服务的消费者多,可能整个网站都在访问该服务,如果采用常规的 Hessian 服务,服务提供者很容易就被压垮,通过单一连接,保证单一消费者不会压死提供者,长连接,减少连接握手验证,并采用异步 IO,复用连接池,防止 C10K 问题\n\n#### rmi 协议\n\n- 采用 JDK 标准的 java.rmi.\\*实现,采用阻塞式短连接和 JDK 标准序列化方式\n\n- 连接个数：多连接\n\n- 连接方式：短连接\n\n- 传输协议：TCP\n\n- 传输方式：同步传输\n\n- 序列化：Java 标准二进制序列化\n\n- 适用范围：传入传出参数数据包大小混合,消费者与提供者个数差不多,可以传文件\n\n- 适用场景：常规远程方法调用,与原生 rmi 服务互操作\n\n#### Hessian 协议\n\n- Hessian 协议用于集成 Hessian 服务,Hessian 底层采用 http 通讯,采用 servlet 暴露服务,dubbo 缺省内置 Jetty 作为服务器实现\n\n- dubbo 的 Hessian 协议可以和原生的 Hessian 服务互操作,即提供者用 dubbo 的 Hessian 协议暴露服务,消费者直接用标准 Hessian 接口调用;或者提供方用标准 Hessian 暴露服务,消费方用 dubbo 的 Hessian 协议调用\n\n- 连接个数：多连接\n\n- 连接方式：短连接\n\n- 传输协议： http\n\n- 传输方式：同步传输\n\n- 序列化： Hessian 二进制序列化\n\n- 适用范围：传入传出参数数据包较大,提供者比消费者个数多,提供者压力较大,可传文件\n\n- 适用场景：页面传输,文件传输,或与原生 Hessian 服务互操作\n\n- 参数及返回值需实现序列化接口\n\n- 参数及返回值不能自定义实现 List,Map,Number,Date,Calender 等接口,只能用 JDK 自带的实现,因为 Hessian 会做特殊处理,自定义实现类中的属性值都会丢失\n\n#### http 协议\n\n- 基于 http 表单的远程调用协议\n\n- 连接个数：多连接\n\n- 连接方式：短连接\n\n- 传输协议：http\n\n- 传输方式：同步传输\n\n- 序列化：表单序列化,即 json\n\n- 适用范围：传入传出参数数据包大小混合,提供者比消费者个数多,可用浏览器查看,可用表单或者 url 传入参数,暂不支持传文件\n\n- 适用场景：需同时给应用程序和浏览器 JS 使用的服务\n\n#### webservice 协议\n\n- 基于 webservice 的远程调用协议,基于 Apache CXF 的 fronted-simple 和 transports-http 实现\n\n- 可以和原生 webservice 服务互操作：提供者用 dubbo 的 webservice 协议暴露服务,消费者直接用标准的 webservice 接口调用;或提供者用标准的 webservice 暴露服务,消费者用 dubbo 的 webservice 协议调用\n\n- 连接个数：多连接\n\n- 连接方式：短连接\n\n- 传输协议：http\n\n- 传输方式：同步传输\n\n- 序列化：soap 文本序列化\n\n- 适用场景：系统集成,跨语言调用\n\n- 参数及返回值需实现序列化接口\n\n- 参数尽量使用基本类型和 POJO\n\n#### thrift 协议\n\n- 当亲 dubbo 支持的 thrift 协议是对 thrift 原生协议的拓展,在原生协议的基础上添加了一些额外的头信息,比如 service name, magic number 等.\n\n- 使用 dubbo thrift 协议同样需要使用 thrift 的 idl compiler 编译生成相应的 Java 代码\n\n- thrift 不支持 null 值,不能在协议中传 null\n\n#### memcached 协议\n\n- 基于 memcached 实现的 rpc 协议\n\n#### redis 协议\n\n- 基于 redis 实现的 rpc 协议\n\n#### rest 协议\n\n- 基于标准的 java rest api--JAX-RS2.0 实现的 REST 调用支持\n\n### 4.dubbo 推荐用什么协议\n\n默认使用 dubbo 协议\n\n### 5.dubbo 默认使用什么序列化框架\n\ndubbo 协议默认使用 Hessian2 序列化\n\nrmi 协议默认使用 java 序列化\n\nhttp 协议默认为 json\n\nHessian 协议默认 Hessian 序列化\n\nwebservice 协议默认 soap 文本序列化\n\n也可以指定第三方的序列化框架,比如 kryo,FST 等\n\n### 6.SpringCloud 和 dubbo 对比\n\n- dubbo 由于是二进制的传输,占用带宽会更少\n\n- SpringCloud 是 http 协议传输,带宽会比较多,同时使用 Http 协议一般会使用 json 报文,消耗更大\n\n- dubbo 的开发难度较大,原因是 dubbo 的 jar 包依赖问题很多大型工程无法解决\n\n- SpringCloud 的接口协议约定比较自由松散,需要有强有力的行政措施来限制接口无序升级\n\n- dubbo 的注册中心可以选择 zk,redis 等,SpringCloud 的注册中心可以选 eureka 或者 Consul\n\n- SpringCloud 提供了丰富的组件:如服务网关\\断路器\\分布式配置\\链路追踪等\n","tags":["interview","dubbo"]},{"title":"rabbit-mq面试知识点(持续更新)","url":"/article/a8db1400.html","content":"\n### 1.rabbitmq 作用 优缺点\n\n作用：\n\n解耦,异步,削峰\n\n优点：\n\n延迟低,可用性高,并发能力强,开源管理界面,社区活跃\n\n缺点：\n\n吞吐量相对较差,阅读源码门槛高,集群动态拓展麻烦,增加 mq 之后增加系统复杂性,可能降低系统可用性,\n\n### 2.rabbitmq 中的角色\n\n- 消息代理 broker\n- 生产者 producer\n- 消费者 consumer\n- 消息队列 queue\n- 交换机 exchange\n- 绑定 binding\n- 路由键 routingKey\n\n### 3.如何保证消息的可靠性传递（如何处理消息丢失的问题）\n\n- 生产者丢失数据的情况\n\n生产者在发送数据到 mq 时,可能消息还没到达服务端,因为网络通信等原因消息就丢失了,\n\n#### transaction 机制\n\n此时可以采用 rabbitmq 提供的事务消息功能,就是生产者发送数据之前开启 rabbitmq 事务（channel.txSelect）,然后发送消息,如果消息没有被 rabbitmq 成功接收到,生产者就会收到异常报错信息,此时就可以回滚事务（channel.txRollback）,然后重试发送消息；如果收到了消息,那么可以提交事务（channel.txCommit）。但是问题是 rabbitmq 开启事务消息之后会因为消耗性能,影响吞吐量\n\n#### confirm 机制\n\n所以一般来说,如果要确保写入 rabbitmq 的消息不丢失,可以开启 confirm 模式,在生产者那里开启 confirm 之后,每次写的消息都会被分配一个唯一 id,如果消息成功写入 rabbitmq 中,rabbitmq 会回调 ack 接口,通知生产者这个消息写入成功。如果 rabbitmq 没能成功处理这条消息,会回调 nack 接口,通知生产者消息处理失败,此时可以进行重试。而且用户可以结合这个机制在内存中维护每个消息 id 的状态,如果超过一定时间没有收到消息的回调通知,可以操作重发\n\n事务机制和 confirm 机制最大的不同在于,事务机制是同步的,提交事务之后会阻塞,但是 confirm 是异步的,发送消息不需要等待返回结果,而是通过 rabbitmq 异步回调通知接口\n\n所以一般为了避免生产者数据丢失,都是用 confirm 机制\n\n- rabbitmq 丢失数据\n\nrabbitmq 自己弄丢数据,比如内存爆满、服务器宕机等情况,会导致已经存储到 rabbitmq 上的数据丢失,此时必须开启 rabbitmq 的持久化功能,将数据存储到磁盘,开启之后即使 rabbitmq 服务挂了,在重启之后会自动读取之前存储的数据进行恢复,极为罕见的是 rabbitmq 还没有进行持久化的操作,服务就已经挂了,可能会导致少量数据丢失\n\n设置持久化有两个步骤,第一个是创建 queue 的时候将其设置为持久化的,这样可以保证 rabbitmq 持久化 queue 的元数据,但是不会持久化 queue 里存的数据；第二步是发送消息的时候将消息的 deliverMode 设置为 2,也就是将消息设置为持久化的,此时 rabbitmq 就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行,才能保证 rabbitmq 重启之后,可以恢复 queue 然后恢复 queue 中的数据\n\n哪怕是给 rabbitmq 开启了持久化,也可能在消息写到 rabbitmq 之后,持久化到磁盘之前,服务宕机,就会导致这部分数据丢失\n\n- 消费者丢失数据\n\n消费者丢失数据一般出现在刚刚接收到消息还没有进行处理的时候,这个时候出现了消费者服务宕机或者异常中断导致消息丢失,rabbitmq 认为消费者已经消费完毕,数据就会丢失了\n\n这时候需要用到 rabbitmq 提供的 ack 机制,关闭 rabbitmq 的自动 ack,在程序处理完成之后进行手动的 ack,没有收到 ack 消息 rabbitmq 是不会丢弃消息的\n\n### 4.如何保证消息队列的高可用\n\nrabbitmq 有三种模式：单机模式,普通集群模式,镜像集群模式\n\n单机模式：\n\n单台服务器\n\n普通集群模式：\n\n多台服务器上启动多个 rabbitmq 实例,但是创建的 queue 只会放到一个实例上,但是每个实例都会同步 queue 的元数据,消费的时候如果链接到了另外一台 rabbitmq 实例,这个实例会从 queue 所在实例上拉取数据\n\n这种模式需要消费者每次随机链接一个实例之后拉取数据,或者固定链接到 queue 所在实例进行消费,前者有拉取数据的开销,后者导致单实例性能瓶颈化,而且如果 queue 所在的实例宕机,会导致其他实例无法进行 queue 数据的拉取,如果开启了消息持久化,数据不一定会丢失,但是要等实例恢复了才能从此 queue 消费\n\n这个方案主要是为了提高吞吐量,就是说让集群中多个节点来服务某个 queue 的读写操作\n\n镜像集群模式：\n\n这种模式才是所谓的 rabbitmq 的高可用模式,跟普通集群模式不同的是,创建的 queue 无论是元数据还是 queue 中的消息都会存在于多个实例上,然后每次生产者将消息写入到 queue 中时,都会自动把消息同步到多个实例中的 queue 中\n\n这样的好处在于,任何一台实例宕机了都不会对消息的生产和消费造成影响。坏处在于,第一性能开销太大,消息同步所有实例,导致网络带宽的压力和消耗很重,第二没有拓展性,每台实例的机器压力都很容易达到性能瓶颈\n\n如何开启镜像集群模式,在 rabbitmq 控制台新增一个策略,这个策略是镜像集群模式的策略,指定的时候可以要求数据同步到所有节点,也可以要求数据只同步到指定数量的节点或者指定名称的节点,然后再次创建 queue 的时候,应用此策略,就会自动将数据同步到其他节点上\n\n### 5.如何保证消息不被重复消费（如何保证消息消费时的幂等性）\n\n数据库记录消息保证唯一\n\n消息带唯一标识,通过 redis 避免重复消费\n\n### 6.如何保证消息的顺序性\n\n- rabbitmq 为什么要保证消费的顺序性\n\nqueue 中的数据只能被一个消费者所消费,多个消费者在消费过程中是无序的,多个消费者同时消费一个 queue,顺序错乱就会导致数据的不一致,这和我们预期的结果不符\n\n- 如何保证顺序性\n\n1. 拆分多个 queue,每个 queue 对应一个 consumer\n\n2. 一个 queue 对应一个 consumer,然后这个 consumer 内部用内存队列做排队,然后底层分发给不同的 worker 去处理\n\n### 7.如何解决消息队列的延时及过期失效问题？消息队列满了应该怎么办？有几百万消息持续积压几个小时,如何解决？\n\n原因：消费端出问题了,消息无法被消费或者消费缓慢,消息队列集群的磁盘可能都快写满了,积压时间过长,rabbitmq 设置了消息过期时间消息可能没被消费就过期了\n\n举例：消费端每次消费之后都要写入 mysql,结果 mysql 挂了,消费端 hang 住无法继续消费消息,或者其他原因导致消费者消费缓慢\n\n分析：\n\n#### 1.大量消息在 mq 积压几个小时\n\n消费者出现问题,即使恢复也需要等待消息被消费,等待时间可能会很长,需要操作临时紧急扩容\n\n- 先修复 consumer 的问题,确保其恢复消费速度,然后将现有 consumer 都停掉\n\n- 新建一个 topic,partition 是原来的 10 倍,临时建立好原先 10 倍或者 20 倍的 queue 数量\n\n- 然后写一个临时的分发数据的 consumer 程序,这个程序部署上去消费积压的数据,消费之后不做耗时的处理,直接轮询写入临时建立好的 10 倍数量的 queue\n\n- 接着用临时征用 10 倍的机器来部署 consumer,每一批 consumer 消费一个临时 queue 的数据\n\n- 这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍,以正常 10 倍的速度来消费数据\n\n- 等快速消费完积压数据之后,得恢复原先架构部署,重新用原来的 consumer 机器来消费消息\n\n#### 2.假设设置了消息过期时间,也就是 TTL,如果消息在 queue 中积压超过一定时间就会被 rabbitmq 给清理掉,这个数据就会丢失\n\n- 写临时程序根据数据逻辑重新生成丢失的消息,重新写入 mq 中\n\n### 8.如何设计一个消息队列\n\n#### 1.支持可伸缩性,支持快速扩容,便于增加吞吐量和容量\n\n分布式系统,broker->topic->partition,每个 partition 加一台机器,就存一部分数据,如果当前资源不够了,就给 topic 增加 partition,做数据迁移,增加机器\n\n#### 2.持久化,保证数据不丢失\n\n顺序写,这样就没有磁盘随机读写的寻址开销,磁盘顺序写的性能是很高的\n\n#### 3.可用性\n\n多副本->leader&follower->broker 挂了重新选举 leader 提供对外服务\n\n### 9.rabbitmq 通信全过程\n\n- 生产者生产消息后,将消息发布给交换机 exchange\n\n- 交换机根据路由规则将消息路由到队列 queue\n\n- broker 再将 queue 中的消息投递给订阅该队列的消费者,或者是消费者从队列中获取消息\n\n- 给 exchange 绑定一个备份交换机,当到达原 exchange 的消息不能被正确路由到任何队列时,消息被发送给备份交换机\n\n- 备份交换机将消息根据路由规则路由到备份队列,存储\n\n- 由于可以给消息设置过期时间,所以当原 queue 中的消息达到过期时间仍未被消费时,会被发送到死信交换机；或者发送给消费者的消息被拒绝后,也会被发送到死信交换机\n\n- 死信交换机根据路由规则将消息路由到死信队列,存储\n\n### 10.rabbitmq 实现订单超时自动关闭\n\n- 死信队列：下单投放消息到 A 交换机,设置过期时间,消息到 AA 队列,为 AA 队列绑定死信交换机,不设置 AA 队列的消费者,让消息不会被消费,消息过期后会投递到死信交换机,死信队列,由死信消费者消费,判断订单是否已经完成支付,已支付则无需处理,未支付执行关闭订单、返还库存等逻辑\n\n- 延时队列：下单发送延时消息到延时队列交换机,消息会保持在 broker 中,并不是立即投递给消费者,只有在到达指定延时时间之后才会投递给消费者,在延时队列消费者中判断订单是否已经完成支付,已支付则无需处理,未支付执行关闭订单、返还库存等逻辑\n\n- 两种方案对比：延时队列需要插件支持,需要实例化更多的 Bean\n\n- 其他方案：定时任务（不准）,线程休眠（重启影响）,监听 redis 键值过期时间,监听 zookeeper 节点过期时间\n\n### 11.rabbitmq 工作模式\n\n#### 简单模式\n\n一个生产者,一个消费者\n\n#### 工作队列模式\n\n一个生产者,多个消费者,每个消费者获取到的消息唯一,默认轮询获取\n\n### 12.Exchange 模式\n\n- 发布订阅模式（fanout）：一个生产者发送的消息会被多个消费者获取,发送到 fanout exchange 的消息都会被转发到与 exchange 绑定的所有 queue 上,这种模式不需要 routingkey,需要提前将 exchange 与 queue 进行绑定,一个 exchange 可以绑定多个 queue,一个 queue 可以和多个 exchange 绑定,如果接收到消息的 exchange 没有与任何 queue 绑定,则消息会丢失\n\n- 路由模式（direct）：任何发送到 direct exchange 的消息都会被转发到 routingKey 指定的 queue,这种模式不需要 exchange 进行任何绑定,消息传递时需要一个 routingkey,可以简单理解为要发送到的队列名称,如果 vhost 中不存在该队列名,消息会丢失\n\n- 匹配订阅模式（topic）：任何发送到 topic exchange 的消息都会被转发到所有关心 routingkey 指定 Topic 的 queue 中,就是每个队列都有其关心的 Topic,所有的 Topic 都带有一个 routingkey,exchange 会将消息转发到所有关注 Topic 能与 routingkey 模糊匹配的队列。这种模式需要 routingkey 并且提前绑定 exchange 与 queue,在进行绑定时要提供一个该队列对应的 Topic,'#'表示 0 或者若干个关键字,'\\*'表示一个关键字,如果 exchange 没有发现能够与 routingkey 匹配的 queue,消息会丢失\n\n- headers 模式：header exchange 主要通过发送的 request message 中的 header 进行匹配,其中匹配规则（x-match）又分为 all 和 any,all 表示必须所有的键值对匹配,any 表示只要有一个键值对匹配即可,headers exchange 的默认匹配规则（x-match）是 any\n","tags":["interview","rabbitmq"]},{"title":"redis面试知识点总结(持续更新)","url":"/article/8df47b3e.html","content":"\n## redis 数据丢失\n\n### Redis 哨兵，当主节点发生故障时，需要进行主备切换，可能会导致数据丢失\n\n### 异步复制数据导致的数据丢失\n\n主节点异步同步数据给备用节点的过程中，主节点宕机了，导致有部分数据未同步到备用节点。而这个从节点又被选举为主节点，这时候就会有部分数据丢失\n\n### 脑裂导致的数据丢失\n\n主节点所在机器脱离了集群网络，实际上自身还是运行着的。但这时原来的集群中主节点的从节点升级成了主节点，这个时候就有两个主节点都在运行，这就是脑裂\n\n发生脑裂后，客户端还没有来得及切换到新的主节点，连的还是原来的，有些数据还是写入到了第一个节点里面，新的节点没有这些数据。等到第一个节点恢复后，会降级为从节点连接到集群，而且自身数据会被清空，重新从主节点复制数据。而新的主节点因为没有客户端之前写入的数据，所以导致数据丢失了一部分\n\n### 如何避免\n\n- 配置 min-slaves-to-write 1，表示至少有一个从节点\n\n- 配置 min-slaves-max-lag 10，表示数据复制和同步的延迟不能超过 10 秒。最多丢失 10 秒的数据\n\n## redis 为什么这么快\n\n1. 纯内存操作，一般都是简单的存取操作，线程占用的时间很多，时间的花费主要集中在 IO 上，所以读取速度快\n2. 整个 redis 就是一个全局 hash 表，他的时间复杂度是 O(1)，而且为了防止 hash 冲突导致链表过长，redis 会执行 reHash 操作，扩充 hash 桶数量，减少 hash 冲突。并且防止一次性重新映射数据过大导致线程阻塞，采用渐进式 rehash，巧妙的将一次性拷贝分摊到多次请求过程中，避免阻塞。\n3. redis 采用的是非阻塞 IO，IO 多路复用。采用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，redis 采用自己实现的事件分离器，效率比较高\n4. 单线程,省去了上下文切换的消耗,CPU 利用率高\n5. redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如跳表，使用有序的数据结构加快了读写速度\n6. 根据实际存储的数据类型选择不同编码\n\n## 1.redis 支持的数据结构\n\nredis 支持 5 种基本数据结构，分别是 string、list、set、zset 和 hash\n\n同时 redis 还支持 3 种特殊的数据类型，分别是 geo、bitmap 和 hyperloglog\n\nstring:\n\n二进制安全的数据类型，可以用来存储图片二进制流或者序列化之后的对象，最大上限 512M\n\n可以保存（1）二进制序列字符串（2）整形数据（3）浮点数据\n\n可以用来做原子计数器\n\n可以用来实现分布式锁（拓展：分布式锁）\n\nlist:\n\n简单的 string 列表，相当于 java 中的 LinkedList，按照插入顺序排序，写操作时间复杂度是 O(1)，读操作时间复杂度是 O(n)\n\n双向链表，可以头插（LPUSH）或者尾插（RPUSH）\n\nlist 最大长度是 2^32-1\n\n发布订阅，可以实现简单的消息队列\n\n通过 list 裁剪功能可以实现排行榜\n\nset:\n\nstring 的无序集合，相当于 java 中的 HashSet，set 内部使用 hash 表保证唯一性，添加、删除、查找的时间复杂度都是 O(1)\n\nset 最大成员个数是 2^32-1\n\n可以通过指令实现交集、并集等操作\n\n可以用于实现去重操作\n\nhash:\n\nstring 的键值对集合，相当于 java 中的 HashMap，特别适合用来存储对象结构\n\nhash 中最大可以存储 2^32-1 个键值对\n\n可以用来实现购物车\n\nredis 数据库就是由 hash 来实现的\n\n渐进式 rehash：在 redis 中针对哈希冲突采用的是渐进式 rehash 操作，渐进式 rehash 会保留新旧两个 hash 结构，查询时同时间查询两个 hash 结构，在后续的定时 任务及 hash 操作的过程中完成从旧 hash 结构迁移到新 hash 结构的过程\n\nzset:\n\nzset 即 sorted set，是带有排序功能的 string 集合，不允许重复的成员\n\n通过为每个对象设置一个 double 类型的 score（分数）来实现排序，根据 score 值从小到大对对象进行排序，不同的成员可以设置相同的 score\n\n增加、修改和删除元素的时间复制度为 O(logN)\n\n可以实现排行榜\n\n（拓展：skipList）\n\nbitmap(2.2.0 版本新增):\n\n位图，byte 数组，用二进制表示，只有 0 和 1 两个数字，基于 string 实现，节省内存\n\n实现布隆过滤器（拓展：布隆过滤器）\n\n可以用于统计员工每日打卡\n\n统计用户在线状态\n\nhyperloglog(2.8.9 版本新增):\n\n用于基数统计\n\n可以用于埋点统计\n\ngeo(3.2 版本新增):\n\n存储地理位置信息，底层由 zset 实现\n\n计算两个坐标点直接的距离\n\n实现附近的人\n\n## 2.与 memcached 比较\n\nredis 支持多种数据类型，memcached 只支持 string 类型\n\nredis 的 string 类型最大可以达到 512M，而 memcached 最大只支持 1M\n\nmemcached 只支持把数据存储到内存，而 redis 提供了持久化方式\n\nmemcached 本身不支持分布式，需要通过客户端的分布式算法实现分布式集群，而 redis 通过 redis cluster 提供了分布式集群功能（拓展：hash 算法）\n\nmemcached 支持多核多线程，而 redis 接收指令只支持单线程\n\n## 3.redis 持久化\n\nredis 提供两种持久化方式，分别是 RDB 和 AOF\n\nRDB:\n\n可以在指定的时间间隔内对存储在 redis 服务器中的某个时间点的数据做快照，主进程会 fork 出一个子进程将快照数据写入临时文件并定期刷新到磁盘，redis 在启动时会读取之前生成的快照文件内容加载到内存中。\n\nAOF:\n\n以指定的时间间隔将服务器执行的所有指令记录下来，以追加的方式写入到指定的日志文件中，当日志文件过大时，redis 会创建子进程对日志文件进行重写。redis 提供了 3 种同步策略：每秒同步/每次修改同步/不同步\n\n比较：\n\nredis 先加载 AOF 文件来恢复原始数据，因为 AOF 数据比 RDB 更完整。\n\n但是 AOF 文件容易被损坏，损坏的 AOF 文件可以通过 redis-check-aof 进行修复\n\nRDB 文件进行了压缩，所以占用体积小，传输速度快，但是如果设置备份时间间隔太长，丢失数据量较大，数据量越大，fork 子进程时间越长，可能阻塞主进程，可读性差\n\nAOF 设置每秒追加一次，如果发生宕机只会丢失 1s 内的数据，生成文件较大，相对于 RDB 效率低，启动恢复慢\n\n混合模式(4.0 版本新增)：\n\n生成新的 AOF 文件前半段是 RDB 文件的全量数据，后半段是 AOF 模式的增量数据。在重启时加载此 AOF 文件进行恢复\n\n## 4.redis 内存淘汰策略\n\nredis 在进行内存淘汰时，采用两种方式：定时扫描主动清除+惰性删除（访问到已经过期的 key 时才进行删除）\n\nnoeviction：\n\n当内存达到 maxmemory 限制时，直接报错\n\nvolatile-lru：\n\n在所有设置了过期时间的 key 中挑选最近最少使用的数据进行淘汰（拓展：LRU 和 LFU）\n\nvolatile-random：\n\n在所有设置了过期时间的 key 中随机挑选一些进行淘汰\n\nvolatile-ttl：\n\n在所有设置了过期时间的 key 中，选择一些即将过期的 key 进行淘汰\n\nallkeys-random：\n\n在所有 key 中随机挑选一些进行淘汰\n\nallkeys-lru：\n\n在所有 key 中挑选最近最少使用的数据进行淘汰\n\nvolatile-lru, volatile-random 和 volatile-ttl 在没有符合条件的 key 可以被淘汰时，表现和 noeviction 一样\n\nvolatile-lfu(4.0 版本新增)：\n\n在所有设置了过期时间的 key 中，挑选最近最不经常使用的 key 进行淘汰\n\nallkeys-lfu(4.0 版本新增):\n\n在所有 key 中挑选最近最不经常使用的 key 进行淘汰\n\n## 5.缓存雪崩/缓存击穿/缓存穿透\n\n缓存雪崩：\n\n缓存数据批量过期，大量的请求穿过缓存直接打到数据库，给数据库带来很大压力，严重的情况可能导致数据库宕机\n\n解决方案：\n\n设置缓存 key 过期时间时增加随机值，避免缓存同时失效\n\n对热点缓存 key 不设置过期时间\n\n本地内存缓存+redis 缓存+服务降级\n\n缓存击穿：\n\n缓存中的热点数据存活时间到期或者被误删除，并发查询此缓存数据的请求穿过缓存打到数据库\n\n解决方案：\n\n对热点缓存 key 不设置过期时间\n\n分布式锁，遇到热点缓存 key 失效时，去请求分布式锁，拿到锁的线程才能去请求数据库，从数据库中查询到有效的数据之后放入缓存，这样后续进来的请求都可以直接从缓存中拿到数据，减轻了数据库压力，也可以避免多个线程同时查询数据库更新缓存，以免造成缓存脏数据\n\n缓存穿透：\n\n查询不存在于缓存也不存在于数据库的数据，这样请求相当于缓存不存在直接请求数据库，当并发请求量大时会对数据库造成很大压力\n\n解决方案：\n\n接口层增加参数校验\n\n缓存空值，设置较短的过期时间\n\n布隆过滤器\n\n## 6.redis 集群模式\n\n单机模式:\n\n优点:简单\n\n缺点:内存容量有限,处理能力有限,无法实现高可用\n\n主从复制:\n\n主从复制允许一个 redis 服务器创建多个复制品,被复制的服务器为 master,从 master 复制的服务器为 slave,master 会将自身的数据通过网络更新同步给 slave\n\n优点:可以通过 master 写入数据,通过 master/slave 读取数据\n\n缺点:无法实现高可用，没有解决 master 写的压力\n\n哨兵 sentinel:\n\n监控 redis 主从服务器,并在 master 下线时自动进行故障转移\n\n监控(Monitoring):sentinel 会不断检查 master 和 slave 是否正常运行\n\n提醒(Notification):当被监控的某个 redis 服务器出现问题时,sentinel 可以通过 API 向管理员或其他应用程序发送通知\n\n自动故障迁移(Automatic failover):当一台 master 不能正常运行时,sentinel 会开始一次自动故障迁移操作,将此 master 的一台 slave 升级成为 master,当原来下线的 master 故障恢复之后,会自动降级为新的 master 的 slave（拓展：哨兵主动切换）\n\n优点:保证高可用，提供节点监控及报警功能\n\n缺点：占用服务器资源，切换需要时间，可能存在丢失数据的风险，没有解决 master 写的压力\n\n集群（代理）:\n\n通过 Twemproxy 或者 codis 第三方代理实现 redis 集群的方式\n\n优点：支持多种 hash 算法，提供第三方功能\n\n缺点：引入代理，维护成本高，failover 逻辑需要自己实现，其本身不能支持故障的自动转移可扩展性差，进行扩缩容都需要手动干预\n\n集群（直连，3.0 版本新增）:\n\nRedis-Cluster 集群，采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。\n\n无中心架构。数据按照 slot 存储在多个节点，节点间数据共享，可以动态调整数据分布（拓展：一致性 hash 算法，hash 槽）。可拓展，节点可以动态添加或删除。高可用，部分节点不可用不影响整体集群，可以通过对节点增加 slave 的方式进行数据备份。实现故障自动 failover,节点间通过 gossip 协议（拓展：gossip 协议）交换状态信息，用投票机制完成主从角色切换。\n\n缺点：资源隔离性较差，容易相互影响。数据通过异步复制，不保证数据的强一致性。\n\n## 7.常见的 redis 客户端\n\nJedis\n比较全面的 redis 操作指令，阻塞 IO，调用方法是同步的，不支持异步，不是线程安全的，所以需要配合连接池来使用\n\nRedission\n基于 Netty 框架的事件驱动的通信层，提供 redLock 实现，调用方法是异步的，线程安全，不支持字符串操作，不支持排序、事务、管道、分区等 redis 特性\n\nLettuce\n基于 Netty 框架的事件驱动的通信层，调用方法是异步的，线程安全\n\n## 8.其他 redis 问题\n\nredis 实现分布式锁\n\n单机\n\n加锁：setnx px(ex)\n\n释放锁：lua 脚本原子性操作\n\n优点：简单，单实例安全\n\n缺点：主从或者集群模式下，如果加锁成功后，锁对象未来得及从 master 同步到 slave，slave 挂了，可能也会出现多实例获取到锁的现象。如果锁住的代码块逻辑执行时间过长，超过缓存的过期时间，锁自动释放，相同的逻辑可能会执行多次\n\n集群\n\nredLock（拓展：redLock）\n\nredis 和 mysql 如何保持数据一致性\n\n先读取缓存，缓存中没有再去读取数据库，读取到数据之后将数据维护进缓存\n\n设置缓存过期时间\n\n删除缓存失败重试\n\n1.延时双删\n\n先删除缓存，再更新数据库，休眠一定时间之后再更次删除缓存\n\n2.异步延时删除\n\n先删除缓存，再更新数据库，发送 MQ 消息再次删除缓存\n\n3.监听 binlog\n\n更新数据库，监听程序监听到 binlog 变化，删除缓存，如果删除失败，发送 mq 消息重试，直至删除成功\n\nredis cluster 只支持 db0\n","tags":["redis","interview"]},{"title":"学习接入sentinel","url":"/article/32240ede.html","content":"\n学习使用 sentinel 流控功能\n\n### 配置 sentinel 控制台\n\n1.可以从 github 获取源码到本地编译或者直接下载官方提供的 jar 包\n\ngithub 地址:<https://github.com/alibaba/Sentinel.git>\n\n操作流程\n\n```shell\ngit clone https://github.com/alibaba/Sentinel.git\ncd Sentinel\nmvn clean package\n```\n\njar 包下载地址: <https://github.com/alibaba/Sentinel/releases>\n\n2.启动控制台\n\n`java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar`\n\n其中 8080 是指定控制台程序的启动端口,如果端口被占用可以修改成别的。\n\n启动成功之后打开 localhost:8080 可以看到 sentinel 控制台的登录界面\n\n![](https://cdn.jsdelivr.net/gh/Aias00/picgo/images/1.png)\n\n默认的用户名密码都是 sentinel\n\n登录成功之后页面\n![](https://cdn.jsdelivr.net/gh/Aias00/picgo/images/2.png)\n\n在这个页面展示了所有连接到 sentinel 的服务相关信息\n\n### 配置项目连接到 sentinel\n\n1.建一个项目,配置文件指向 sentinel\napplication.yml\n\n```yml\nspring:\n  application:\n    name: coco-sentinel\n  profiles:\n    active: dev\n  cloud:\n    sentinel:\n      transport:\n        port: 8719\n        dashboard: localhost:8080\nserver:\n  port: 9993\n```\n\npom.xml\n\n```xml\n<dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n        <!-- spring-cloud-alibaba-sentinel -->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\n        </dependency>\n    </dependencies>\n```\n\n测试类\n\n```java\n@RestController\npublic class SentinelController {\n    @Resource\n    private TestService service;\n\n    @GetMapping(value = \"/hello/{name}\")\n    public String apiHello(@PathVariable String name) {\n        return service.sayHello(name);\n    }\n}\n@Service\npublic class TestService {\n    @SentinelResource(value = \"sayHello\")\n    public String sayHello(String name) {\n        return \"Hello, \" + name;\n    }\n}\n```\n\n@SentinelResource 注解用来标识资源是否被限流、降级。上述例子上该注解的属性 sayHello 表示资源名。\n@SentinelResource 还提供了其它额外的属性如 blockHandler，blockHandlerClass，fallback 用于表示限流或降级的操作（注意有方法签名要求），更多内容可以参考 Sentinel 注解支持文档<https://github.com/alibaba/Sentinel/wiki/%E6%B3%A8%E8%A7%A3%E6%94%AF%E6%8C%81>。若不配置 blockHandler、fallback 等函数，则被流控降级时方法会直接抛出对应的 BlockException；若方法未定义 throws BlockException 则会被 JVM 包装一层 UndeclaredThrowableException\n\n2.启动服务,请求一次,然后查看 sentinel 控制台\n\n![](https://cdn.jsdelivr.net/gh/Aias00/picgo/images/3.png)\n\n可以看到我们的服务已经在控制台展示出来了\n\n### 流控配置\n\n1.点击我们要设置流控的服务,点击簇点链路,找到刚才指定的资源,即 sayHello\n\n![](https://cdn.jsdelivr.net/gh/Aias00/picgo/images/4.png)\n\n2.点击流控,在弹出的对话框里设置单机阈值为 1\n\n![](https://cdn.jsdelivr.net/gh/Aias00/picgo/images/5.png)\n\n3.点击新增,保存成功之后可以看到刚才配置的流控规则信息\n\n![](https://cdn.jsdelivr.net/gh/Aias00/picgo/images/6.png)\n\n4.这时再次请求我们的接口,可以发现在 1 秒内只有一次请求能成功\n\n![](https://cdn.jsdelivr.net/gh/Aias00/picgo/images/7.png)\n\n而我们应用的控制台打印出了 UndeclaredThrowableException\n\n![](https://cdn.jsdelivr.net/gh/Aias00/picgo/images/8.png)\n\n本文代码地址:<https://gitee.com/AtlsHY/coco/tree/master/coco-sentinel>\n更多详细内容请参考官方文档:<https://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel>\n","tags":["sentinel"]},{"title":"使用Nacos注册中心功能","url":"/article/bc887465.html","content":"\n开始学习使用 spring-cloud-alibaba\n\n### 启动部署 Nacos\n\n1.下载链接 <https://github.com/alibaba/nacos/releases>\n\n2.选择一个版本下载之后解压,之后进入到 bin 目录\n\n- linux 执行 `sh startup.sh -m standalone`\n- windows 执行 `cmd startup.cmd -m standalone`\n\n命令参数中-m 表示模式 mode，standalone 表示启动的是单机版模式\n\n3.启动日志如下\n![image-20210401133617644](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401133617644.png)\n\n![image-20210401133938392](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401133938392.png)\n\n从启动日志中我们可以看出:\n\n- Nacos 默认启动的端口号是 8848\n- Nacos 本次启动的进程 pid 是 13640\n- Nacos 控制台页面访问 url:<http://localhost:8848/nacos/index.html>\n- 根据下面一些的日志,很容易就能确定 Nacos 是基于 spring 开发的\n\n4. 访问 Nacos 控制台页面\n\n![image-20210401133917153](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401133917153.png)\n\n默认用户名和密码都是 nacos\n\n### 使用 Nacos 注册中心功能\n\n1.创建一个 maven 父工程,引入 spring-cloud-alibaba 相关依赖\n\n```xml\n    <dependencyManagement>\n        <dependencies>\n            <!--spring-boot-->\n            <dependency>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-dependencies</artifactId>\n                <version>2.2.4.RELEASE</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n            <!-- spring-cloud -->\n            <dependency>\n                <groupId>org.springframework.cloud</groupId>\n                <artifactId>spring-cloud-dependencies</artifactId>\n                <version>Hoxton.SR3</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n            <!-- spring-cloud-alibaba -->\n            <dependency>\n                <groupId>com.alibaba.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>2.2.1.RELEASE</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n```\n\n2.创建一个 provider 模块和一个 consumer 模块,引入 alibaba-nacos-discovery 依赖\n\n```xml\n<dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n        <!--nacos注册中心-->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n    </dependencies>\n```\n\n3.为 provider 模块创建服务提供接口,并添加 bootstrap.yml 作为配置文件\n\n```java\n@RestController\npublic class ProviderController {\n\n    @GetMapping(\"/echo\")\n    public String echo(String string) {\n        return \"Hello Nacos Discovery \" + string;\n    }\n\n}\n```\n\n```yml\nspring:\n  application:\n    name: coco-provider\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 192.168.70.1:8848 #注册中心地址\nserver:\n  port: 9990\n```\n\n4.启动 provider 服务,服务启动成功之后查看 nacos 控制台->左侧服务管理->服务列表,可以看见 provider 服务的相关信息\n![image-20210401134207281](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401134207281.png)\n\n5.配置 consumer 服务,在启动类上增加`@EnableDiscoveryClient`注解,添加 bootstrap.yml 作为配置文件,并添加接口利用 RestTemplate 调用 provider 提供的方法\n\n启动类\n\n```java\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class CocoConsumerApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(CocoConsumerApplication.class, args);\n    }\n}\n```\n\nrestTemplate 配置类\n\n```java\n@Configuration\npublic class RestConfig {\n    @LoadBalanced\n    @Bean\n    public RestTemplate restTemplate() {\n        return new RestTemplate();\n    }\n}\n```\n\n消费者接口类\n\n```java\n@RestController\npublic class ConsumerController {\n    @Resource\n    private RestTemplate restTemplate;\n\n    @GetMapping(\"/echo\")\n    public String echo(String str) {\n        return restTemplate.getForObject(\"http://coco-provider/echo/?string=\" + str, String.class);\n    }\n}\n```\n\n配置文件\n\n```yml\nspring:\n  application:\n    name: coco-consumer\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 192.168.70.1:8848 #注册中心地址\nserver:\n  port: 9991\n```\n\n6.启动 consumer 服务,可以在 Nacos 服务列表看见两个服务\n![image-20210401134230450](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401134230450.png)\n\n7.调用 consumer 接口,可以实现通过 consumer 接口调用 provider 提供的方法\n![image-20210401134245658](https://gitee.com/AtlsHY/picgo/raw/master/images/image-20210401134245658.png)\n\n8.本文相关代码提交到 gitee: <https://gitee.com/AtlsHY/coco>\n","tags":["spring-cloud-alibaba","spring-cloud-alibaba-nacos","spring-cloud"]},{"title":"记录线上activemq出现的问题","url":"/article/5883ff82.html","content":"\n某天凌晨接到售后的电话,说线上设备出现了批量离线的问题,下意识以为是之前 Netty 相关服务代码导致的问题又复现了,但是排查了一下发现并不是这个原因\n现在把这个问题记录下来,虽然至今还没有找到具体原因但是已经大致缩小了范围\n\n1. 各个服务平台报出无法与 mq 建立连接的错误\n\n2. 查询 mq 服务进程发现进程 pid 还在但是端口号却没了\n\n3. 因为急着解决问题,于是联系运维重启了 mq 服务(这里不应该,其实应该先查一下 mq 进程的状态,这里直接重启导致后面无法细致排查)\n\n4. 事后分析 mq 日志及源码,发现在出现问题之前的一些迹象:\n\n   - 凌晨 00:10,mq 集群 Master 主机发生了不明原因的网络波动,导致 master 与 zookeeper 的连接超时,断开连接\n\n   - 断开连接之后 mq master 自动降级为 slave\n\n   - mq master 在降级为 slave 的过程中先要将自己的 master 服务和 broker 服务停止,然后以 slave 角色重新启动\n\n   - 在 mq 重启的过程中又恢复了与 zookeeper 的连接\n\n   - 在 mq 停止 master 服务过程中没有停止成功,处于挂起状态\n\n   - 由于 mq master 服务 hang 在挂起状态,导致 mq 集群没有完成角色切换,这个状态就是 master 死了一半,但是其他 slave 依旧还是 slave\n\n   - 整个 mq 集群没有办法对外服务,消费者无法消费,导致 mq 消息堆积,导致设备显示离线\n\n5. 以上就是目前分析出的整个状况,因为没有保留事故现场并且因为急着恢复服务导致没有排查出真正的原因,是什么原因导致的 master 与 zookeeper 连接断开,以及为什么 master 服务会没有完成重启动作\n","tags":["activemq","线上问题"]},{"title":"在亚马逊免费试用ubuntu","url":"/article/db8ef88b.html","content":"\n本篇不写参与试用方法,只记录启动实例之后做的一系列操作,只要是 ubuntu-18.04 版本的系统都可以参考此操作流程\n\n### 更新 apt\n\n```shell\napt-get update\n```\n\n### 安装 shadowsocks-libev\n\n因为服务器在东京,正好手头没有合适的梯子,不利用起来就是浪费\n\n1.准备编译环境\n\n```shell\napt install --no-install-recommends build-essential autoconf libtool \\\n    libssl-dev gawk debhelper dh-systemd init-system-helpers pkg-config asciidoc \\\n    xmlto apg libpcre3-dev zlib1g-dev libev-dev libudns-dev libsodium-dev \\\n    libmbedtls-dev libc-ares-dev automake\n```\n\n2.安装 git\n\n```shell\napt install git -y\n```\n\n3.获取源码并编译\n\n首先要进入到你想要保存源码的目录,比如/usr/local/xxx(自己建的文件夹)\n\n```shell\ngit clone https://github.com/shadowsocks/shadowsocks-libev.git\ncd shadowsocks-libev\ngit submodule update --init\n./autogen.sh && ./configure --disable-documentation && make\nsudo make install\n```\n\n4.创建配置文件\n\n```shell\nsudo mkdir /etc/shadowsocks-libev\nsudo vim /etc/shadowsocks-libev/config.json\n```\n\n配置文件内容,记得修改密码\n\n```json\n{\n  \"server\": \"0.0.0.0\",\n  \"server_port\": 8388,\n  \"local_port\": 1080,\n  \"password\": \"password\",\n  \"timeout\": 600,\n  \"method\": \"aes-256-cfb\",\n  \"fast_open\": false\n}\n```\n\n5.创建 Shadowsocks-libev.service 配置文件,用于配置服务启动\n\n```shell\nsudo vim /etc/systemd/system/shadowsocks-libev.service\n```\n\n内容如下:\n\n```shell\n[Unit]\nDescription=Shadowsocks-libev Server\nAfter=network.target\n\n[Service]\nType=simple\nExecStart=/usr/local/bin/ss-server -c /etc/shadowsocks-libev/config.json -u\nRestart=on-abort\n\n[Install]\nWantedBy=multi-user.target\n```\n\n6.启动服务\n\n```shell\nsudo systemctl start shadowsocks-libev\n```\n\n7.配置开机启动\n\n```shell\nsudo systemctl enable shadowsocks-libev\n```\n\n至此,配置完成,自己找找客户端进行连接,上网冲浪吧(记得开放安全组端口噢)\n\n### 未完待续\n","tags":["liunx"]},{"title":"使用Aliyun OssClient的错误案例","url":"/article/f2cdca07.html","content":"\n### 事故描述\n\n公司的硬件设备和设备网关服务是以 TCP 长连接方式通讯的,网关服务用到了 Netty\n\n前段时间突然线上一批新的设备集体离线, 查看设备网关发现网关进程的 netstat 存在大量的 CLOSE_WAIT 状态连接\n\n第一时间重启了设备网关,很快设备正常上线了,观察一段时间之后发现又开始陆续出现 CLOSE_WAIT 状态的连接\n\n### 分析原因\n\n仔细观察了一下这些连接,发现这些连接的目标地址都是阿里云的,不由得想到之前添加的一个将设备日志上报阿里云 oss 的小功能\n\n### 解决问题\n\n这个功能先是封装了一层请求阿里云 Oss 客户端的代码,然后将这个工具作为依赖引入到原有的项目中,在封装过程中想到为了避免重复创建 OssClient 引起资源消耗,所以定义了一个全局的 client,创建成功之后可以全局复用,所以没有显示调用 oss 的 shutdown()方法,正是这个想法导致了线上出现的问题;\n\n将全局 OssClient 改为每次上传前创建,上传完毕之后调用ossClient.shutdown()方法关闭连接,问题就再没复现过\n","tags":["线上问题","ossClient","CLOSE_WAIT"]},{"title":"redisTemplate反序列化时遇到的问题","url":"/article/d84d4fa.html","content":"\n最近在开发中使用了 RedisTemplate 来操作 redis 缓存,SpringBoot 集合 RedisTemplate 感觉用起来也不错,同时在开发过程中也遇到了一些问题,在这里记录一下整个过程\n\n### 配置\n\n- 创建 SrpingBoot 项目或者模块工程,引入依赖\n\n```xml\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-data-redis</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.data</groupId>\n            <artifactId>spring-data-commons</artifactId>\n        </dependency>\n```\n\n- 添加 redis 配置参数\n\n```yml\nspring:\n  redis:\n    host: localhost\n    port: 6379\n    jedis:\n      pool:\n        min-idle: 50\n        max-idle: 10\n        max-wait: 200\n        max-active: 300\n```\n\n- 添加配置类,修改 redis 中存储 key 和 value 的序列化和反序列化方式,RedisTemplate 默认配置的是使用 Jdk 序列化,这种序列化方式对存储对象不是很方便\n\n```java\n@Configuration\npublic class RedisConfig {\n    @Resource\n    private RedisTemplate<String, Object> redisTemplate;\n\n    @Bean\n    public RedisTemplate<String, Object> redisTemplateInit() {\n        // 设置key的序列化方式为String\n        redisTemplate.setKeySerializer(RedisSerializer.string());\n        // 设置Hash key的序列化方式为String\n        redisTemplate.setHashKeySerializer(RedisSerializer.string());\n        // new 一个jackson方式的valueSerializer 序列化和反序列化方式都为json\n        Jackson2JsonRedisSerializer<Object> jackson2JsonRedisSerializer =\n                new Jackson2JsonRedisSerializer<>(Object.class);\n        // 自定义ObjectMapper\n        ObjectMapper objectMapper = new ObjectMapper();\n        // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public\n        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常\n        objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(objectMapper);\n        // 设置value的序列化方式为json\n        redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);\n        // 设置hash value的序列化方式为json\n        redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer);\n        redisTemplate.afterPropertiesSet();\n        return redisTemplate;\n    }\n```\n\n这样就配置好了 RedisTemplate\n\n### 问题\n\n记录一下遇到的一些问题\n\n- 存到 redis 中的数据,读取出来之后类型不是原来的类型,而是 LinkedHashMap\n\n在 jackson2JsonRedisSerializer 中没有配置自定义 objectMapper,而 jackson2JsonRedisSerializer 默认的 ObjectMapper 没有配置 DefaultTyping 属性,jackson 将使用简单的数据绑定具体的 java 类型,其中 Object 就会在反序列化的时候变成 LinkedHashMap\n\n- 之前也试过 FastJsonRedisSerializer,利用这种序列化方式,如果没有一个包含无参构造函数或者一个包含全部参数的构造函数,在反序列化之后会出现属性丢失,因为 Serializer 在反序列化时会调用对象类的构造器去进行属性注入\n\n- 用 jackson2JsonRedisSerializer 或者 GenericJackson2JsonRedisSerializer, 如果没有一个包含无参构造函数,反序列化时会报错\n","tags":["redis"]},{"title":"注解@Resource和@Autowired的区别","url":"/article/759d9b9f.html","content":"\n在应用 spring 框架进行开发时,我们常常用@Resource 和@Autowired 注解进行依赖注入\n\n在开发过程中仿佛这两者应用起来并没有什么区别,但是其实这两个注解本质上就是不一样的\n\n区别如下:\n\n- @Resource 是由 java 提供的注解,而@Autowired 是由 spring 提供的\n\n- @Resource 是 ByName,而@Autowired 是 ByType\n\n- @Autowire 注入时 ByType 如果要使用 ByName 需要配合@Qualifier\n\n```java\n  @Autowire\n  @Qualifier（\"orderService\"）\n  private OrderService orderService;\n\n```\n\n- @Resource 默认 ByName,当找不到与名称匹配的 bean 才会按照类型装配,可以通过 name 属性指定,如果没有指定 name 属性，当注解标注在字段上,即默认取字段的名称作为 bean 名称寻找依赖对象，当注解标注在属性的 setter 方法上,即默认取属性名作为 bean 名称寻找依赖对象\n\n- 注意：如果没有指定 name 属性,并且按照默认的名称仍然找不到依赖的对象时候,会回退到按照类型装配,但一旦指定了 name 属性,就只能按照名称装配了\n","tags":["spring"]},{"title":"我是如何使用策略模式的","url":"/article/f4f8ffc6.html","content":"\n### 关于\n\n在工作中遇到数据类型不同,需要采用不同的方式处理,常见的写法是根据条件进行判断,采用 if...else... 或者 switch 的方式\n\n比如我最近在写的工单,不同类型工单需要的数据和处理逻辑各有区别\n\n由于工单类型比较多,想到要写一堆 if...else...我就头大,这样的代码太丑,我不喜欢...\n\n略一思考,用策略模式去实现,就清爽很多\n\n### 步骤\n\n首先我们需要定义一个接口,定义一个方法,然后由各个类型工单的具体处理类去实现,代码:\n\n```java\n\npublic interface OrderHandler{\n  public void handle(Order order);\n}\n\n```\n\n然后根据工单类型去写出各自相应的实现类,比如加油工单、洗车工单\n\n```java\n\npublic class JiayouOrderHandler implements OrderHandler{\n\n  @Override\n  public void handle(Order order){\n    System.out.println(\"去加油\");\n    // ...\n  }\n\n}\n\npublic class CleanOrderHandler implements OrderHandler{\n\n  @Override\n  public void handle(Order order){\n    System.out.println(\"去洗车\");\n    // ...\n  }\n\n}\n\n```\n\n然后需要根据不同工单类型定义好枚举,将工单类型和实际的操作类去做一个绑定\n\n```java\npublic enum OrderTypeEnum{\n\n  JIAYOU(\"JIAYOU\",new JiayouOrderHandler()),\n  XICHE(\"XICHE\",new CleanOrderHandler()),\n  ;\n\n  public String type;\n\n  public OrderHandler handler;\n\n  OrderTypeEnum(String type, OrderHandler handler) {\n        this.type = type;\n        this.handler = handler;\n  }\n\n  // 根据传入的工单类型匹配到具体的操作类\n  public static OrderHandler getHandler(String type){\n      OrderTypeEnum[] values = OrderTypeEnum.values();\n      for (OrderTypeEnum value : values) {\n          if(type.equals(value.type))){\n              return value.handler;\n          }\n      }\n      return null;\n  }\n\n  public String getType() {\n      return type;\n  }\n\n  public OrderHandler getHandler() {\n      return handler;\n  }\n\n}\n```\n\n然后调用的地方\n\n```java\n\npublic static void main(String[] args){\n\n  Order order = new Order();\n  order.type = \"JIAYOU\";\n  // ...\n  OrderHandler handler = OrderTypeEnum.getHandler(order.getType());\n  if(null == handler){\n    System.out.println(\"不支持的工单类型\");\n    return ;\n  }\n  handler.handle(order);\n\n}\n\n```\n\n没有一堆的 if...else...,真开心!\n","tags":["设计模式"]},{"title":"查看redis所有key对应value占用内存大小","url":"/article/670c67ee.html","content":"\n公司的一个服务用了一个单台 redis 服务器,本来配置 redis 的 maxmemory 只有 512M,但是服务跑了几个月都没什么问题,说明是够用的。\n\n但是最近不到一个月的时间的时间,这台服务器的 redis 报了两次内存不足,最开始是以为调用量慢慢上来了,所以只是单纯的修改 maxmemory 的值,修改到了 3g。\n\n昨天观察了一下发现内存占用已经到了 2.3g 了,这马上又快满了,觉得不对劲,所以想要分析一下是哪些 key 占用的空间比较大,看看能不能相应的优化一下代码\n\n### 环境\n\n- CentOS Linux release 7.2.1511\n\n- redis-5.0.4\n\n- python2.7\n\n- git\n\n### 工具\n\n在网上查了一下,发现了 redis-rdb-tools 这个工具,redis-rdb-tools 是一个快照文件解析器,可以对 rdb 文件中所有 key 对应的 value 的大小等数据进行分析,可以导出 json/csv 等格式文件\n\n### 安装流程\n\n```shell\n\nyum install python-dev\n\npip install rdbtools python-lzf\n\ngit clone https://github.com/sripathikrishnan/redis-rdb-tools (到自己选定的路径下克隆)\n\ncd redis-rdb-tools\n\npython setup.py install\n\n```\n\n### 操作流程\n\n- 找到 redis 的 dump.rdb 位置, 如我们的 /Data/redis/dump.rdb\n\n- 在安装 redis-rdb-tools 的目录下执行指令 : rdb -c memory /Data/redis/dump.rdb > /home/proview/redis.csv (将 rdb 内存分析结果存储到指定目录的 csv 文件中)\n\n- 在安装 redis-rdb-tools 的目录下执行指令 : rdb --command json /Data/redis/dump.rdb > /home/proview/redis.json (将 rdb 内存分析结果存储到指定目录的 json 文件中)\n\n- 在安装 redis-rdb-tools 的目录下执行指令 : rdb --command json --key \"key1.*\" /Data/redis/dump.rdb > /home/proview/redis-key.json (将指定key的 rdb 内存分析结果存储到指定目录的 json 文件中)\n\n拿下来这个 csv 一看,有个 key 占用达到了 2g,然后就去分析代码吧\n","tags":["redis"]},{"title":"缓存雪崩","url":"/article/90da3a95.html","content":"\n### 什么是缓存雪崩\n\n缓存雪崩通常是指缓存大面积失效,或者 Redis 宕机,大量的请求直接去请求到了数据库,在并发大的情况下可能直接导致数据库宕机\n\n### 出现缓存雪崩的原因\n\n在将数据存入缓存的时间我们通常都需要为缓存设置过期时间,避免缓存长时间占用内存资源,当然也会配合 redis 的淘汰策略对缓存进行失效淘汰\n\n假如缓存设置的过期时间是相同的并且刚好在同一时刻全部失效,或者 Redis 宕机,就会造成所谓的缓存雪崩\n\n### 如何避免缓存雪崩\n\n- 在对缓存 key 设置过期时间的时候给这个过期时间加上一个随机值,尽量避免缓存同时失效的情况发生\n\n- 一些热点数据可以不设置过期时间,这样缓存就不会过期,在更新数据成功之后再将缓存失效\n\n- 为了避免 redis 宕机的情况,最好是采用 redis 哨兵或者集群模式部署,将热点数据分散存储在不同的 redis 库中也能避免雪崩的发生\n\n- 最好是配合本地缓存+降级服务,这样如果缓存真的出了问题至少服务是可用的\n","tags":["cache"]},{"title":"缓存穿透和缓存击穿","url":"/article/6c6b9155.html","content":"\n### 什么是缓存穿透和缓存击穿\n\n缓存穿透和缓存击穿是存在区别的两种情况:\n\n- 缓存穿透\n\n要查询的数据本来就不存在于缓存,也不存在于数据库。当各种请求进来查询的时候,先查缓存,没有查到就会去持久层查询数据库,依旧查不到。下一个请求再来查的时候还是相同的情况。\n\n在这种情况下,缓存这一层相当于不存在,所有请求直接查询了数据库\n\n- 缓存击穿\n\n如果缓存中的数据因为某种原因失效(存活时间到期或者被删除等),并发查询这条数据的请求在失效的瞬间就会穿过缓存去查询数据库,就像在缓存这层开了个洞,所以被成为缓存击穿\n\n以上这两种情况在并发量大的情况下会对数据库造成很大压力,甚至可能引起数据库宕机\n\n### 面对缓存穿透一些解决办法\n\n- 缓存空值\n\n面对缓存穿透的情况,这类数据因为本来就不存在,所以最终请求到的结果也是空值,所以可以将对应的 key 直接存入缓存,value 相应设置为 null 或者空字符串(根据业务)\n\n为了保证这些缓存数据不会对后期真实存在了的数据数据造成影响,需要对这类缓存设置一个相对较短的过期时间,而且应该保证在真正的数据入库成功之后,将这些缓存失效\n\n因为这种方法在有效数据入库成功之后和使空值缓存失效之前,存在一定的时间差,还是可能造成一段时间的数据不一致\n\n而且将空值存入缓存也会占用缓存资源,造成内存浪费。如果遭受恶意攻击,将大量空值存入缓存,可能会将内存资源占满,造成缓存服务器一定时间无法访问\n\n这种解决方案的建议使用场景为: key 全集数据数据量级较小，并且完全可预测，可以通过提前填充的方式直接将数据缓存\n\n- 布隆过滤器(BloomFilter)\n\n本质上布隆过滤器是一种数据结构,比较巧妙的概率型数据结构,特点是高效地插入和查询,可以用来告诉你\"某样东西一定不存在或者可能存在\"\n\n相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少,但是缺点是其返回的结果是概率性的，而不是确切的\n\n通常把有数据的 key 都放到 BloomFilter 中,每次查询的时候都先去 BloomFilter 判断,如果没有就直接返回空\n\n由于布隆过滤器不支持删除操作,对于删除的 key,查询就会经过 BloomFilter 然后查询缓存再查询数据库,所以 BloomFilter 建议结合缓存空值用,对于删除的 key,可以在缓存中缓存空\n\n同样它也不支持扩容操作,这就要求布隆过滤器建立初期必须进行严格的推算,确保后期不需要扩容,否则重建布隆过滤器的成本可能会超乎想象\n\n### 缓存击穿的一些解决办法\n\n- 互斥锁(独占锁)\n\n在缓存失效的时候,并不直接去查询数据库,而是要拿到锁,由成功抢占到锁资源的线程去查询数据库,并更新回缓存,更新缓存成功,释放锁资源,后续\n\n这样可以避免多个线程同时穿过缓存去查询数据库,防止多个线程对缓存进行重复更新的情况发生\n","tags":["cache"]},{"title":"关于缓存我的理解","url":"/article/f431f94b.html","content":"\n### 为什么要用缓存\n\n缓存主要是为了支持高性能/高并发的处理逻辑,以及缓解数据库的压力\n\n不考虑持久化的情况,缓存中的数据基本上都是存在于内存中,相比于查询数据库,程序读取内存的速度要快的多\n\n假设没有缓存,程序直接读取数据库,在高并发的情况下,很容易导致数据库宕机\n\n### 什么是数据库缓存读写一致性\n\n所谓的数据库缓存一致性主要指的是最终一致性,因为数据库和缓存本来就属于两个个体,所以要让他俩时时刻刻保持数据一致基本上是很难实现的\n\n工作中常见的保证数据库一致性的基本流程如下:\n\n- 查询:如果在缓存中查到了,直接返回查询结果;如果在缓存中没有查到,就去查数据库,然后将结果写入缓存,然后返回\n\n- 更新:直接更新数据库,如果更新成功,使缓存失效;这样再下一次查询时就会将查询结果写入缓存\n\n### 为什么不能写完数据库之后更新缓存\n\n写数据库和写缓存是两次写入,存在时间差,假设两个线程同时操作一条数据,A 线程先写入数据库,B 线程后写入数据库,但是 B 线程先更新完缓存,之后 A 线程才更新缓存,就会导致数据库缓存不一致\n\n而且我认为,在更新完数据库之后,数据并不一定马上就需要被用到,可能很久以后才会查询到,那么更新完数据库就放进缓存,属于浪费资源\n\n### 其他保证数据库缓存一致性的思路\n\n- Read Through Pattern\n\n缓存失效之后缓存自己从数据库中加载数据\n\n- Write Through Pattern\n\n当有数据更新的时候,如果没有命中缓存,直接更新数据库,然后返回;如果命中了缓存，则更新缓存,然后再由 Cache 自己更新数据库（这是一个同步操作）\n\n- Write Behind Caching Pattern\n\n在更新数据的时候,只更新缓存,不更新数据库,而我们的缓存会异步地批量更新数据库\n\n### 推荐\n\n酷壳 [缓存更新的套路](https://coolshell.cn/articles/17416.html \"缓存更新的套路\")\n","tags":["cache"]},{"title":"redis实现分布式锁-单redis实例实现分布式锁","url":"/article/8dec7256.html","content":"\n### 为什么要用分布式锁\n\n在开发过程中,涉及到单服务多实例同时运行,某些操作例如定时任务跑批/更新数据等,为了避免多个实例同时对同一共享资源进行多次操作或者重复操作,我们需要分布式锁来进行并发协调\n\n### 单 Redis 实例实现分布式锁\n\n获取锁使用命令: SET resource_name my_random_value NX PX 30000\n\n这个命令利用了 redis 2.6.12 版本以后提供的 set (ex nx px xx) 指令, 这个指令支持对 set 指令设置参数\n\n其中:\n\n- EX seconds : 将键的过期时间设置为 seconds 秒\n\n- PX: 将键的过期时间设置为 milliseconds 毫秒\n\n- NX: 只有键不存在时,才会对键进行设置操作\n\n- XX: 只有键已经存在时,才对键进行设置操作\n\n这个指令只有在不存在 resource_name 这个 key 的时候才能执行成功,并且为这个 key 设置了一个 30s 的过期时间,这个 key 的值是一个 random_value(随机数)\n\n设置过期时间是为了保证操作线程如果在获取锁之后挂掉了,锁到了过期时间依旧可以自动释放,避免了死锁的情况发生\n\nvalue 值必须是随机数主要是为了能够更安全地释放锁,释放锁的操作需要结合 lua 脚本实现\n\n```lua\nif redis.call(\"get\",KEYS[1]) == ARGV[1] then\n    return redis.call(\"del\",KEYS[1])\nelse\n    return 0\nend\n```\n\n这个指令的意思是:只有 key 存在并且存储的值和传入的值一样才能进行删除操作,否则返回 0\n\n这样操作的是为了避免一个实例删除了其他实例获取的锁, 删除锁不能先 get 再 del 因为这两步没有原子性，假设 get 后锁刚好时间到了，过期了，就会把别人上的锁删掉，而 lua 脚本就有原子性的\n\nkey 的失效时间，被称作“锁定有效期”。它不仅是 key 自动失效时间，而且还是一个客户端持有锁多长时间后可以被另外一个客户端重新获得\n\n用 Java 简单实现的效果\n\n加锁:\n\n```java\npublic static boolean tryLock(String key, String randomValue, int seconds) {\n    return \"OK\".equals(jedis.set(key, randomValue, \"NX\", \"EX\", seconds));\n}\n```\n\n解锁:\n\n```java\npublic static boolean releaseLock(String key, String randomValue) {\n    String luaScript = \"if redis.call('get', KEYS[1]) == ARGV[1] then \" +\n            \"return redis.call('del', KEYS[1]) else return 0 end\";\n    return jedis.eval(\n        luaScript,\n        Collections.singletonList(key),\n        Collections.singletonList(randomValue)\n    ).equals(1L);\n}\n```\n\n优点:\n\n- 代码简洁,单 redis 实例安全\n\n缺点:\n\n- 只支持单 redis 实例,集群/主从模式下,如果加锁成功后,锁的 value 从 Master 复制到 Slave 的时候挂了,也是会出现同一资源被多个 Client 加锁的\n\n- 如果锁住的代码块逻辑执行时间过长,可能会超过缓存的过期时间,锁自动释放,相同的资源可能会被操作多次\n","tags":["redis"]},{"title":"redis基本数据类型","url":"/article/dbc52038.html","content":"\nRedis 支持 5 种基本数据类型: string(字符串) / hash(哈希) / list(列表) / set(无序集合) / zset(有序集合)\n\n### 1.string\n\nstring 是 Redis 最基本的类型,string 类型是二进制安全的,string 类型可以包含任何数据,例如图片二进制流或者序列化之后的对象\n\nstring 类型最大能存储 512M 的内容\n\n![操作string](https://gitee.com/AtlsHY/picgo/raw/master/images/1.png)\n\n### 2.hash\n\nhash 是一个键值对的集合\n\nhash 是一个 string 类型的 field 和 value 的映射表,对应 java 集合中的 map 类型,特别适合用来存储对象结构\n\n每个 hash 可以存储 2^32 -1 个键值对（40 多亿）\n\n![操作hash](https://gitee.com/AtlsHY/picgo/raw/master/images/2.png)\n\n### 3.list\n\nlist 是简单的字符串列表，按照插入顺序排序\n\n你可以添加一个元素到列表的头部（左边）或者尾部（右边）,即双向链表\n\nlist 最多可存储 2^32 - 1 个元素 (4294967295, 每个列表可存储 40 多亿)\n\n![操作list](https://gitee.com/AtlsHY/picgo/raw/master/images/3.png)\n\n### 4.set\n\nset 是 string 类型的无序集合\n\nset 是通过哈希表实现的,所以添加/删除/查找的复杂度都是 O(1)\n\n添加一个 string 元素到 key 对应的 set 集合中，成功返回 1，如果元素已经在集合中返回 0\n\n集合中最大的成员数为 2^32 - 1(4294967295, 每个集合可存储 40 多亿个成员)\n\n![操作set](https://gitee.com/AtlsHY/picgo/raw/master/images/4.png)\n\n### 5.zset\n\nzset 即 sorted set, 有序集合\n\nzset 和 set 一样也是 string 类型元素的集合,且不允许重复的成员\n\n不同的是每个元素都会关联一个 double 类型的分数(score)。redis 正是通过分数来为集合中的成员进行从小到大的排序\n\nzset 的成员是唯一的,但分数却可以重复\n\n![操作zset](https://gitee.com/AtlsHY/picgo/raw/master/images/5.png)\n","tags":["redis"]},{"title":"搭建SpringBoot+dubbo+zookeeper简单demo工程","url":"/article/ce309dda.html","content":"\n### 1.创建一个基于 maven 的 SpringBoot 工程，type 选择 maven pom\n\n![](https://i.loli.net/2021/04/01/zs5V1yP2Bu3fWNX.png)\n\n![](https://i.loli.net/2021/04/01/1rGqw4MkodtyZRF.png)\n\n![](https://i.loli.net/2021/04/01/eZMuIxrgkGLWT9N.png)\n\n![](https://i.loli.net/2021/04/01/AwG4ina6TJkFsDQ.png)\n\n### 2.创建完成之后的工程结构如下，生成的 pom.xml 内容如下\n\n![](https://i.loli.net/2021/04/01/iMjXfLvqCYV2Any.png)\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>2.1.8.RELEASE</version>\n        <relativePath/> <!-- lookup parent from repository -->\n    </parent>\n    <groupId>com.aias</groupId>\n    <artifactId>demo</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>demo</name>\n    <description>Demo project for Spring Boot</description>\n\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n</project>\n```\n\n### 3.在父类项目上右键->New->Module，添加三个子 module，demoProvider（服务提供者）\\demoConsumer（服务调用者）\\common（公共模块），过程和创建父类工程类似\n\n![](https://i.loli.net/2021/04/01/TUcaNkHXCKVQR6P.png)\n\n![](https://i.loli.net/2021/04/01/hEo6K78jcTluaMt.png)\n\n![](https://i.loli.net/2021/04/01/qPKyXiRLgaFjG5S.png)\n\n### 4.修改子模块的 pom.xml，将<parent>里的内容替换成我们父工程的内容\n\n### 5.common 工程里创建一个 User.java 和 IUserService，common 工程之后是打包成被其他 Module 项目依赖的 jar 包，不需要独立部署，所以这里把其他的无用文件夹删除，完成之后的目录结构如下。\n\n![](https://i.loli.net/2021/04/01/RWIwmfKGxvpDgUo.png)\n\n### common 项目的 pom.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>com.aias</groupId>\n        <artifactId>demo</artifactId>\n        <version>0.0.1-SNAPSHOT</version>\n    </parent>\n    <groupId>com.aias</groupId>\n    <artifactId>common</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>common</name>\n    <description>Demo project for Spring Boot</description>\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n</project>\n\n```\n\n### 6.demoProvider 工程中添加了 MyBatis、druid 和 mysql-connector 的依赖，实现了 IUserService 接口类，实现了对数据库的实际操作，目录结构如下。在不添加其他配置和依赖的情况下，可以通过单元测试\n\n![](https://i.loli.net/2021/04/01/qzUnk4xPr5tXI1O.png)\n\n### 7.添加 dubbo 和 dubbo-spring-boot-starter 依赖，在 application.properties 中添加 dubbo 相关配置信息，然后启动单元测试，这时候会报连接失败的错误，需要启动 zookeeper 才能成功。至此 provider 已经配置完成\n\n![](https://i.loli.net/2021/04/01/hHBmAnWISjpyktb.png)\n\n![](https://i.loli.net/2021/04/01/w4nzBJ32VHsQAti.png)\n\n### demoProvider 工程的完整 pom 文件\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>com.aias</groupId>\n        <artifactId>demo</artifactId>\n        <version>0.0.1-SNAPSHOT</version>\n    </parent>\n    <groupId>com.aias</groupId>\n    <artifactId>demoProvider</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>demoProvider</name>\n    <description>Demo project for Spring Boot</description>\n    <dependencies>\n        <dependency>\n            <groupId>com.aias</groupId>\n            <artifactId>common</artifactId>\n            <version>0.0.1-SNAPSHOT</version>\n        </dependency>\n        <!-- mybatis -->\n        <dependency>\n            <groupId>org.mybatis.spring.boot</groupId>\n            <artifactId>mybatis-spring-boot-starter</artifactId>\n            <version>2.1.0</version>\n        </dependency>\n        <!-- druid -->\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>druid-spring-boot-starter</artifactId>\n            <version>1.1.10</version>\n        </dependency>\n        <!-- mysql-connector -->\n        <dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n        </dependency>\n        <!-- dubbo -->\n        <dependency>\n            <groupId>com.alibaba.boot</groupId>\n            <artifactId>dubbo-spring-boot-starter</artifactId>\n            <version>0.2.0</version>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>dubbo</artifactId>\n            <version>2.6.3</version>\n        </dependency>\n    </dependencies>\n</project>\n\n```\n\n### 8.在 demoConsumer 工程中添加相关依赖，和 dubbo 配置信息，通过注解注入的方式调用服务提供者的 service 实现\n\n![](https://i.loli.net/2021/04/01/xmX5YfPC3KweNbp.png)\n\n![](https://i.loli.net/2021/04/01/s4fNegUxRMiZlTV.png)\n\n### demoConsumer 完整 pom 文件\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>com.aias</groupId>\n        <artifactId>demo</artifactId>\n        <version>0.0.1-SNAPSHOT</version>\n    </parent>\n    <groupId>com.aias</groupId>\n    <artifactId>demoConsumer</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>demoConsumer</name>\n    <description>Demo project for Spring Boot</description>\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n    <dependencies>\n        <dependency>\n            <groupId>com.aias</groupId>\n            <artifactId>common</artifactId>\n            <version>0.0.1-SNAPSHOT</version>\n        </dependency>\n        <!-- dubbo -->\n        <dependency>\n            <groupId>com.alibaba.boot</groupId>\n            <artifactId>dubbo-spring-boot-starter</artifactId>\n            <version>0.2.0</version>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>dubbo</artifactId>\n            <version>2.6.3</version>\n        </dependency>\n    </dependencies>\n</project>\n\n```\n\n### 9.启动 zookeeper，启动 demoProvider 和 demoConsumer 项目，浏览器访问http://localhost:8080/hello\n\n### 成功页面\n\n![](https://i.loli.net/2021/04/01/93rmxG2EsKkWueq.png)\n\n### 10.项目源码详见[springboot 集成 dubbo 示例项目](https://github.com/Aias00/demoSpringBootDubbo)\n","tags":["springboot","dubbo"]}]